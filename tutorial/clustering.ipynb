{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Reference-docs\" data-toc-modified-id=\"Reference-docs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reference docs</a></span></li><li><span><a href=\"#Start-up\" data-toc-modified-id=\"Start-up-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Start up</a></span></li><li><span><a href=\"#Sign-representations\" data-toc-modified-id=\"Sign-representations-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sign representations</a></span></li><li><span><a href=\"#Object-similarity\" data-toc-modified-id=\"Object-similarity-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Object similarity</a></span><ul class=\"toc-item\"><li><span><a href=\"#Storing-similarity-computations\" data-toc-modified-id=\"Storing-similarity-computations-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Storing similarity computations</a></span></li></ul></li><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Clustering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Algorithm\" data-toc-modified-id=\"Algorithm-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Algorithm</a></span></li><li><span><a href=\"#A-few-runs\" data-toc-modified-id=\"A-few-runs-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>A few runs</a></span></li></ul></li><li><span><a href=\"#Cluster-evaluation\" data-toc-modified-id=\"Cluster-evaluation-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Cluster evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Criteria\" data-toc-modified-id=\"Criteria-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Criteria</a></span></li><li><span><a href=\"#Threshold-search\" data-toc-modified-id=\"Threshold-search-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Threshold search</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-27T08:24:45.190815Z",
     "start_time": "2018-02-27T08:24:45.174943Z"
    }
   },
   "source": [
    "<img align=\"left\" src=\"images/P005381-obverse-photo.png\" width=\"15%\"/>\n",
    "<img align=\"left\" src=\"images/P005381-obverse-lineart-annot.png\" width=\"15%\"/>\n",
    "<img align=\"right\" src=\"images/P005381-reverse-photo.png\" width=\"15%\"/>\n",
    "<img align=\"right\" src=\"images/P005381-reverse-lineart.png\" width=\"15%\"/>\n",
    "\n",
    "<p>\n",
    "```\n",
    "&P005381 = MSVO 3, 70\n",
    "```\n",
    "</p>\n",
    "<p>\n",
    "<img src=\"images/P005381-obverse-atf.png\" width=\"40%\"/>\n",
    "<img src=\"images/P005381-reverse-atf.png\" width=\"40%\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "\n",
    "\n",
    "# Clustering\n",
    "\n",
    "We want to get insights in the co-occurrences of signs on tablets in the \n",
    "[Uruk III/IV](http://cdli.ox.ac.uk/wiki/doku.php?id=proto-cuneiform)\n",
    "corpus (4000-3100 BC).\n",
    "These tablets have a poor archival context, since they come from rubbish pits, and may have been transported\n",
    "from various different places than where they have been excavated.\n",
    "\n",
    "In order to get more information about their chronology and context, we need to study the evolution of\n",
    "the signs on the tablets. Clustering and collocation are prerequisites to do so.\n",
    "\n",
    "In [collocation](collocation.ipynb) we did first steps in pairing signs\n",
    "that co-occur on the same tablets, faces, columns, lines.\n",
    "\n",
    "Now we want to *cluster* tablets based on the signs they contain.\n",
    "\n",
    "**N.B.:** This notebook does not use the results from the collocation notebook.\n",
    "\n",
    "The method borrows insights from finding parallel passages in the Hebrew Bible,\n",
    "as executed in the [parallels notebook](https://github.com/ETCBC/parallels/blob/master/programs/parallels.ipynb).\n",
    "\n",
    "## Data\n",
    "\n",
    "We have downloaded the transcriptions from the \n",
    "**Cuneiform Digital Library Initiative**\n",
    "[CDLI](https://cdli.ucla.edu),\n",
    "and converted them to\n",
    "[Text-Fabric](https://github.com/Dans-labs/text-fabric).\n",
    "Read more about the details of the conversion in the\n",
    "[checks](checks.ipynb) notebook.\n",
    "For an introduction to Text-Fabric, follow the\n",
    "[start](start.ipynb) tutorial.\n",
    "\n",
    "## Reference docs\n",
    "The functions used by this notebook are documented in the following places:\n",
    "\n",
    "[Feature docs](https://github.com/Dans-labs/Nino-cunei/blob/master/docs/transcription.md)\n",
    "\n",
    "[Cunei API](https://github.com/Dans-labs/Nino-cunei/blob/master/docs/cunei.md)\n",
    "\n",
    "[Utils API](https://github.com/Dans-labs/Nino-cunei/blob/master/docs/utils.md)\n",
    "\n",
    "[Text-Fabric API](https://github.com/Dans-labs/text-fabric)\n",
    "\n",
    "\n",
    "# Authors\n",
    "\n",
    "J. Cale Johnson and Dirk Roorda (see the \n",
    "[README](https://github.com/Dans-labs/Nino-cunei)\n",
    "of this repository)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start up\n",
    "\n",
    "We import the Python modules we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:24:30.061956Z",
     "start_time": "2018-02-28T17:24:30.039727Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:24:32.078535Z",
     "start_time": "2018-02-28T17:24:32.046294Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, collections\n",
    "from IPython.display import Markdown, display\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up our working locations on the file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:24:35.699055Z",
     "start_time": "2018-02-28T17:24:35.661862Z"
    }
   },
   "outputs": [],
   "source": [
    "GITHUB = 'https://github.com'\n",
    "REPO_REL = 'Dans-labs/Nino-cunei'\n",
    "REPO = f'~/github/{REPO_REL}'\n",
    "SOURCE = 'uruk'\n",
    "VERSION = '0.1'\n",
    "CORPUS = f'{REPO}/tf/{SOURCE}/{VERSION}'\n",
    "SOURCE_DIR = os.path.expanduser(f'{REPO}/sources/cdli')\n",
    "PROGRAM_DIR = os.path.expanduser(f'{REPO}/programs')\n",
    "TEMP_DIR = os.path.expanduser(f'{REPO}/_temp')\n",
    "REPORT_DIR = os.path.expanduser(f'{REPO}/reports')\n",
    "RESULT_DIR = f'{REPORT_DIR}/clustering'\n",
    "RESULT_GH = f'{GITHUB}/{REPO_REL}/blob/master/reports/clustering'\n",
    "TEMP_RESULT_DIR = f'{TEMP_DIR}/clustering'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the temporary and report directories, if they do not exist already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:24:38.679685Z",
     "start_time": "2018-02-28T17:24:38.658583Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(PROGRAM_DIR)\n",
    "from cunei import Cunei\n",
    "from utils import Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:24:39.662126Z",
     "start_time": "2018-02-28T17:24:39.642366Z"
    }
   },
   "outputs": [],
   "source": [
    "for cdir in (TEMP_DIR, REPORT_DIR, RESULT_DIR, TEMP_RESULT_DIR):\n",
    "    os.makedirs(cdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:24:40.483475Z",
     "start_time": "2018-02-28T17:24:40.457767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.2.2\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "32 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=[CORPUS], modules=[''], silent=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:24:42.518063Z",
     "start_time": "2018-02-28T17:24:41.414074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.00s B catalogId            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B fullNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B number               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.06s B grapheme             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.05s B srcLn                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B srcLnNum             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B prime                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B repeat               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B variant              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B variantOuter         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifier             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierInner        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierFirst        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B damage               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B uncertain            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B remarkable           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B written              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B period               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B name                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.03s B type                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B identifier           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B origNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B badNumbering         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B crossref             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B text                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B op                   from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.10s B sub                  from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B comments             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s Feature overview: 27 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  1.08s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    grapheme prime repeat\n",
    "    variant variantOuter\n",
    "    modifier modifierInner modifierFirst\n",
    "    damage uncertain remarkable written\n",
    "    period name type identifier catalogId\n",
    "    number fullNumber origNumber badNumbering\n",
    "    crossref text\n",
    "    srcLn srcLnNum\n",
    "    op sub comments''')\n",
    "api.makeAvailableIn(globals())\n",
    "CUNEI = Cunei(api)\n",
    "COMP = Compare(api, SOURCE_DIR, TEMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick up where we left off in the [start](start.ipynb) tutorial: computing co-occurrences\n",
    "by tablet. But we make the move to put our recipes into functions, that we will re-use and refine later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sign representations\n",
    "\n",
    "We pre-compute the sets of distinct signs per object.\n",
    "\n",
    "We also make an sign-index of the objects.\n",
    "\n",
    "Objects without signs (after filtering out non-signs), will be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:25:16.556985Z",
     "start_time": "2018-02-28T17:25:16.494854Z"
    }
   },
   "outputs": [],
   "source": [
    "NA = {'', '…', 'X'}\n",
    "\n",
    "def getSigns(nodeType):\n",
    "    signsFromObject = collections.defaultdict(set)\n",
    "    objectsFromSign = collections.defaultdict(set)\n",
    "    emptyObjects = set()\n",
    "\n",
    "    for obj in F.otype.s(nodeType):\n",
    "        theseSigns = {\n",
    "            CUNEI.atfFromSign(s)\n",
    "            for s in L.d(obj, otype='sign')\n",
    "            if F.grapheme.v(s) not in NA\n",
    "        }\n",
    "        for signRep in theseSigns:\n",
    "            signsFromObject[obj].add(signRep)\n",
    "            objectsFromSign[signRep].add(obj)\n",
    "        if len(theseSigns) == 0:\n",
    "            emptyObjects.add(obj)\n",
    "    print(\n",
    "        f'computed {len(objectsFromSign)} distinct sign representations'\n",
    "        f' from {len(signsFromObject)} {nodeType}s'\n",
    "        f' ({len(emptyObjects)} empty {nodeType}s)'\n",
    "    )\n",
    "    return (signsFromObject, objectsFromSign, emptyObjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will work with tablets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:25:19.821030Z",
     "start_time": "2018-02-28T17:25:19.162569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed 1526 distinct sign representations from 5674 tablets (722 empty tablets)\n"
     ]
    }
   ],
   "source": [
    "(signsFromObject, objectsFromSign, emptyObjects) = getSigns('tablet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show one of the empty tablets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:25:53.953968Z",
     "start_time": "2018-02-28T17:25:53.930060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P005057 = ATU 6, pl. 91, VAT 21520\n",
      "#version: 0.1\n",
      "#atf: lang qpc\n",
      "@obverse\n",
      "@column 1\n",
      "1. [...] , X [...]\n"
     ]
    }
   ],
   "source": [
    "emptyTablet = sorted(emptyObjects)[100]\n",
    "print('\\n'.join(COMP.getSource(emptyTablet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![empty](images/P005057-photo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object similarity\n",
    "\n",
    "We will group the objects into clusters based on a concept of *similarity* between objects.\n",
    "\n",
    "A handy measure is \n",
    "\n",
    "$$|T_1 \\cap T_2| \\over |T_1 \\cup T_2|$$\n",
    "\n",
    "In words: we take the number of signs in the intersection of the sign sets of two objects\n",
    "and divide it by the number of signs in the union of the sign sets of those two objects.\n",
    "\n",
    "It is the ratio between the amount of signs that the objects have in common and the \n",
    "total amount of signs they have.\n",
    "\n",
    "If the two objects are equal, or even if they have the same sign set, their similarity is maximal, \n",
    "i.e. `1`.\n",
    "\n",
    "If two objects have no signs in common, their similarity is minimal, i.e. `0`.\n",
    "\n",
    "If the sign set of one object is contained in that of another object, the similarity is the\n",
    "size of the smaller sign set divided by the bigger sign set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:27:16.057676Z",
     "start_time": "2018-02-28T17:27:16.040421Z"
    }
   },
   "outputs": [],
   "source": [
    "def signSimilarity(t1, t2):\n",
    "    signSet1 = signsFromObject[t1]\n",
    "    signSet2 = signsFromObject[t2]\n",
    "    return len(signSet1 & signSet2) / len(signSet1 | signSet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing similarity computations\n",
    "\n",
    "We are going to need many similarities between tablets, sometimes multiple times per pair.\n",
    "That's why we are going to memoize the results of the similarity function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:27:22.892357Z",
     "start_time": "2018-02-28T17:27:22.850125Z"
    }
   },
   "outputs": [],
   "source": [
    "simCache = {}\n",
    "stats = [0, 0]\n",
    "\n",
    "def memoSim(t1, t2):\n",
    "    pair = (t1, t2) if t1 < t2 else (t2, t1)\n",
    "    sim = simCache.get(pair, None)\n",
    "    if sim is None:\n",
    "        sim = signSimilarity(*pair)\n",
    "        simCache[pair] = sim\n",
    "        stats[1] += 1\n",
    "    else:\n",
    "        stats[0] += 1\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to see an example.\n",
    "Here is the source code of two (admittedly handy chosen) tablets.\n",
    "\n",
    "We then show their similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T17:27:41.621079Z",
     "start_time": "2018-02-28T17:27:41.551327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P001059 = ATU 5, pl. 039, W 9168,d\n",
      "#version: 0.1\n",
      "#atf: lang qpc\n",
      "@obverse\n",
      "@column 1\n",
      "1. 2(N01) , APIN~a SZAM2#\n",
      "2. 2(N14)# [...] , |KA2xLAM|#\n",
      "3. [...] 2(N01)# , KINGAL#\n",
      "4. [...] , [...]\n",
      "\n",
      " - - - - - - - - - - - - \n",
      "\n",
      "&P448701 = www archaeo-auction 003 \n",
      "#atf: lang qpc \n",
      "@obverse \n",
      "@column 1 \n",
      "1. 1(N46) 2(N19) 4(N41) , \n",
      "2. , AB~a APIN~a NUN~a X X \n",
      "@column 2 \n",
      "1. , X X\n",
      "2. , SZE~a DU NUN~a  \n",
      "@reverse \n",
      "$ (not imaged) \n",
      "\n",
      "o-o-o-o-o-o-o-o-o-o-o-o-o\n",
      "\n",
      "2(N01) 2(N14) APIN~a KA2 KINGAL LAM SZAM2\n",
      "\n",
      " - - - - - - - - - - - - \n",
      "\n",
      "1(N46) 2(N19) 4(N41) AB~a APIN~a DU NUN~a SZE~a\n",
      "\n",
      "o-o-o-o-o-o-o-o-o-o-o-o-o\n",
      "\n",
      "intersection: length 1: APIN~a \n",
      "union       : length 14: 1(N46) 2(N01) 2(N14) 2(N19) 4(N41) AB~a APIN~a DU KA2 KINGAL LAM NUN~a SZAM2 SZE~a\n",
      "\n",
      "o-o-o-o-o-o-o-o-o-o-o-o-o\n",
      "\n",
      "\n",
      "SIMILARITY 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "tablet1 = T.nodeFromSection(('P001059',))\n",
    "tablet2 = T.nodeFromSection(('P448701',))\n",
    "source1 = '\\n'.join(COMP.getSource(tablet1))\n",
    "source2 = '\\n'.join(COMP.getSource(tablet2))\n",
    "signs1 = signsFromObject[tablet1]\n",
    "signs2 = signsFromObject[tablet2]\n",
    "intersection = signs1 & signs2\n",
    "union = signs1 | signs2\n",
    "lengthI = len(intersection)\n",
    "lengthU = len(union)\n",
    "\n",
    "print(source1)\n",
    "print('\\n - - - - - - - - - - - - \\n')\n",
    "print(source2)\n",
    "print('\\no-o-o-o-o-o-o-o-o-o-o-o-o\\n')\n",
    "\n",
    "print(' '.join(sorted(signs1)))\n",
    "print('\\n - - - - - - - - - - - - \\n')\n",
    "print(' '.join(sorted(signs2)))\n",
    "print('\\no-o-o-o-o-o-o-o-o-o-o-o-o\\n')\n",
    "\n",
    "print(f'intersection: length {lengthI}: {\" \".join(sorted(intersection))} ')\n",
    "print(f'union       : length {lengthU}: {\" \".join(sorted(union))}')\n",
    "\n",
    "print('\\no-o-o-o-o-o-o-o-o-o-o-o-o\\n')\n",
    "\n",
    "print(f'\\nSIMILARITY {memoSim(tablet1, tablet2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "We borrow from the concept of *cliques* and the method of obtaining\n",
    "them demonstrated in the\n",
    "[parallels notebook](http://localhost:8888/notebooks/etcbc/parallels/programs/parallels.ipynb#4.3-Cliques).\n",
    "\n",
    "### Algorithm\n",
    "The idea is to visit all objects, one by one, and form clusters as we go.\n",
    "\n",
    "Suppose we have already a bunch of clusters and we visit a new object.\n",
    "\n",
    "We determine the clusters that are close enough to the object.\n",
    "\n",
    "If there are such clusters, we merge them and add the object to the new cluster.\n",
    "\n",
    "If not, we make a new empty cluster and put the object in it.\n",
    "\n",
    "We set a threshold to define what is \"close enough\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:06:03.305652Z",
     "start_time": "2018-02-28T18:06:03.211375Z"
    }
   },
   "outputs": [],
   "source": [
    "progress = 1000000\n",
    "\n",
    "def clustering(objects, threshold):\n",
    "    print(f'clustering {len(objects)} objects with threshold {threshold}')\n",
    "    i = 0\n",
    "    j = 0\n",
    "    clustersUnsorted = []\n",
    "    for (o, obj) in enumerate(objects):\n",
    "        added = None\n",
    "        removable = set()\n",
    "        for (k, cluster) in enumerate(clustersUnsorted):\n",
    "            origCluster = tuple(cluster)\n",
    "            for objC in origCluster:            \n",
    "                if j >= progress:\n",
    "                    print(\n",
    "                        f'\\t{o:>4} objects - {i:>9} x memoSim'\n",
    "                        f' - {stats[0]:>8} lookups {stats[1]:>9} comps'\n",
    "                    )\n",
    "                    j = 0\n",
    "                sim = memoSim(obj, objC)\n",
    "                i += 1\n",
    "                j += 1\n",
    "                if sim >= threshold:\n",
    "                    if added == None:    \n",
    "                        # obj has not been added to any cluster yet\n",
    "                        cluster.add(obj)\n",
    "                        added = k        \n",
    "                        # remember that we added obj to this cluster\n",
    "                    else:                \n",
    "                        # obj has alreay been added to another cluster:\n",
    "                        # we merge this cluster with that one\n",
    "                        clustersUnsorted[added] |= cluster\n",
    "                        removable.add(k) \n",
    "                        # we remember that we have merged this cluster into another one,\n",
    "                        # so we can throw away this cluster later \n",
    "                    break\n",
    "        if added == None:\n",
    "            clustersUnsorted.append({obj})\n",
    "        else:\n",
    "            if len(removable):\n",
    "                clustersUnsorted = [\n",
    "                    cluster\n",
    "                    for (k,cluster) in enumerate(clustersUnsorted)\n",
    "                    if k not in removable\n",
    "            ]\n",
    "    result = sorted(\n",
    "        [\n",
    "            tuple(sorted(cluster)) \n",
    "            for cluster in clustersUnsorted\n",
    "        ]\n",
    "    )\n",
    "    print(\n",
    "        f'\\t{len(objects):>4} objects - {i:>9} x memoSim'\n",
    "        f' - {stats[0]:>8} lookups {stats[1]:>9} comps'\n",
    "    )\n",
    "\n",
    "    print(f'{len(result)} clusters with threshold {threshold}')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few runs\n",
    "\n",
    "We just run the clustering with a similarity threshold of `0.8` to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:06:04.668239Z",
     "start_time": "2018-02-28T18:06:04.653822Z"
    }
   },
   "outputs": [],
   "source": [
    "objects = sorted(signsFromObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:06:26.267661Z",
     "start_time": "2018-02-28T18:06:05.313509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering 5674 objects with threshold 0.8\n",
      "\t1414 objects -   1000000 x memoSim - 111248734 lookups  16090051 comps\n",
      "\t2000 objects -   2000000 x memoSim - 112248734 lookups  16090051 comps\n",
      "\t2450 objects -   3000000 x memoSim - 113248734 lookups  16090051 comps\n",
      "\t2829 objects -   4000000 x memoSim - 114248734 lookups  16090051 comps\n",
      "\t3163 objects -   5000000 x memoSim - 115248734 lookups  16090051 comps\n",
      "\t3465 objects -   6000000 x memoSim - 116248734 lookups  16090051 comps\n",
      "\t3742 objects -   7000000 x memoSim - 117248734 lookups  16090051 comps\n",
      "\t4000 objects -   8000000 x memoSim - 118248734 lookups  16090051 comps\n",
      "\t4243 objects -   9000000 x memoSim - 119248734 lookups  16090051 comps\n",
      "\t4473 objects -  10000000 x memoSim - 120248734 lookups  16090051 comps\n",
      "\t4691 objects -  11000000 x memoSim - 121248734 lookups  16090051 comps\n",
      "\t4900 objects -  12000000 x memoSim - 122248734 lookups  16090051 comps\n",
      "\t5100 objects -  13000000 x memoSim - 123248734 lookups  16090051 comps\n",
      "\t5292 objects -  14000000 x memoSim - 124248734 lookups  16090051 comps\n",
      "\t5478 objects -  15000000 x memoSim - 125248734 lookups  16090051 comps\n",
      "\t5658 objects -  16000000 x memoSim - 126248734 lookups  16090051 comps\n",
      "\t5674 objects -  16089918 x memoSim - 126338652 lookups  16090051 comps\n",
      "5214 clusters with threshold 0.8\n"
     ]
    }
   ],
   "source": [
    "clusters = clustering(objects, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a few hundred objects got clustered with an other one.\n",
    "Such a rare clustering is not very informative.\n",
    "The threshold is too strict.\n",
    "\n",
    "What if we work with a very generous threshold, say `0.1`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:06:33.102381Z",
     "start_time": "2018-02-28T18:06:32.677384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering 5674 objects with threshold 0.1\n",
      "\t5674 objects -    212638 x memoSim - 126551290 lookups  16090051 comps\n",
      "9 clusters with threshold 0.1\n"
     ]
    }
   ],
   "source": [
    "clusters = clustering(objects, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the caching of the similarity computation pays off: looking up a value\n",
    "is quicker than computing it.\n",
    "\n",
    "We now have very few clusters. That is also not very meaningful.\n",
    "\n",
    "How big are the clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:06:38.073537Z",
     "start_time": "2018-02-28T18:06:38.051007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5666, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(c) for c in clusters]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet an other hallmark of bad clustering: there is one big cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster evaluation\n",
    "\n",
    "We just arrived at a few quality checks on a clustering: not too few, not too many, and not too large clusters.\n",
    "\n",
    "### Criteria\n",
    "Let's formalize what a good clustering is in terms of a few thresholds.\n",
    "\n",
    "These threshold restrain the number of clusters between a minimun and a maximum,\n",
    "and demand that the largest cluster is smaller than a certain size.\n",
    "\n",
    "All these thresholds are expressed in fractions of the total number of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:06:41.156059Z",
     "start_time": "2018-02-28T18:06:41.140683Z"
    }
   },
   "outputs": [],
   "source": [
    "N_MIN = 0.02 # at least 2% of amount of objects\n",
    "N_MAX = 0.4  # at most 40% of amount of objects\n",
    "SIZE_MAX = 0.7 # largest cluster at most 70% of the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:06:42.189649Z",
     "start_time": "2018-02-28T18:06:42.129047Z"
    }
   },
   "outputs": [],
   "source": [
    "def checkQuality(clusters, nObjects):\n",
    "    nC = len(clusters)\n",
    "    amountClusters = nC / nObjects\n",
    "    largestCluster = max(len(cluster) for cluster in clusters)\n",
    "    sizeCluster = largestCluster / nObjects\n",
    "\n",
    "    flaws = {}\n",
    "    msgs = {}\n",
    "    if amountClusters < N_MIN:\n",
    "        msgs['amount'] = f'< {N_MIN:>4.2f}'\n",
    "        flaws['amount'] = 'TOO FEW'\n",
    "    elif amountClusters > N_MAX:\n",
    "        msgs['amount'] = f'> {N_MAX:>4.2f}'\n",
    "        flaws['amount'] = 'TOO MANY'\n",
    "    else:\n",
    "        msgs['amount'] = f'>= {N_MIN:>4.2f} and <= {N_MAX:>4.2f}'\n",
    "\n",
    "    if sizeCluster > SIZE_MAX:\n",
    "        msgs['size'] = f'> {SIZE_MAX:>4.2f}'\n",
    "        flaws['size'] = 'TOO LARGE'\n",
    "    else:\n",
    "        msgs['size'] = f'<= {SIZE_MAX:>4.2f}'\n",
    "        \n",
    "    info1 = f'{nC:>4} clusters for {nObjects:>4} objects'\n",
    "    info2 = f'largest cluster has size {largestCluster:>4}'\n",
    "    msg1 = f'{amountClusters:>4.2f} {msgs[\"amount\"]}'\n",
    "    msg2 = f'{sizeCluster:>4.2f} {msgs[\"size\"]}'\n",
    "    flaw1 = f'{flaws.get(\"amount\", \"OK\"):<10}'\n",
    "    flaw2 = f'{flaws.get(\"size\", \"OK\"):<10}'\n",
    "    \n",
    "    print(\n",
    "        f'{flaw1}{info1:<40} relatively {msg1}\\n'\n",
    "        f'{flaw2}{info2:<40} relatively {msg2}'\n",
    "    )\n",
    "\n",
    "    return not flaws    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:06:44.018469Z",
     "start_time": "2018-02-28T18:06:44.001039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOO FEW      9 clusters for 5674 objects           relatively 0.00 < 0.02\n",
      "TOO LARGE largest cluster has size 5666            relatively 1.00 > 0.70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkQuality(clusters, len(objects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold search\n",
    "\n",
    "We now run the clustering with a series of thresholds and evaluate the outcomes.\n",
    "\n",
    "If the resulting clustering does not pass the quality check, we discard it.\n",
    "Otherwise we retain it for later inspection.\n",
    "\n",
    "We show the statistics of each clustering (good or bad), and print\n",
    "the good clusterings to file.\n",
    "\n",
    "When we write clusterings, we leave out the singleton clusters and clusters that\n",
    "have half of the objects or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:16:32.727591Z",
     "start_time": "2018-02-28T18:16:32.634078Z"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(objects, threshold):\n",
    "    clusters = clustering(objects, threshold)\n",
    "    if checkQuality(clusters, len(objects)):\n",
    "        return clusters\n",
    "    return False\n",
    "\n",
    "def writeClustering(clusterings, signsFromObject, nodeType, idFeature, threshold):\n",
    "    clusterFile = f'{nodeType}-{threshold}.tsv'\n",
    "    clusterPath = f'{RESULT_DIR}/{clusterFile}'\n",
    "    with open(clusterPath, 'w') as fh:\n",
    "        fh.write(f'cluster\\t{nodeType}\\tobjectId\\tsigns\\n')\n",
    "        for (i, cluster) in enumerate(sorted(\n",
    "            clusterings[threshold],\n",
    "            key=lambda x: -len(x),\n",
    "        )):\n",
    "            if len(cluster) == 1 or len(cluster) >= 0.5 * len(signsFromObject):\n",
    "                continue\n",
    "            for obj in cluster:\n",
    "                objId = Fs(idFeature).v(obj)\n",
    "                signs = ' '.join(sorted(signsFromObject[obj]))\n",
    "                fh.write(f'{i}\\t{obj}\\t{objId}\\t{signs}\\n')\n",
    "    display(Markdown(f'[{clusterFile}]({RESULT_GH}/{clusterFile})\\n\\n'))\n",
    "    \n",
    "    \n",
    "def experiments(nodeType, idFeature, thresholds):\n",
    "    (signsFromObject, objectsFromSign, emptyObjects) = getSigns(nodeType)\n",
    "    objects = sorted(signsFromObject)\n",
    "    \n",
    "    clusterings = {}\n",
    "    for threshold in thresholds:\n",
    "        display(Markdown(f'**Experiment** {len(objects)} {nodeType}s *threshold* {threshold}'))\n",
    "        clusters = experiment(objects, threshold)\n",
    "    if clusters:\n",
    "        clusterings[threshold] = clusters\n",
    "        writeClustering(clusterings, signsFromObject, nodeType, idFeature, threshold)\n",
    "\n",
    "    print(f'Found {len(clusterings)} good clusterings')\n",
    "    \n",
    "    return clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-28T18:16:49.740591Z",
     "start_time": "2018-02-28T18:16:33.481591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed 1526 distinct sign representations from 5674 tablets (722 empty tablets)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Experiment** 5674 tablets *threshold* 0.35"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering 5674 objects with threshold 0.35\n",
      "\t1522 objects -   1000000 x memoSim - 153327270 lookups  16090051 comps\n",
      "\t2174 objects -   2000000 x memoSim - 154327270 lookups  16090051 comps\n",
      "\t2635 objects -   3000000 x memoSim - 155327270 lookups  16090051 comps\n",
      "\t3085 objects -   4000000 x memoSim - 156327270 lookups  16090051 comps\n",
      "\t3423 objects -   5000000 x memoSim - 157327270 lookups  16090051 comps\n",
      "\t3725 objects -   6000000 x memoSim - 158327270 lookups  16090051 comps\n",
      "\t4018 objects -   7000000 x memoSim - 159327270 lookups  16090051 comps\n",
      "\t4324 objects -   8000000 x memoSim - 160327270 lookups  16090051 comps\n",
      "\t4602 objects -   9000000 x memoSim - 161327270 lookups  16090051 comps\n",
      "\t4902 objects -  10000000 x memoSim - 162327270 lookups  16090051 comps\n",
      "\t5184 objects -  11000000 x memoSim - 163327270 lookups  16090051 comps\n",
      "\t5453 objects -  12000000 x memoSim - 164327270 lookups  16090051 comps\n",
      "\t5674 objects -  12887990 x memoSim - 165215260 lookups  16090051 comps\n",
      "2091 clusters with threshold 0.35\n",
      "OK        2091 clusters for 5674 objects           relatively 0.37 >= 0.02 and <= 0.40\n",
      "OK        largest cluster has size 3358            relatively 0.59 <= 0.70\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[tablet-0.35.tsv](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/clustering/tablet-0.35.tsv)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 good clusterings\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "experiments('tablet', 'catalogId', [0.35])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
