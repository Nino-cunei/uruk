{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/quad.png\" width=\"300\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "This notebook gets you started with using\n",
    "[Text-Fabric](https://github.com/Dans-labs/text-fabric) for coding in cuneiform tablet transcriptions.\n",
    "\n",
    "Chances are that a bit of reading about the underlying\n",
    "[data model](https://github.com/Dans-labs/text-fabric/wiki/Data-model)\n",
    "helps you to follow the exercises below, and vice versa.\n",
    "\n",
    "There are also exercises that are really checks on the conversion from the transcriptions\n",
    "to Text-Fabric.\n",
    "We have collected them into the separate notebook [checks](checks.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most programs start with loading a few modules.\n",
    "In the next cell, the first line loads standard modules that come with Python itself,\n",
    "and the second cell loads Text-Fabric.\n",
    "\n",
    "Before you can run this, you need to install it.\n",
    "The basic instruction for that is, on a terminal:\n",
    "\n",
    "```\n",
    "pip install text-fabric\n",
    "```\n",
    "\n",
    "if you have installed Python with the help of Anaconda, or\n",
    "\n",
    "```\n",
    "sudo -H pip3 install text-fabric\n",
    "```\n",
    "if you have installed Python from [python.org](https://www.python.org).\n",
    "\n",
    "Make sure that you do all this with Python **3**, not 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:42.780761Z",
     "start_time": "2018-02-20T21:13:42.758502Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:42.805855Z",
     "start_time": "2018-02-20T21:13:42.782966Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, collections\n",
    "from tf.fabric import Fabric\n",
    "from utils import Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Text-Fabric\n",
    "\n",
    "Everything starts by setting up Text-Fabric.\n",
    "It needs to know where to look for data.\n",
    "\n",
    "The cuneiform tablet transcriptions are in the same repository as this tutorial.\n",
    "I assume you have cloned [nino-cunei](https://github.com/Dans-labs/nino-cunei).\n",
    "in your directory `~/github/Dans-labs`, so that your directory structure looks like this\n",
    "\n",
    "    your home direcectory\\\n",
    "    |                     - github\\\n",
    "    |                       |      - Dans-labs\\\n",
    "    |                       |        |         - nino-cunei\n",
    "    \n",
    "## Tip\n",
    "If you start computing with this tutorial, first copy its parent directory to somewhere else,\n",
    "outside your `nino-cunei` directory.\n",
    "If you pull changes from the `nino-cunei` repository later, your work will not be overwritten.\n",
    "Where you put your tutorial directory is up till you.\n",
    "It will work from any directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:44.532908Z",
     "start_time": "2018-02-20T21:13:44.509679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.2.0\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "29 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "REPO = '~/github/Dans-labs/nino-cunei'\n",
    "SOURCE = 'uruk'\n",
    "VERSION = '0.1'\n",
    "CORPUS = f'{REPO}/tf/{SOURCE}/{VERSION}'\n",
    "SOURCE_DIR = os.path.expanduser(f'{REPO}/sources/cdli')\n",
    "TEMP_DIR = os.path.expanduser(f'{REPO}/_temp')\n",
    "TF = Fabric(locations=[CORPUS], modules=[''], silent=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features\n",
    "The data of the corpus is organized in features.\n",
    "They are *columns* of data.\n",
    "Think of the corpus of tablet transcriptions as a gigantic spreadsheet, where row 1 corresponds to the\n",
    "first sign, row 2 to the second sign, and so on, for all 100,000+ signs.\n",
    "\n",
    "The grapheme name of each sign is a column `grapheme` in that spreadsheet.\n",
    "\n",
    "The information whether a sign is damaged, constitutes a column `damaged`.\n",
    "\n",
    "The corpus contains over 20 columns, not only for the signs, but also for a 150,000+ more\n",
    "textual objects, such as *(sub)quads*, *clusters*, *lines*, *cases*, *columns*, *faces* and *tablets*.\n",
    "\n",
    "We also have features that contain the original lines of transcription.\n",
    "These features are filled for tablets, faces, columns, lines, and comments.\n",
    "\n",
    "Instead of putting that information in one big table, the data is organized in separate columns.\n",
    "We call those columns **features**.\n",
    "\n",
    "We just load the features we need for this tutorial.\n",
    "Later on, where we use them, it will become clear what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:47.330643Z",
     "start_time": "2018-02-20T21:13:46.299599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.01s B catalogId            from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B number               from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.05s B grapheme             from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.04s B srcLn                from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B srcLnNum             from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B prime                from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B variant              from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifier             from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B rmodifier            from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B repeat               from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B damage               from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B uncertain            from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B remarkable           from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B written              from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B name                 from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B op                   from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B comments             from /Users/dirk/github/Dans-labs/nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s Feature overview: 24 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  1.01s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    grapheme prime variant modifier rmodifier repeat\n",
    "    damage uncertain remarkable written\n",
    "    name number catalogId\n",
    "    srcLn srcLnNum\n",
    "    op comments\n",
    "''')\n",
    "api.makeAvailableIn(globals())\n",
    "COMP = Compare(api, SOURCE_DIR, TEMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this all is that we have a bunch of special variables at our disposal\n",
    "that give us access to the text and data of the tablets.\n",
    "\n",
    "At this point it is helpful to throw a quick glance at the text-fabric\n",
    "[API documentation](https://github.com/Dans-labs/text-fabric/wiki/Api)\n",
    "especially the right side bar.\n",
    "\n",
    "The most essential thing for now is that we can use `F` to access the data in the features\n",
    "we've loaded.\n",
    "But there is more, such as `N`, which helps us to walk over the text, as we see in a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting\n",
    "\n",
    "In order to get acquainted with the data, we start with the simple task of counting.\n",
    "\n",
    "## Count all nodes\n",
    "We use the \n",
    "[`N()` generator](https://github.com/Dans-labs/text-fabric/wiki/Api#walking-through-nodes)\n",
    "to walk through the nodes.\n",
    "\n",
    "We compared the tablet data to a gigantic spreadsheet, where the rows correspond to the words.\n",
    "In Text-Fabric, we call the rows `slots`, because they are the textual positions that can be filled with words.\n",
    "\n",
    "We also mentioned that there are also other textual objects. \n",
    "They are the tablets, columns, lines, etc.\n",
    "They also correspond to rows in the big spreadsheet.\n",
    "\n",
    "In Text-Fabric we call all these rows *nodes*, and the `N()` generator\n",
    "carries us through those nodes in the textual order.\n",
    "\n",
    "Just one extra thing: the `info` statements generate timed messages.\n",
    "If you use them instead of `print` you'll get a sense of the amount of time that \n",
    "the various processing steps typically need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:50.034675Z",
     "start_time": "2018-02-20T21:13:49.924413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Counting nodes ...\n",
      "  0.09s 448584 nodes\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('Counting nodes ...')\n",
    "\n",
    "i = 0\n",
    "for n in N(): i += 1\n",
    "\n",
    "info('{} nodes'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see it: more than 400,000 nodes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are all those nodes?\n",
    "Every node has a type, like sign, or line, face.\n",
    "We know that we have many of them,\n",
    "but what exactly are they?\n",
    "\n",
    "Text-Fabric has two special features, `otype` and `oslots`, that must occur in every Text-Fabric data set.\n",
    "`otype` tells you for each node its type, and you can ask for the number of `slot`s in the text.\n",
    "\n",
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:53.585705Z",
     "start_time": "2018-02-20T21:13:53.559168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sign'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.slotType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:53.604695Z",
     "start_time": "2018-02-20T21:13:53.588342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147190"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxSlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:53.623630Z",
     "start_time": "2018-02-20T21:13:53.607057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448584"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:53.642262Z",
     "start_time": "2018-02-20T21:13:53.626306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tablet',\n",
       " 'face',\n",
       " 'column',\n",
       " 'line',\n",
       " 'case',\n",
       " 'cluster',\n",
       " 'quad',\n",
       " 'comment',\n",
       " 'sign')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain a bit more knowledge about the types of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:55.426288Z",
     "start_time": "2018-02-20T21:13:55.408422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tablet   average length 23.0128 from 147191 to 153586\n",
      "face     average length 14.3715 from 153587 to 163028\n",
      "column   average length  9.5055 from 163029 to 177061\n",
      "line     average length  3.5707 from 225828 to 262752\n",
      "case     average length  3.1877 from 262753 to 314437\n",
      "cluster  average length  1.0314 from 192868 to 225827\n",
      "quad     average length  1.0333 from 314438 to 448584\n",
      "comment  average length  1.0000 from 177062 to 192867\n",
      "sign     average length  1.0000 from      1 to 147190\n"
     ]
    }
   ],
   "source": [
    "for (nodeType, avLen, startNode, endNode) in C.levels.data:\n",
    "    print(f'{nodeType:<8} average length {avLen:>7.4f} from {startNode:>6} to {endNode:>6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the first *cluster*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:57.261483Z",
     "start_time": "2018-02-20T21:13:57.245471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192868"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = F.otype.s('cluster')[0]\n",
    "cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what is embedded in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:13:59.092251Z",
     "start_time": "2018-02-20T21:13:59.077054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 314438 of type quad\n",
      "node      3 of type sign\n"
     ]
    }
   ],
   "source": [
    "for n in L.d(cl):\n",
    "    print(f'node {n:>6} of type {F.otype.v(n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the third *sign*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:00.947498Z",
     "start_time": "2018-02-20T21:14:00.932858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sign'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.v(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:02.880674Z",
     "start_time": "2018-02-20T21:14:02.865896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 314438 of type quad\n",
      "node 192868 of type cluster\n",
      "node 262753 of type case\n",
      "node 225828 of type line\n",
      "node 163029 of type column\n",
      "node 153587 of type face\n",
      "node 147191 of type tablet\n"
     ]
    }
   ],
   "source": [
    "for n in L.u(3):\n",
    "    print(f'node {n:>6} of type {F.otype.v(n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count individual object types\n",
    "This is an intuitive way to count the number of nodes in each type.\n",
    "Note in passing, how we use the `indent` in conjunction with `info` to produce neat timed \n",
    "and indented progress messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:04.838905Z",
     "start_time": "2018-02-20T21:14:04.746148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s counting objects ...\n",
      "   |     0.00s    6396 tablets\n",
      "   |     0.00s    9442 faces\n",
      "   |     0.00s   14033 columns\n",
      "   |     0.01s   36925 lines\n",
      "   |     0.01s   51685 cases\n",
      "   |     0.00s   32960 clusters\n",
      "   |     0.02s  134147 quads\n",
      "   |     0.00s   15806 comments\n",
      "   |     0.02s  147190 signs\n",
      "  0.07s Done\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('counting objects ...')\n",
    "\n",
    "for otype in F.otype.all:\n",
    "    i = 0\n",
    "\n",
    "    indent(level=1, reset=True)\n",
    "\n",
    "    for n in F.otype.s(otype): i+=1\n",
    "\n",
    "    info('{:>7} {}s'.format(i, otype))\n",
    "\n",
    "indent(level=0)\n",
    "info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locality\n",
    "\n",
    "We travel upwards and downwards, forwards and backwards through the nodes.\n",
    "The Locality-API (`L`) provides functions: `u()` for going up, and `d()` for going down,\n",
    "`n()` for going to next nodes and `p()` for going to previous nodes.\n",
    "\n",
    "These directions are indirect notions: nodes are just numbers, but by means of the\n",
    "`oslots` feature they are linked to slots. One node *contains* an other node, if the one is linked to a set of slots that contains the set of slots that the other is linked to.\n",
    "And one if next or previous to an other, if its slots follow of precede the slots of the other one.\n",
    "\n",
    "`L.u(node)` **Up** is going to nodes that embed `node`.\n",
    "\n",
    "`L.d(node)` **Down** is the opposite direction, to those that are contained in `node`.\n",
    "\n",
    "`L.n(node)` **Next** are the next *adjacent* nodes, i.e. nodes whose first slot comes immediately after the last slot of `node`.\n",
    "\n",
    "`L.p(node)` **Previous** are the previous *adjacent* nodes, i.e. nodes whose last slot comes immediately before the first slot of `node`.\n",
    "\n",
    "All these functions yield nodes of all possible otypes.\n",
    "By passing an optional parameter, you can restrict the results to nodes of that type.\n",
    "\n",
    "The result are ordered according to the order of things in the text.\n",
    "\n",
    "The functions return always a tuple, even if there is just one node in the result.\n",
    "\n",
    "## Going up\n",
    "We go from the first sign to the tablet it contains.\n",
    "Note the `[0]` at the end. You expect one tablet, yet `L` returns a tuple. \n",
    "To get the only element of that tuple, you need to do that `[0]`.\n",
    "\n",
    "If you are like me, you keep forgetting it, and that will lead to weird error messages later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:06.733329Z",
     "start_time": "2018-02-20T21:14:06.717562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147191\n"
     ]
    }
   ],
   "source": [
    "firstTablet = L.u(1, otype='tablet')[0]\n",
    "print(firstTablet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see all the containing objects of sign 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:08.716120Z",
     "start_time": "2018-02-20T21:14:08.694764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign 100 is contained in tablet 147195\n",
      "sign 100 is contained in face 153593\n",
      "sign 100 is contained in column 163041\n",
      "sign 100 is contained in line 225855\n",
      "sign 100 is contained in case 262783\n",
      "sign 100 is not contained in a cluster\n",
      "sign 100 is contained in quad 314527\n",
      "sign 100 is not contained in a comment\n"
     ]
    }
   ],
   "source": [
    "w = 100\n",
    "for otype in F.otype.all:\n",
    "    if otype == F.otype.slotType: continue\n",
    "    up = L.u(w, otype=otype)\n",
    "    upNode = None if len(up) == 0 else up[0]\n",
    "    if upNode is None:\n",
    "        print('sign {} is not contained in a {}'.format(w, otype))\n",
    "    else:\n",
    "        print('sign {} is contained in {} {}'.format(w, otype, upNode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going next\n",
    "Let's go to the next nodes of the first tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:10.594195Z",
     "start_time": "2018-02-20T21:14:10.575428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10: sign          first slot=10    , last slot=10    \n",
      " 177064: comment       first slot=10    , last slot=10    \n",
      " 147192: tablet        first slot=10    , last slot=39    \n"
     ]
    }
   ],
   "source": [
    "afterFirstTablet = L.n(firstTablet)\n",
    "for n in afterFirstTablet:\n",
    "    print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "        n, F.otype.v(n),\n",
    "        E.oslots.s(n)[0],\n",
    "        E.oslots.s(n)[-1],\n",
    "    ))\n",
    "secondTablet = L.n(firstTablet, otype='tablet')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going previous\n",
    "\n",
    "And let's see what is right before the second tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:12.604343Z",
     "start_time": "2018-02-20T21:14:12.570351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 147191: tablet        first slot=1     , last slot=9     \n",
      " 153587: face          first slot=3     , last slot=9     \n",
      " 163030: column        first slot=6     , last slot=9     \n",
      " 225829: line          first slot=6     , last slot=9     \n",
      " 262754: case          first slot=6     , last slot=9     \n",
      " 192869: cluster       first slot=9     , last slot=9     \n",
      " 314444: quad          first slot=9     , last slot=9     \n",
      "      9: sign          first slot=9     , last slot=9     \n"
     ]
    }
   ],
   "source": [
    "for n in L.p(secondTablet):\n",
    "    print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "        n, F.otype.v(n),\n",
    "        E.oslots.s(n)[0],\n",
    "        E.oslots.s(n)[-1],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go to the columns of the second tablet, and just count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:16.549361Z",
     "start_time": "2018-02-20T21:14:16.533997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "columns = L.d(secondTablet, otype='column')\n",
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first line\n",
    "We pick the first line and the first sign, and explore what is above and below them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:18.560898Z",
     "start_time": "2018-02-20T21:14:18.522772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1\n",
      "   |   UP\n",
      "   |      |   177062          comment\n",
      "   |      |   147191          tablet\n",
      "   |   DOWN\n",
      "   |      |   \n",
      "Node 225828\n",
      "   |   UP\n",
      "   |      |   262753          case\n",
      "   |      |   163029          column\n",
      "   |      |   153587          face\n",
      "   |      |   147191          tablet\n",
      "   |   DOWN\n",
      "   |      |   163029          column\n",
      "   |      |   262753          case\n",
      "   |      |   192868          cluster\n",
      "   |      |   314438          quad\n",
      "   |      |   3               sign\n",
      "   |      |   314439          quad\n",
      "   |      |   4               sign\n",
      "   |      |   314440          quad\n",
      "   |      |   5               sign\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "firstLine = L.d(firstTablet, otype='line')[0]\n",
    "\n",
    "for n in [1, firstLine]:\n",
    "    indent(level=0)\n",
    "    info('Node {}'.format(n), tm=False)\n",
    "    indent(level=1)\n",
    "    info('UP', tm=False)\n",
    "    indent(level=2)\n",
    "    info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.u(n)]), tm=False)\n",
    "    indent(level=1)\n",
    "    info('DOWN', tm=False)\n",
    "    indent(level=2)\n",
    "    info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.d(n)]), tm=False)\n",
    "indent(level=0)\n",
    "info('Done', tm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text\n",
    "\n",
    "The `T` functions provide ways of printing out text, and they know about section levels.\n",
    "\n",
    "We use section levels `tablet`, `column`, `line`.\n",
    "`face` is a level of nodes, but not a section level.\n",
    "\n",
    "We will define our own function to get the literal transcription text back for\n",
    "tablets, faces, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:20.530876Z",
     "start_time": "2018-02-20T21:14:20.501487Z"
    }
   },
   "outputs": [],
   "source": [
    "oLevels = '''\n",
    "    tablet\n",
    "    face\n",
    "    column\n",
    "    case\n",
    "'''.strip().split()\n",
    "\n",
    "lowerLevel = dict((oLevels[n], oLevels[n+1]) for n in range(len(oLevels) - 1))\n",
    "\n",
    "def transObject(n):\n",
    "    kind = F.otype.v(n)\n",
    "    trans = []\n",
    "    trans.append(f'{F.srcLnNum.v(n):>7}: {F.srcLn.v(n)}')\n",
    "    for c in E.comments.f(n):\n",
    "        trans.append(f'{F.srcLnNum.v(c):>7}: {F.srcLn.v(c)}')\n",
    "    print('\\n'.join(trans))\n",
    "    subKind = lowerLevel.get(kind, None)\n",
    "    if subKind:\n",
    "        for m in L.d(n, otype=subKind):\n",
    "            if F.srcLn.v(m) is not None:\n",
    "                transObject(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:20.549311Z",
     "start_time": "2018-02-20T21:14:20.533429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1: &P006427 = HJN 0044\n",
      "      2: #version: 0.1\n",
      "      3: #atf: lang qpc\n",
      "      4: @obverse\n",
      "      5: @column 1\n",
      "      6: 1. [...] , X X\n",
      "      7: @column 2\n",
      "      8: 1. 3(N14) X SANGA~a? [...]\n"
     ]
    }
   ],
   "source": [
    "transObject(firstTablet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know the *P-number*, we can get the tablet with that P-number by means of\n",
    "`T.nodeFromSection()`.\n",
    "\n",
    "You pass this function a tuple, representing *tablet*, *column*, *line*, and it gives you back\n",
    "the node of the corresponding object.\n",
    "\n",
    "*column* and *line* are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:22.521047Z",
     "start_time": "2018-02-20T21:14:22.504600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147196"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabletId = 'P471695'\n",
    "tabletNode = T.nodeFromSection((tabletId,))\n",
    "tabletNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the transcription of this tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:24.438706Z",
     "start_time": "2018-02-20T21:14:24.423413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     87: &P471695 = Anonymous 0712 \n",
      "     88: #atf: lang qpc \n",
      "     90: @obverse \n",
      "     91: @column 1\n",
      "     92: 1.a. 3(N01) , APIN~a 3(N57) UR4~a \n",
      "     93: 1.b1. , (EN~a DU ZATU759)a \n",
      "     94: 1.b2. , (BAN~b KASZ~c)a \n",
      "     95: 1.b3. , (KI@n SAG)a \n",
      "     96: 2.a. 1(N14) 2(N01) , [...] \n",
      "     97: 2.b1. , (3(N57) PAP~a)a \n",
      "     98: 2.b2. , (SZU KI X)a \n",
      "     99: $ n lines broken  \n",
      "    100: 2.b3'. , (EN~a AN EZINU~d)a \n",
      "    101: 2.b4'. , (IDIGNA [...])a \n",
      "    102: $ rest broken \n",
      "    103: $ (for a total of 12 sub-cases with PNN) \n",
      "    104: @column 2\n",
      "    105: 1.a. 1(N01) , ISZ~a#? \n",
      "    106: 1.b1. , (PAP~a GIR3~c)a\n",
      "    107: $ blank space \n",
      "    108: $ rest broken \n",
      "    109: @reverse \n",
      "    110: $ beginning broken \n",
      "    111: 1'. [1(N14)] 6(N01)# , [...] \n",
      "    111: 1'. [1(N14)] 6(N01)# , [...] \n"
     ]
    }
   ],
   "source": [
    "transObject(tabletNode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphemes\n",
    "\n",
    "`F`\n",
    "gives access to all features.\n",
    "Every feature has a method\n",
    "`freqList()`\n",
    "to generate a frequency list of its values, higher frequencies first.\n",
    "Here are the graphemes (the top 20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:26.440773Z",
     "start_time": "2018-02-20T21:14:26.343309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29618 x …\n",
      "21676 x N01\n",
      "17307 x \n",
      " 6956 x X\n",
      " 5924 x N14\n",
      " 1970 x EN\n",
      " 1846 x N57\n",
      " 1835 x N34\n",
      " 1349 x SZE\n",
      " 1241 x GAL\n",
      " 1125 x DUG\n",
      " 1069 x AN\n",
      " 1046 x U4\n",
      "  892 x NUN\n",
      "  881 x SAL\n",
      "  879 x PAP\n",
      "  877 x E2\n",
      "  875 x GI\n",
      "  788 x BA\n",
      "  747 x SANGA\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.grapheme.freqList()[0:20]:\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a bit more: we'll write a file with all graphemes to your TEMP_DIR.\n",
    "In fact, we'll write two: one ordered by grapheme, and one ordered by frequency.\n",
    "\n",
    "In order to not clutter this notebook, we use a function `writeFreqs()`, defined in \n",
    "[utils](utils.py) in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:28.355127Z",
     "start_time": "2018-02-20T21:14:28.262968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 673 bare graphemes\n"
     ]
    }
   ],
   "source": [
    "COMP.writeFreqs('grapheme-plain', F.grapheme.freqList(), 'bare grapheme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a look at your TEMP_DIR and you see two generated files:\n",
    "\n",
    "* `graphemes-plain-alpha.txt` (sorted by grapheme)\n",
    "* `graphemes-plain-freq.txt` (sorted by frequency)\n",
    "\n",
    "But we can do better, we also want the prime, variants, and modifiers taken into account.\n",
    "\n",
    "Let us first see what they can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prime\n",
    "\n",
    "The prime is a feature with two values: 1 or 0. 1 means: there is a prime.\n",
    "Below you see how often that occurs.\n",
    "Note that we count all primes here: on signs, case numbers and column numbers.\n",
    "\n",
    "For more info and a check on the occurrences of primes, see [checks](checks.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:32.148956Z",
     "start_time": "2018-02-20T21:14:32.132229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5184 x 1\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.prime.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant\n",
    "\n",
    "The variant or allograph is what occurs after the grapheme and after the `~` symbol, which should be digits and/or\n",
    "lowercase letters except the `x`.\n",
    "\n",
    "Here is the frequency list of variant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:34.181605Z",
     "start_time": "2018-02-20T21:14:34.150164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23843 x a\n",
      " 4214 x b\n",
      " 1534 x c\n",
      " 1356 x a1\n",
      "  703 x b1\n",
      "  194 x a2\n",
      "  191 x d\n",
      "  127 x b2\n",
      "   85 x f\n",
      "   73 x a3\n",
      "   40 x e\n",
      "   29 x c2\n",
      "   22 x c1\n",
      "   22 x c3\n",
      "   14 x c5\n",
      "   13 x b3\n",
      "   12 x a0\n",
      "   12 x d1\n",
      "   12 x v\n",
      "   11 x c4\n",
      "    6 x a4\n",
      "    6 x g\n",
      "    5 x d2\n",
      "    4 x d4\n",
      "    4 x h\n",
      "    2 x 3a\n",
      "    2 x d3\n",
      "    1 x h2\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.variant.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifier\n",
    "\n",
    "The modifier is what occurs after the grapheme and after the `@` symbol, which should be digits and/or\n",
    "lowercase letters except the `x`.\n",
    "\n",
    "Here is the frequency list of *modifier* and *rmodifier* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:36.150597Z",
     "start_time": "2018-02-20T21:14:36.133975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  648 x g\n",
      "  251 x t\n",
      "   39 x n\n",
      "    6 x r\n",
      "    4 x s\n",
      "    1 x c\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifier.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:36.170140Z",
     "start_time": "2018-02-20T21:14:36.153900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 x f\n",
      "   15 x t\n",
      "    1 x r\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.rmodifier.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full grapheme overview\n",
    "\n",
    "We make a frequency list of all full graphemes, i.e. the grapheme including variant, modifier, and prime.\n",
    "We show as they appear in transcriptions.\n",
    "\n",
    "First we show on what node types primes, variants and modifiers occur.\n",
    "We only deal with cases where they occur on signs, ignoring the cases where they occur on (sub)quads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:39.513305Z",
     "start_time": "2018-02-20T21:14:38.137632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prime     :  4652 x case\n",
      "prime     :   523 x column\n",
      "prime     :     9 x sign\n",
      "variant   : 32450 x sign\n",
      "variant   :    87 x quad\n",
      "modifier  :   950 x sign\n"
     ]
    }
   ],
   "source": [
    "for feature in ('prime', 'variant', 'modifier'):\n",
    "    nodeTypes = collections.Counter()\n",
    "    for n in N():\n",
    "        if Fs(feature).v(n):\n",
    "            nodeTypes[F.otype.v(n)] += 1\n",
    "    for (value, frequency) in nodeTypes.items():\n",
    "        print(f'{feature:<10}: {frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the full graphemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:40.705725Z",
     "start_time": "2018-02-20T21:14:40.111326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29618 x …\n",
      "17307 x \n",
      "12995 x 1(N01)\n",
      " 6956 x X\n",
      " 3081 x 2(N01)\n",
      " 2606 x 1(N14)\n",
      " 1849 x EN~a\n",
      " 1603 x 3(N01)\n",
      " 1357 x 2(N14)\n",
      " 1308 x SZE~a\n",
      " 1304 x 5(N01)\n",
      " 1224 x GAL~a\n",
      " 1119 x 4(N01)\n",
      " 1069 x AN\n",
      " 1045 x U4\n",
      " 1001 x 1(N34)\n",
      "  881 x SAL\n",
      "  874 x GI\n",
      "  854 x PAP~a\n",
      "  801 x 1(N57)\n",
      "There are 1530 full graphemes\n"
     ]
    }
   ],
   "source": [
    "fullGraphemes = collections.Counter()\n",
    "\n",
    "for n in F.otype.s('sign'):\n",
    "    fullGrapheme = COMP.strFromSign(n)\n",
    "    fullGraphemes[fullGrapheme] += 1\n",
    "    \n",
    "for (value, frequency) in sorted(fullGraphemes.items(), key=lambda x: (-x[1], x[0]))[0:20]:\n",
    "    print(f'{frequency:>5} x {value}')\n",
    "    \n",
    "COMP.writeFreqs('grapheme-full', fullGraphemes.items(), 'full grapheme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge features: left and right\n",
    "\n",
    "We have not talked about edges much. If the nodes correspond to the rows in the big spreadsheet,\n",
    "the edges point from one row to another.\n",
    "\n",
    "One edge we have encountered: the special feature `oslots`.\n",
    "Each non-slot node is linked by `oslots` to all of its slot nodes.\n",
    "\n",
    "An edge is really a feature as well.\n",
    "Whereas a node feature is a column of information,\n",
    "one cell per node, \n",
    "an edge feature is also a column of information, one cell per pair of nodes.\n",
    "\n",
    "In the tablets quads may be subdivided into subquads and signs, related by operators.\n",
    "If there is an operator *op* between `qLeft` and `qRight`, there is an \n",
    "edge between `qLeft` and `qRight` with feature `op` having value *op*.\n",
    "\n",
    "And if a quad is the result of an operator working on operands, which are sub-*quads* or *signs*,\n",
    "there will be edges between the big quad and its operands with feature `sub`, having no value.\n",
    "\n",
    "Likewise, there will be edges between *lines* and *cases* and their subcases, also\n",
    "having feature `sub` with no value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "By now you have an impression how to compute around in the Hebrew Bible.\n",
    "While this is still the beginning, I hope you already sense the power of unlimited programmatic access\n",
    "to all the bits and bytes in the data set.\n",
    "\n",
    "Here are a few directions for unleashing that power.\n",
    "\n",
    "## Search\n",
    "Text-Fabric contains a flexible search engine, that does not only work for the BHSA data,\n",
    "but also for data that you add to it.\n",
    "There is a tutorial dedicated to [search](search.ipynb).\n",
    "And if you already know MQL queries, you can build from that in\n",
    "[searchFromMQL](searchFromMQL.ipynb).\n",
    "\n",
    "## Explore additional data\n",
    "The ETCBC has a few other repositories with data that work in conjunction with the BHSA data.\n",
    "One of them you have already seen: \n",
    "[phono](https://github.com/ETCBC/phono),\n",
    "for phonetic transcriptions.\n",
    "\n",
    "There is also\n",
    "[parallels](https://github.com/ETCBC/parallels)\n",
    "for detecting parallel passages,\n",
    "and\n",
    "[valence](https://github.com/ETCBC/valence)\n",
    "for studying patterns around verbs that determine their meanings.\n",
    "\n",
    "## Add your own data\n",
    "If you study the additional data, you can observe how that data is created and also\n",
    "how it is turned into a text-fabric data module.\n",
    "The last step is incredibly easy. You can write out every Python dictionary where the keys are numbers\n",
    "and the values string or numbers as a Text-Fabric feature.\n",
    "When you are creating data, you have already constructed those dictionaries, so writing\n",
    "them out is just one method call.\n",
    "See for example how the\n",
    "[flowchart](https://github.com/ETCBC/valence/blob/master/programs/flowchart.ipynb#Add-sense-feature-to-valence-module)\n",
    "notebook in valence writes out verb sense data.\n",
    "![flow](images/valence.png)\n",
    "\n",
    "You can then easily share your new features on GitHub, so that your colleagues everywhere \n",
    "can try it out for themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Emdros MQL\n",
    "\n",
    "[EMDROS](http://emdros.org), written by Ulrik Petersen,\n",
    "is a text database system with the powerful *topographic* query language MQL.\n",
    "The ideas are based on a model devised by Christ-Jan Doedens in\n",
    "[Text Databases: One Database Model and Several Retrieval Languages](https://books.google.nl/books?id=9ggOBRz1dO4C).\n",
    "\n",
    "Text-Fabric's model of slots, nodes and edges is a fairly straightforward translation of the models of Christ-Jan Doedens and Ulrik Petersen.\n",
    "\n",
    "[SHEBANQ](https://shebanq.ancient-data.org) uses EMDROS to offer users to execute and save MQL queries against the Hebrew Text Database of the ETCBC.\n",
    "\n",
    "So it is kind of logical and convenient to be able to work with a Text-Fabric resource through MQL.\n",
    "\n",
    "If you have obtained an MQL dataset somehow, you can turn it into a text-fabric data set by `importMQL()`,\n",
    "which we will not show here.\n",
    "\n",
    "And if you want to export a Text-Fabric data set to MQL, that is also possible.\n",
    "\n",
    "After the `Fabric(modules=...)` call, you can call `exportMQL()` in order to save all features of the\n",
    "indicated modules into a big MQL dump, which can be imported by an EMDROS database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clean caches\n",
    "\n",
    "Text-Fabric pre-computes data for you, so that it can be loaded faster.\n",
    "If the original data is updated, Text-Fabric detects it, and will recompute that data.\n",
    "\n",
    "But there are cases, when the algorithms of Text-Fabric have changed, without any changes in the data, that you might\n",
    "want to clear the cache of precomputed results.\n",
    "\n",
    "There are two ways to do that:\n",
    "\n",
    "* Locate the `.tf` directory of your dataset, and remove all `.tfx` files in it.\n",
    "  This might be a bit awkward to do, because the `.tf` directory is hidden on Unix-like systems.\n",
    "* Call `TF.clearCache()`, which does exactly the same.\n",
    "\n",
    "It is not handy to execute the following cell all the time, that's why I have commented it out.\n",
    "So if you really want to clear the cache, remove the comment sign below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:48.202043Z",
     "start_time": "2018-02-20T21:14:48.189363Z"
    }
   },
   "outputs": [],
   "source": [
    "# TF.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
