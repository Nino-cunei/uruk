{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Text-Fabric\" data-toc-modified-id=\"Text-Fabric-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Text-Fabric</a></span></li><li><span><a href=\"#Cuneiform-tablets-in-ATF\" data-toc-modified-id=\"Cuneiform-tablets-in-ATF-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Cuneiform tablets in ATF</a></span><ul class=\"toc-item\"><li><span><a href=\"#Provenance\" data-toc-modified-id=\"Provenance-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Provenance</a></span></li></ul></li><li><span><a href=\"#Why-Text-Fabric?\" data-toc-modified-id=\"Why-Text-Fabric?-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Why Text-Fabric?</a></span></li></ul></li><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#More-information\" data-toc-modified-id=\"More-information-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>More information</a></span></li><li><span><a href=\"#Installing-Text-Fabric\" data-toc-modified-id=\"Installing-Text-Fabric-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Installing Text-Fabric</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prerequisites\" data-toc-modified-id=\"Prerequisites-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Prerequisites</a></span></li><li><span><a href=\"#TF-itself\" data-toc-modified-id=\"TF-itself-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>TF itself</a></span></li><li><span><a href=\"#Get-the-data\" data-toc-modified-id=\"Get-the-data-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Get the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tip\" data-toc-modified-id=\"Tip-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Tip</a></span></li></ul></li></ul></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#A-tour-around-the-TF-API\" data-toc-modified-id=\"A-tour-around-the-TF-API-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>A tour around the TF API</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sections:-tablet---column---line\" data-toc-modified-id=\"Sections:-tablet---column---line-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Sections: tablet - column - line</a></span></li><li><span><a href=\"#Navigation\" data-toc-modified-id=\"Navigation-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Navigation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Source-lines\" data-toc-modified-id=\"Source-lines-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Source lines</a></span></li><li><span><a href=\"#Source-lines:-refined\" data-toc-modified-id=\"Source-lines:-refined-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Source lines: refined</a></span></li><li><span><a href=\"#Lines-and-cases\" data-toc-modified-id=\"Lines-and-cases-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Lines and cases</a></span></li><li><span><a href=\"#Line-numbers\" data-toc-modified-id=\"Line-numbers-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;</span>Line numbers</a></span></li></ul></li><li><span><a href=\"#Deep-cases\" data-toc-modified-id=\"Deep-cases-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Deep cases</a></span><ul class=\"toc-item\"><li><span><a href=\"#Measuring-the-depth-of-a-structure.\" data-toc-modified-id=\"Measuring-the-depth-of-a-structure.-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;</span>Measuring the depth of a structure.</a></span></li></ul></li></ul></li><li><span><a href=\"#Mass-operations\" data-toc-modified-id=\"Mass-operations-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Mass operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Walking-all-nodes\" data-toc-modified-id=\"Walking-all-nodes-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Walking all nodes</a></span></li><li><span><a href=\"#All-signs\" data-toc-modified-id=\"All-signs-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>All signs</a></span></li><li><span><a href=\"#Particular-signs\" data-toc-modified-id=\"Particular-signs-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Particular signs</a></span></li><li><span><a href=\"#From-instance-to-context\" data-toc-modified-id=\"From-instance-to-context-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>From instance to context</a></span></li><li><span><a href=\"#Frequency-list\" data-toc-modified-id=\"Frequency-list-7.5\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>Frequency list</a></span></li></ul></li><li><span><a href=\"#Structures\" data-toc-modified-id=\"Structures-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Structures</a></span><ul class=\"toc-item\"><li><span><a href=\"#Quads\" data-toc-modified-id=\"Quads-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Quads</a></span><ul class=\"toc-item\"><li><span><a href=\"#Getting-a-big-quad\" data-toc-modified-id=\"Getting-a-big-quad-8.1.1\"><span class=\"toc-item-num\">8.1.1&nbsp;&nbsp;</span>Getting a big quad</a></span></li><li><span><a href=\"#Unraveling-a-quad\" data-toc-modified-id=\"Unraveling-a-quad-8.1.2\"><span class=\"toc-item-num\">8.1.2&nbsp;&nbsp;</span>Unraveling a quad</a></span></li><li><span><a href=\"#Collecting-quads-by-depth\" data-toc-modified-id=\"Collecting-quads-by-depth-8.1.3\"><span class=\"toc-item-num\">8.1.3&nbsp;&nbsp;</span>Collecting quads by depth</a></span></li><li><span><a href=\"#Distribution-of-quads-by-depth\" data-toc-modified-id=\"Distribution-of-quads-by-depth-8.1.4\"><span class=\"toc-item-num\">8.1.4&nbsp;&nbsp;</span>Distribution of quads by depth</a></span></li></ul></li><li><span><a href=\"#Clusters\" data-toc-modified-id=\"Clusters-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Clusters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Kinds-of-clusters\" data-toc-modified-id=\"Kinds-of-clusters-8.2.1\"><span class=\"toc-item-num\">8.2.1&nbsp;&nbsp;</span>Kinds of clusters</a></span></li><li><span><a href=\"#Lengths-of-clusters\" data-toc-modified-id=\"Lengths-of-clusters-8.2.2\"><span class=\"toc-item-num\">8.2.2&nbsp;&nbsp;</span>Lengths of clusters</a></span></li></ul></li></ul></li><li><span><a href=\"#Signs\" data-toc-modified-id=\"Signs-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Signs</a></span><ul class=\"toc-item\"><li><span><a href=\"#Writing-results-to-file\" data-toc-modified-id=\"Writing-results-to-file-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Writing results to file</a></span></li><li><span><a href=\"#Prime\" data-toc-modified-id=\"Prime-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Prime</a></span></li><li><span><a href=\"#Variant\" data-toc-modified-id=\"Variant-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Variant</a></span></li><li><span><a href=\"#Modifier\" data-toc-modified-id=\"Modifier-9.4\"><span class=\"toc-item-num\">9.4&nbsp;&nbsp;</span>Modifier</a></span></li><li><span><a href=\"#Full-grapheme-overview\" data-toc-modified-id=\"Full-grapheme-overview-9.5\"><span class=\"toc-item-num\">9.5&nbsp;&nbsp;</span>Full grapheme overview</a></span></li></ul></li><li><span><a href=\"#Representation\" data-toc-modified-id=\"Representation-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Representation</a></span></li><li><span><a href=\"#Collation\" data-toc-modified-id=\"Collation-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Collation</a></span><ul class=\"toc-item\"><li><span><a href=\"#TF-ad\" data-toc-modified-id=\"TF-ad-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>TF ad</a></span></li><li><span><a href=\"#Back-to-collation\" data-toc-modified-id=\"Back-to-collation-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>Back to collation</a></span></li><li><span><a href=\"#Collect-sign-pairs\" data-toc-modified-id=\"Collect-sign-pairs-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;</span>Collect sign-pairs</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "This notebook gets you started with using\n",
    "[Text-Fabric](https://github.com/Dans-labs/text-fabric) for coding in cuneiform tablet transcriptions.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Text-Fabric\n",
    "\n",
    "Text-Fabric is a model for textual data with annotations that is optimized for efficient data analysis. Not only that, it also facilitates the creation of new, derived data, which can be added to the original data.\n",
    "Data combination is a feature of Text-Fabric.\n",
    "\n",
    "Text-Fabric is being used for the\n",
    "[Hebrew Bible](https://github.com/ETCBC/bhsa)\n",
    "and a large body of linguisitic annotations on top of it. The researchers of the \n",
    "[ETCBC](http://etcbc.nl) thought that a plain database is not a satisfactory text model,\n",
    "and that XML is too limited too express multiple hierarchies in a text smoothly.\n",
    "\n",
    "That's why they adopted a model by\n",
    "[Doedens](http://books.google.nl/books?id=9ggOBRz1dO4C)\n",
    "that reflects more of the essential properties of text (sequence, embedding). This model is the basis of MQL, a working text-database system.\n",
    "Text-Fabric is based on the same\n",
    "[model](https://github.com/Dans-labs/text-fabric/wiki/Data-model),\n",
    "and once the data is in Text-Fabric, it can be exported to MQL.\n",
    "\n",
    "See more on the effort of modeling the Hebrew Bible in Dirk's article\n",
    "[The Hebrew Bible as Data: Laboratory - Sharing - Experiences](https://doi.org/10.5334/bbi.18)\n",
    "\n",
    "With data in Text-Fabric, it becomes possible to build rich online interfaces on the data of ancient texts.\n",
    "For the Hebrew Bible, we have built\n",
    "[SHEBANQ](https://shebanq.ancient-data.org).\n",
    "\n",
    "Working with TF is a bit like buying from IKEA. You get your product in bits and pieces, and you assemble it yourself. TF decomposes any dataset into its components, nicely stacked per component, with every component uniquely labeled. You go to the store, make your selection, enter the warehouse, collect your parts, and, at home, assemble your product.\n",
    "\n",
    "In order to enjoy an IKEA product, you do not need to be a craftsman, but you do need to be able to handle a screw driver.\n",
    "\n",
    "In the TF world, it is the same. You do not have to be a professional programmer, but you do need to be able to program little things. A first course in Python is enough.\n",
    "\n",
    "Another parallel: in IKEA you take a package with components home, and there you assemble it. \n",
    "In TF it is likewise: you download the TF data, and then you write a little program. Inside that program you can call up the Text-Fabric tool, which act as the IKEA user manual. But your program takes control, not Text-Fabric.\n",
    "\n",
    "The best environment to enjoy Text-Fabric is in Python programs that you develop in a \n",
    "[Jupyter Notebook](http://jupyter.readthedocs.io/en/latest/).\n",
    "This tutorial is such a notebook. If you are reading it online, you see text bits and code bits,\n",
    "but you cannot execute the code bits.\n",
    "\n",
    "If you download this tutorial, and you have installed Python, Jupyter, and Text-Fabric,\n",
    "you can *execute* the code bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuneiform tablets in ATF\n",
    "\n",
    "Cuneiform tablets have been transcribed in ATF files, in which the marks on a tablet are represented\n",
    "by ascii characters. The marks on a tablet have structure (they can be composed, they build cases and lines) and properties (they can be uncertain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"images/P005381-obverse-photo.png\" width=\"25%\"/>\n",
    "<img align=\"left\" src=\"images/P005381-obverse-lineart.png\" width=\"25%\"/>\n",
    "```\n",
    "&P005381 = MSVO 3, 70\n",
    "#version: 0.1\n",
    "#atf: lang qpc\n",
    "```\n",
    "<img align=\"right\" src=\"images/P005381-obverse-atf.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"images/P005381-reverse-photo.png\" width=\"25%\"/>\n",
    "<img align=\"left\" src=\"images/P005381-reverse-lineart.png\" width=\"25%\"/>\n",
    "<img align=\"right\" src=\"images/P005381-reverse-atf.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Obverse* and *reverse* face of tablet\n",
    "[P005381](https://cdli.ucla.edu/search/search_results.php?SearchMode=Text&ObjectID=P005381). \n",
    "\n",
    ">Authors: Robert K. Englund and Peter Damerow\n",
    "\n",
    ">Transcription by Robert K. Englund\n",
    "\n",
    ">UCLA Library ARK\t21198/zz001q057f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provenance\n",
    "\n",
    "We have taken a corpus of ca. 6000 tablets, from the\n",
    "[Uruk-III/IV period](http://cdli.ox.ac.uk/wiki/doku.php?id=proto-cuneiform)\n",
    "(4000-3100 BC).\n",
    "These tablets are *proto-cuneiform*, \n",
    "\n",
    "We have downloaded the transcriptions from the \n",
    "**Cuneiform Digital Library Initiative**\n",
    "[CDLI](https://cdli.ucla.edu),\n",
    "and converted them to Text-Fabric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Text-Fabric?\n",
    "When you search for tablet data in an ATF file, you can do so conveniently by using regular expressions.\n",
    "\n",
    "However, the ATF transcriptions have become packed with information. Not every transcriber uses ATF in the same way, and there are a few coding errors in the sources.\n",
    "\n",
    "That means that the most obvious search expressions will leave out cases. Either you live with that, or you refine your search expressions.\n",
    "\n",
    "An other issue is, that when you look for something, your search expressions must reflect the shape of not\n",
    "only your target, but also everything else. There is virtually no separation of concerns.\n",
    "\n",
    "When your search task becomes complicated, your mind tends to get overloaded with the details of the transcription format, rather than with the quest you would like to have in mind.\n",
    "\n",
    "You also want to be able to divide a research task into smaller chunks.\n",
    "Whereas regular expressions are a wonderful tool to look for patterns, on their own they fall short\n",
    "when your search involves nested structures, intermediate sets of patterns, special functions.\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "* we tell you how to get Text-Fabric on your system;\n",
    "* we tell you how to get a set of cuneiform tablet transcriptions on your system;\n",
    "* we make a tour, showing how to use the data;\n",
    "* we add a real world exercise in collocation.\n",
    "\n",
    "## More information\n",
    "Chances are that a bit of reading about the underlying\n",
    "[data model](https://github.com/Dans-labs/text-fabric/wiki/Data-model)\n",
    "helps you to follow the exercises below, and vice versa.\n",
    "\n",
    "We have checked the conversion from the transcriptions to Text-Fabric extensively.\n",
    "Cruelly, you might say. You can follow the checks\n",
    "in a separate notebook [checks](checks.ipynb).\n",
    "\n",
    "A handy feature reference is in the [docs](https://github.com/Dans-labs/Nino-cunei/blob/master/docs/transcription.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Text-Fabric\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "You need to have Python on your system. Most systems have it out of the box,\n",
    "but alas, that is python2 and we need at least python 3.6.\n",
    "\n",
    "Install it from [python.org]() or from [Anaconda]().\n",
    "If you got it from python.org, you also have to install [Jupyter]().\n",
    "\n",
    "### TF itself\n",
    "\n",
    "```\n",
    "pip install text-fabric\n",
    "```\n",
    "\n",
    "if you have installed Python with the help of Anaconda, or\n",
    "\n",
    "```\n",
    "sudo -H pip3 install text-fabric\n",
    "```\n",
    "if you have installed Python from [python.org](https://www.python.org).\n",
    "\n",
    "###### Execute: If all this is done, the following cells can be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:33:20.994069Z",
     "start_time": "2018-02-26T20:33:20.967153Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:33:21.828913Z",
     "start_time": "2018-02-26T20:33:21.801834Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, collections\n",
    "from tf.fabric import Fabric\n",
    "from tf.cunei import Cunei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "\n",
    "You can get all data needed for this tutorial\n",
    "from GitHub as follows.\n",
    "\n",
    "We suggest you make an appropriate directory in your home directory:\n",
    "\n",
    "```\n",
    "github/Dans-labs\n",
    "```\n",
    "\n",
    "then go to that directory in a terminal, and then say\n",
    "\n",
    "```\n",
    "git clone https://github.com/Dans-labs/Nino-cunei\n",
    "```\n",
    "\n",
    "After that your directory structure shold look like this:\n",
    "\n",
    "    your home direcectory\\\n",
    "    |                     - github\\\n",
    "    |                       |      - Dans-labs\\\n",
    "    |                       |        |         - Nino-cunei\n",
    "    \n",
    "#### Tip\n",
    "If you start computing with this tutorial, first copy its parent directory to somewhere else,\n",
    "outside your `Nino-cunei` directory.\n",
    "If you pull changes from the `Nino-cunei` repository later, your work will not be overwritten.\n",
    "Where you put your tutorial directory is up till you.\n",
    "It will work from any directory.\n",
    "\n",
    "###### Execute: it this has been done, you can execute the next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:33:24.520332Z",
     "start_time": "2018-02-26T20:33:24.489814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.2.1\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "33 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "REPO = '~/github/Dans-labs/Nino-cunei'\n",
    "SOURCE = 'uruk'\n",
    "VERSION = '0.1'\n",
    "CORPUS = f'{REPO}/tf/{SOURCE}/{VERSION}'\n",
    "SOURCE_DIR = os.path.expanduser(f'{REPO}/sources/cdli')\n",
    "TEMP_DIR = os.path.expanduser(f'{REPO}/_temp')\n",
    "REPORT_DIR = os.path.expanduser(f'{REPO}/reports')\n",
    "TF = Fabric(locations=[CORPUS], modules=[''], silent=False )\n",
    "\n",
    "for cdir in (TEMP_DIR, REPORT_DIR):\n",
    "    os.makedirs(cdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "The transcriptions of the tablets in their TF form is organized in a model of nodes, edges and features.\n",
    "\n",
    "The things such as tablets, faces, columns, cases, and, at the most basic level, signs, are numbered.\n",
    "The signs correspond to number 1 ... ca. 120,000, in the same order as they occur in the corpus.\n",
    "All other things are built from signs. They have number from ca 120,000 to 450,000.\n",
    "\n",
    "In TF, we call these numbers *nodes*. Like a barcode, this number gives access to a whole bunch of\n",
    "information about the corresponding object.\n",
    "\n",
    "For example, lines have a property (in TF we call it a *feature*) called `fullNumber`. \n",
    "It contains the hierarchical number found at the start of the line in the transcription.\n",
    "\n",
    "If the node for a line is `n`, we can find its hierarchical number by saying\n",
    "\n",
    "```\n",
    "F.fullNumber.v(n)\n",
    "```\n",
    "\n",
    "In words, it reads as:\n",
    "\n",
    "* `F`: I want to look up a `F`eature\n",
    "* `fullNumber`: the name of the feature\n",
    "* `.v`: I want the value of that feature\n",
    "* `(n)`: for the given node `n`\n",
    "\n",
    "Seen in this way, the data is like a gigantic spreadsheet of 450,000 rows (the nodes),\n",
    "with 30 columns (the features).\n",
    "\n",
    "There is a bit more to it, since the nodes can be grouped together in ways we will see later on.\n",
    "\n",
    "###### Execute: the next cell loads most features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:33:32.572745Z",
     "start_time": "2018-02-26T20:33:31.493345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.00s B catalogId            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B fullNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B number               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.06s B grapheme             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.05s B srcLn                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.03s B srcLnNum             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B prime                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B repeat               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B variant              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B variantOuter         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifier             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierInner        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierFirst        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B damage               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B uncertain            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B remarkable           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B written              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B kind                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B period               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B name                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B type                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B identifier           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B origNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B badNumbering         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B crossref             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B text                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B op                   from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.10s B sub                  from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B comments             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s Feature overview: 28 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  1.06s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    grapheme prime repeat\n",
    "    variant variantOuter\n",
    "    modifier modifierInner modifierFirst\n",
    "    damage uncertain remarkable written\n",
    "    kind\n",
    "    period name type identifier catalogId\n",
    "    number fullNumber origNumber badNumbering\n",
    "    crossref text\n",
    "    srcLn srcLnNum\n",
    "    op sub comments''')\n",
    "api.makeAvailableIn(globals())\n",
    "CUNEI = Cunei(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A tour around the TF API\n",
    "\n",
    "We have the data of over 6000 tablets at our fingertips now. But how can we see it?\n",
    "In a meaningful way?\n",
    "\n",
    "The following tour shows you the most important parts of the Text-Fabric API.\n",
    "It is a set of functions, defined in the TF package, that you can use in your own program.\n",
    "\n",
    "This notebook itself is our current program, and we have just loaded the API.\n",
    "\n",
    "See in the next cells how we navigate to the tablets we want and pick our data from them.\n",
    "\n",
    "The full API-reference documentation is available on the\n",
    "[Text-Fabric wiki](https://github.com/Dans-labs/text-fabric/wiki/Api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sections: tablet - column - line\n",
    "\n",
    "Let's start with just a single, specific tablet P448702.\n",
    "\n",
    "Here is its transcription, copied from the CDLI source.\n",
    "\n",
    "```\n",
    "&P448702 = www archaeo-auction 004 \n",
    "#atf: lang qpc \n",
    "@tablet \n",
    "@obverse \n",
    "@column 1 \n",
    "$ beginning broken \n",
    "1'. [n] , [...] KA~a \n",
    "2.a'. [n] 2(N14) 3(N01) , KASZ~b NUN~a \n",
    "2.b'. 3(N01) , KASZ~a? GI \n",
    "3'. [n] 6(N14)#? 4(N01) 2(N39~a) , X [...] \n",
    "@column 2 \n",
    "$ beginning broken \n",
    "$ blank space \n",
    "1'. , U4 |U4x1(N01)| SUKUD@inversum? NA \n",
    "@column 3 \n",
    "$ beginning broken \n",
    "$ blank space \n",
    "@reverse \n",
    "$ (not imaged) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a node for this tablet. How do we find it?\n",
    "\n",
    "The easiest way is to ask TF to find the node on the basis of a section specification.\n",
    "\n",
    "When we converted the transcriptions to TF, we made it so that tablets are the first\n",
    "section level, columns the second, and lines the third. \n",
    "\n",
    "In order to find the node corresponding to a section, we have to give a tuple\n",
    "`(tabletName, columnNumber, lineNumber)` to the appropriate function in TF.\n",
    "\n",
    "Here you may leave out `lineNumber` (to specify a column), or both `columnNumber` and `lineNumber` \n",
    "(to specify a tablet).\n",
    "The latter is our case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:33:44.320334Z",
     "start_time": "2018-02-26T20:33:44.295224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justATablet = T.nodeFromSection(('P448702',))\n",
    "justATablet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is the node, the barcode, as it were. It gives you access to all data we have stored of this\n",
    "tablet.\n",
    "\n",
    "One of the things we have stored for tablets, columns, and lines, is the original transcription line.\n",
    "Let's retrieve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:33:57.447562Z",
     "start_time": "2018-02-26T20:33:57.431067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&P448702 = www archaeo-auction 004 '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.srcLn.v(justATablet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the source line of the tablet header.\n",
    "How do we get the other source lines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigation\n",
    "\n",
    "We'll need another concept first.\n",
    "Things on a tablet have spatial relationships. \n",
    "While the transcriptions abstract from the physical relationships, there are still a few\n",
    "important ones left: sequence and embedding.\n",
    "\n",
    "At the most basic level we have signs. \n",
    "For all other levels, TF knows exactly which signs are part of the objects of those levels.\n",
    "\n",
    "And based on that knowledge, we can travel from objects to the objects embedded in it, and back,\n",
    "and to the right and left siblings.\n",
    "\n",
    "All these functions start with `L.`, and they take a starting node as argument.\n",
    "\n",
    "* `L.d()` goes \"down\": from enbedder to embeddee;\n",
    "* `L.u()` goes \"up\": from embeddee to embedder;\n",
    "* `L.p()` goes \"previous\": to the first left sibling;\n",
    "* `L.n()` goes \"next\": to the first right sibling.\n",
    "\n",
    "We can now find all the nodes contained in the example tablet.\n",
    "When we retrieve them, we also fetch their *type*: is it a face, a column, a sign?\n",
    "The type of a node is stored in the feature `otype`. \n",
    "This feature is so central to the TF model that every TF dataset has it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:01.183520Z",
     "start_time": "2018-02-26T20:34:01.160938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180739 of type comment\n",
      "    56 of type sign\n",
      "157262 of type face\n",
      "166709 of type column\n",
      "180740 of type comment\n",
      "    57 of type sign\n",
      "229518 of type line\n",
      "266443 of type case\n",
      "196542 of type cluster\n",
      "    58 of type sign\n",
      "196543 of type cluster\n",
      "    59 of type sign\n",
      "    60 of type sign\n",
      "229519 of type line\n",
      "266444 of type case\n",
      "266445 of type case\n",
      "196544 of type cluster\n",
      "    61 of type sign\n",
      "    62 of type sign\n",
      "    63 of type sign\n",
      "    64 of type sign\n",
      "    65 of type sign\n",
      "266446 of type case\n",
      "266447 of type case\n",
      "    66 of type sign\n",
      "    67 of type sign\n",
      "    68 of type sign\n",
      "229520 of type line\n",
      "266448 of type case\n",
      "196545 of type cluster\n",
      "    69 of type sign\n",
      "    70 of type sign\n",
      "    71 of type sign\n",
      "    72 of type sign\n",
      "    73 of type sign\n",
      "196546 of type cluster\n",
      "    74 of type sign\n",
      "166710 of type column\n",
      "180741 of type comment\n",
      "    75 of type sign\n",
      "180742 of type comment\n",
      "    76 of type sign\n",
      "229521 of type line\n",
      "266449 of type case\n",
      "    77 of type sign\n",
      "146957 of type quad\n",
      "    78 of type sign\n",
      "    79 of type sign\n",
      "    80 of type sign\n",
      "    81 of type sign\n",
      "166711 of type column\n",
      "180743 of type comment\n",
      "    82 of type sign\n",
      "180744 of type comment\n",
      "    83 of type sign\n",
      "    84 of type sign\n",
      "157263 of type face\n",
      "180745 of type comment\n",
      "    85 of type sign\n",
      "    86 of type sign\n"
     ]
    }
   ],
   "source": [
    "for child in L.d(justATablet):\n",
    "    print(f'{child:>6} of type {F.otype.v(child)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note:\n",
    "\n",
    "* the numbers are not really important to us, only to the program;\n",
    "  soon, we will stop showing them altogether;\n",
    "* the order in which the nodes are delivered, is a natural one:\n",
    "  1. first things first, and \n",
    "  2. bigger things before the smaller things they contain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source lines\n",
    "\n",
    "So in order to find all the source lines of this tablet, we can just take all these nodes,\n",
    "see whether they have a value for feature *srcLn*, retrieve it, an print it.\n",
    "\n",
    "Let's do it, and write this as a function, i.e. a recipe that we can apply to every tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:05.757124Z",
     "start_time": "2018-02-26T20:34:05.738466Z"
    }
   },
   "outputs": [],
   "source": [
    "def getSource(tablet):\n",
    "    sourceLines = []\n",
    "    sourceLines.append(F.srcLn.v(tablet))\n",
    "    for child in L.d(tablet):\n",
    "        sourceLine = F.srcLn.v(child)\n",
    "        if sourceLine:\n",
    "            sourceLines.append(sourceLine)\n",
    "    return sourceLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gets all source lines in a list.\n",
    "Let's apply it to our sample tablet, and print out the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:07.721220Z",
     "start_time": "2018-02-26T20:34:07.704400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P448702 = www archaeo-auction 004 \n",
      "#atf: lang qpc \n",
      "@obverse \n",
      "@column 1 \n",
      "$ beginning broken \n",
      "1'. [n] , [...] KA~a \n",
      "2.a'. [n] 2(N14) 3(N01) , KASZ~b NUN~a \n",
      "2.b'. 3(N01) , KASZ~a? GI \n",
      "3'. [n] 6(N14)#? 4(N01) 2(N39~a) , X [...] \n",
      "@column 2 \n",
      "$ beginning broken \n",
      "$ blank space \n",
      "1'. , U4 |U4x1(N01)| SUKUD@inversum? NA \n",
      "@column 3 \n",
      "$ beginning broken \n",
      "$ blank space \n",
      "@reverse \n",
      "$ (not imaged) \n"
     ]
    }
   ],
   "source": [
    "sourceLines = getSource(justATablet)\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nearly the original. The only difference we spot is that we have left out\n",
    "the `@tablet` line. This has been done because the `&P` line is the true header of the\n",
    "tablet. In fact, the `@tablet` line is not consistently present in the source.\n",
    "\n",
    "This is an example where the TF data is a little bit more streamlined than the source transcriptions.\n",
    "\n",
    "Speaking of which: see that strange modifier on `SUKUD`, the `@inversum`?\n",
    "It is not in the [Oracc primer on ATF](http://oracc.museum.upenn.edu/doc/help/editinginatf/primer/inlinetutorial/index.html)\n",
    "\n",
    "Probably it is a typo, and the `inversum` should be replaced by a single letter.\n",
    "While Dirk was programming, he decided to \"correct\" this into `@v`, but what really is needed here is\n",
    "to correct the source. Or we could correct the correction.\n",
    "In either case, we expect to run the conversion again, with all issues like these resolved.\n",
    "\n",
    "To see what those issues are, see the complete list of\n",
    "[diagnostics](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/diagnostics.tsv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just enjoy the new power, and get the source lines of another, important tablet: \n",
    "[P005381](https://cdli.ucla.edu/search/search_results.php?SearchMode=Text&ObjectID=P005381).\n",
    "\n",
    "We show the photos, lineart and transcriptions of both faces of this tablet.\n",
    "For provenance: see above or follow the link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"images/P005381-obverse-photo.png\" width=\"50%\"/>\n",
    "<img align=\"right\" src=\"images/P005381-reverse-photo.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"images/P005381-obverse-lineart-annot.png\" width=\"50%\"/>\n",
    "<img align=\"right\" src=\"images/P005381-reverse-lineart.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:12.212982Z",
     "start_time": "2018-02-26T20:34:12.197446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P005381 = MSVO 3, 70\n",
      "#version: 0.1\n",
      "#atf: lang qpc\n",
      "@obverse\n",
      "@column 1\n",
      "1.a. 2(N14) , SZE~a SAL TUR3~a NUN~a\n",
      "1.b. 3(N19) , |GISZ.TE|\n",
      "2. 1(N14) , NAR NUN~a SIG7\n",
      "3. 2(N04)# , PIRIG~b1 SIG7 URI3~a NUN~a\n",
      "@column 2\n",
      "1. 3(N04) , |GISZ.TE| GAR |SZU2.((HI+1(N57))+(HI+1(N57)))| GI4~a\n",
      "2. , GU7 AZ SI4~f\n",
      "@reverse\n",
      "@column 1\n",
      "1. 3(N14) , SZE~a\n",
      "2. 3(N19) 5(N04) ,\n",
      "3. , GU7\n",
      "@column 2\n",
      "1. , AZ SI4~f\n"
     ]
    }
   ],
   "source": [
    "exampleTablet = T.nodeFromSection(('P005381',))\n",
    "sourceLines = getSource(exampleTablet)\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, in column 2, line 1 we find a composition of three levels: \n",
    "`|SZU2.((HI+1(N57))+(HI+1(N57)))|`\n",
    "\n",
    "We call compositions of signs by means of operators such as `.` and `x` and `+` *quads*.\n",
    "They are also a node type, the first node type above the \"atomic\" sign.\n",
    "\n",
    "We'll see a lot of *quads* later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source lines: refined\n",
    "\n",
    "If you just want the lines, and nothing else in between, you can instruct the `L.d` function to\n",
    "let through only nodes of a certain type.\n",
    "\n",
    "Let's improve the `getSource` function to give it an additional, optional argument that\n",
    "tells us the kind of object we want to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:14.689357Z",
     "start_time": "2018-02-26T20:34:14.668450Z"
    }
   },
   "outputs": [],
   "source": [
    "def getSource(tablet, nodeType=None):\n",
    "    sourceLines = []\n",
    "    sourceLines.append(F.srcLn.v(tablet))\n",
    "    for child in L.d(tablet, nodeType):\n",
    "        sourceLine = F.srcLn.v(child)\n",
    "        if sourceLine:\n",
    "            sourceLines.append(sourceLine)\n",
    "    return sourceLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call it without node type, we get the same results.\n",
    "\n",
    "Let's call it with `nodeType='face'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:16.540482Z",
     "start_time": "2018-02-26T20:34:16.524456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P005381 = MSVO 3, 70\n",
      "@obverse\n",
      "@reverse\n"
     ]
    }
   ],
   "source": [
    "sourceLines = getSource(exampleTablet, nodeType='face')\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see only the face specifiers.\n",
    "\n",
    "Now let's grab the lines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:18.297380Z",
     "start_time": "2018-02-26T20:34:18.280138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P005381 = MSVO 3, 70\n",
      "1.a. 2(N14) , SZE~a SAL TUR3~a NUN~a\n",
      "1.b. 3(N19) , |GISZ.TE|\n",
      "2. 1(N14) , NAR NUN~a SIG7\n",
      "3. 2(N04)# , PIRIG~b1 SIG7 URI3~a NUN~a\n",
      "1. 3(N04) , |GISZ.TE| GAR |SZU2.((HI+1(N57))+(HI+1(N57)))| GI4~a\n",
      "2. , GU7 AZ SI4~f\n",
      "1. 3(N14) , SZE~a\n",
      "2. 3(N19) 5(N04) ,\n",
      "3. , GU7\n",
      "1. , AZ SI4~f\n"
     ]
    }
   ],
   "source": [
    "sourceLines = getSource(exampleTablet, nodeType='case')\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lines and cases\n",
    "\n",
    "Note that we actually supplied `nodeType='case'`.\n",
    "This is because we have modelled the data in such a way, that a line corresponds to all\n",
    "transcription lines in a column that start with the same number.\n",
    "Lines are divided in cases and sub-cases according to the hierarchical line numbers.\n",
    "At the lowest level of sub-case we encounter the material that belong to single\n",
    "transcription lines.\n",
    "\n",
    "Also when lines only have a single case, we will have a case embedded in the line.\n",
    "\n",
    "So *case* is the node type for the geometric divisions of lines,\n",
    "coded by the hierarchical line number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line numbers\n",
    "\n",
    "The TF data also retains the original line numbers, i.e. the line number in the file\n",
    "that contains the transcriptions.\n",
    "We do not mean the hierarchical line numbers of the cases!\n",
    "Let us once again improve the `getSource` function by \n",
    "giving it an optional argument for fetching line numbers too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:25.941649Z",
     "start_time": "2018-02-26T20:34:25.919582Z"
    }
   },
   "outputs": [],
   "source": [
    "def getSource(tablet, nodeType=None, lineNumbers=False):\n",
    "    sourceLines = []\n",
    "    lineNumber = ''\n",
    "    if lineNumbers:\n",
    "        lineNumber = f'{F.srcLnNum.v(tablet):>5}: '\n",
    "    sourceLines.append(f'{lineNumber}{F.srcLn.v(tablet)}')\n",
    "    for child in L.d(tablet, nodeType):\n",
    "        sourceLine = F.srcLn.v(child)\n",
    "        lineNumber = ''\n",
    "        if sourceLine:\n",
    "            if lineNumbers:\n",
    "                lineNumber = f'{F.srcLnNum.v(child):>5}: '\n",
    "            sourceLines.append(f'{lineNumber}{sourceLine}')\n",
    "    return sourceLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print the lines with source line numbers, so that we can look them up in the\n",
    "source easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:27.764024Z",
     "start_time": "2018-02-26T20:34:27.746851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80927: &P005381 = MSVO 3, 70\n",
      "80932: 1.a. 2(N14) , SZE~a SAL TUR3~a NUN~a\n",
      "80933: 1.b. 3(N19) , |GISZ.TE|\n",
      "80934: 2. 1(N14) , NAR NUN~a SIG7\n",
      "80935: 3. 2(N04)# , PIRIG~b1 SIG7 URI3~a NUN~a\n",
      "80937: 1. 3(N04) , |GISZ.TE| GAR |SZU2.((HI+1(N57))+(HI+1(N57)))| GI4~a\n",
      "80938: 2. , GU7 AZ SI4~f\n",
      "80941: 1. 3(N14) , SZE~a\n",
      "80942: 2. 3(N19) 5(N04) ,\n",
      "80943: 3. , GU7\n",
      "80945: 1. , AZ SI4~f\n"
     ]
    }
   ],
   "source": [
    "sourceLines = getSource(exampleTablet, nodeType='case', lineNumbers=True)\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll appreciate the way you can build up your own power tools as you go.\n",
    "The functions of TF provide a foundation, so that start when all the gory details\n",
    "have been taken care of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep cases\n",
    "\n",
    "How deep can cases go?\n",
    "We explore the distribution of cases with respect to their depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring the depth of a structure.\n",
    "\n",
    "Cases are structures that can be nested.\n",
    "It is interesting to know how deep cases can be nested.\n",
    "\n",
    "We need a function that computes the depth of a case.\n",
    "We program that function in such a way that it also works for *quads*,\n",
    "an other nested structure.\n",
    "\n",
    "The idea of this function is:\n",
    "* if a structure does not have sub-structures, its depth is 1;\n",
    "* the depth of a structure is 1 more than the maximum of the depths of its sub-structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:30.955829Z",
     "start_time": "2018-02-26T20:34:30.934317Z"
    }
   },
   "outputs": [],
   "source": [
    "def depthStructure(node, nodeType):\n",
    "    subDepths = [\n",
    "        depthStructure(subNode, nodeType) \n",
    "        for subNode in E.sub.f(node) \n",
    "        if F.otype.v(subNode) == nodeType\n",
    "    ]\n",
    "    if len(subDepths) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return max(subDepths) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to collect all cases in buckets according to their depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:32.793848Z",
     "start_time": "2018-02-26T20:34:32.628263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   23 cases with depth 5\n",
      "   80 cases with depth 4\n",
      " 1096 cases with depth 3\n",
      " 8316 cases with depth 2\n",
      "42170 cases with depth 1\n"
     ]
    }
   ],
   "source": [
    "caseDepths = collections.defaultdict(list)\n",
    "\n",
    "for case in F.otype.s('case'):\n",
    "    caseDepths[depthStructure(case, 'case')].append(case)\n",
    "\n",
    "caseDepthsSorted = sorted(\n",
    "    caseDepths.items(), \n",
    "    key=lambda x: (-x[0], -len(x[1])),\n",
    ")\n",
    "\n",
    "for (depth, cases) in caseDepthsSorted:\n",
    "    print(f'{len(cases):>5} cases with depth {depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show where the deepest cases are.\n",
    "We also retrieve the size of the face containing that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:34.625452Z",
     "start_time": "2018-02-26T20:34:34.587013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P218054:reverse:1 ( 18 signs on face)\n",
      "P006092:obverse:1 ( 22 signs on face)\n",
      "P002694:reverse:1 ( 35 signs on face)\n",
      "P325754:reverse:1 ( 38 signs on face)\n",
      "P006295:reverse:1 ( 40 signs on face)\n",
      "P004735:obverse:2 ( 42 signs on face)\n",
      "P004735:obverse:2 ( 42 signs on face)\n",
      "P002856:obverse:2 ( 45 signs on face)\n",
      "P005322:reverse:1 ( 47 signs on face)\n",
      "P411608:obverse:1 ( 48 signs on face)\n",
      "P003531:obverse:1 ( 54 signs on face)\n",
      "P325234:reverse:1 ( 54 signs on face)\n",
      "P006160:obverse:1 ( 59 signs on face)\n",
      "P006307:reverse:1 ( 63 signs on face)\n",
      "P003529:obverse:1 ( 99 signs on face)\n",
      "P003529:obverse:2 ( 99 signs on face)\n",
      "P387752:obverse:0 (112 signs on face)\n",
      "P387752:obverse:0 (112 signs on face)\n",
      "P006056:reverse:1 (112 signs on face)\n",
      "P003808:obverse:3 (307 signs on face)\n",
      "P003808:obverse:5 (307 signs on face)\n",
      "P003808:obverse:6 (307 signs on face)\n",
      "P003808:obverse:6 (307 signs on face)\n"
     ]
    }
   ],
   "source": [
    "deepestCases = caseDepthsSorted[0][1]\n",
    "\n",
    "deepCaseData = []\n",
    "\n",
    "for deepCase in deepestCases:\n",
    "    (tNumber, colNumber, lineNumber) = T.sectionFromNode(deepCase)\n",
    "    face = L.u(deepCase, otype='face')[0]\n",
    "    faceSlots = L.d(face, otype='sign')\n",
    "    lengthFace = faceSlots[-1] - faceSlots[0]\n",
    "    deepCaseData.append((tNumber, colNumber, lengthFace))\n",
    "    \n",
    "deepCaseDataSorted = sorted(deepCaseData, key=lambda x: (x[2], x[1]))\n",
    "\n",
    "for (tNumber, colNumber, lengthFace) in deepCaseDataSorted:\n",
    "    print(f'{tNumber}:{colNumber} ({lengthFace:>3} signs on face)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the first entry (on P218054) and the last four ones\n",
    "on (P003808) are on remarkable faces.\n",
    "The first one is a deep case on a very small face, and the last four ones are\n",
    "deep cases all on the same face.\n",
    "\n",
    "We show the sources of those tablets. First the small tablet, note the `@reverse` face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:37.675527Z",
     "start_time": "2018-02-26T20:34:37.658439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P218054 = CDLB nn, CMAA 020-C0003\n",
      "#version: 0.1\n",
      "#atf: lang qpc\n",
      "@obverse\n",
      "@column 1\n",
      "1. [...] 1(N01)# , [...] X X\n",
      "2.a. 6(N01) , PAP~a DUR~b\n",
      "2.b. 2(N01) ,\n",
      "3.a1A. 3(N01) , DUR~b\n",
      "3.a1B. 1(N01) , MASZ2\n",
      "3.a2. , NI~a 3(N57)\n",
      "3.b. 6(N01) , GI\n",
      "4. 1(N01) , MASZ2 ZATU628~a DIM~a SAL\n",
      "5. 1(N01) , NUN~b DIM~a\n",
      "6. 1(N01) , NUN~b GAR SAG ZATU694~c\n",
      "7.a. 3(N01) , DUR~b UD5~a\n",
      "7.b. 1(N01) , GI\n",
      "8.a. 2(N01)# [...] , X [...]\n",
      "8.b. 5(N01) , GI\n",
      "9. [...] , [...]\n",
      "@column 2\n",
      "1. [...] 6(N01)# , [...]\n",
      "2.a. 3(N01) , SI TE NIM~b2\n",
      "2.b. 1(N01) ,\n",
      "3.a. 3(N01) , ZATU843\n",
      "3.b. 3(N01) ,\n",
      "4.a. 2(N01) , NA~a GI KU6~a\n",
      "4.b1. 1(N01) ,\n",
      "4.b2. 1(N01) , DUR~b\n",
      "@reverse\n",
      "@column 1\n",
      "1.a1A1. [...] 5(N01)# , [...] UDU~a#?\n",
      "1.a1A2. [...] 7(N01)# , MASZ2\n",
      "1.a1B. 4(N14) 1(N01) , DUR~b\n",
      "1.a2A. [...] , [...]\n",
      "1.a2B. 2(N14) 3(N01) , UDU~a GI\n",
      "1.b. , |LAL2~axNIM~b2|# [...]\n"
     ]
    }
   ],
   "source": [
    "smallTablet = T.nodeFromSection(('P218054',))\n",
    "sourceLines = getSource(smallTablet)\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"images/P218054-reverse-photo.png\" width=\"75%\"/>\n",
    "\n",
    "> From [CDLI](https://cdli.ucla.edu/search/search_results.php?SearchMode=Text&ObjectID=P218054)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we do the big tablet, note the `@obverse` face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:41.566571Z",
     "start_time": "2018-02-26T20:34:41.544176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P003808 = IM —\n",
      "#version: 0.1\n",
      "#atf: lang qpc\n",
      "@obverse\n",
      "@column 1\n",
      "1. [...] , [...] MUSZ3~a# KASZ~b EZEN~b\n",
      "2. 1(N01) , SAL AMA~a\n",
      "3. 4(N01) , MEN~a NUNUZ~c DU\n",
      "4. 1(N01) , PAP~a GA2~a1 IB~a\n",
      "@column 2\n",
      "1.a. [...] , [...]\n",
      "1.b. [...] , [...]\n",
      "2.a. [...] , [...]\n",
      "2.b. [...] , KAB ZI~a\n",
      "3.a. [...] , [...] X\n",
      "3.b. , SZUBUR BU~a SUKKAL\n",
      "4.a. 2(N01)# [...] , X KUR~a SIG2~b SZE~a\n",
      "4.b. , GESZTU~b# [...]\n",
      "5.a. 6(N01) , PAD~a GA~a\n",
      "5.b1. 3(N57) , |SZE~a&SZE~a| DU\n",
      "5.b2. 3(N57) , DU AB2 SAG#\n",
      "@column 3\n",
      "1.a. [...] , [...] DUG~c#\n",
      "1.b1. [...] 1(N01) , GAN~c [...]\n",
      "1.b2A. 3(N57) , EN~a BAD AB~a@g\n",
      "1.b2B. 1(N57) , PAP~a SIG7 NUN~a GUL\n",
      "1.c. [...] , [...] IB~a#\n",
      "2.a. 1(N01) , DUG~c\n",
      "2.b1A. [...] , |DUG~cx1(N57)|\n",
      "2.b1B1. [...] , GAN~c SZU\n",
      "2.b1B2. , SZITA~a1 ADAB UTUL~a\n",
      "2.b2A. 2(N01) , SILA3~a GARA2~a\n",
      "2.b2B1. 1(N57) , SZA SZU\n",
      "2.b2B2. 1(N57) , ZATU659? PAP~a SUKKAL\n",
      "2.b3. 4(N01) , |SILA3~axGA~a| SZA\n",
      "2.c. , SUG5 LA2 IB~a\n",
      "3.a1. [...] , X AMA~a AN [...]\n",
      "3.a2. 1(N01) , KI# NA2~a [...]\n",
      "3.a3. 1(N01) , MIR~b |ZATU651xNUN~a|\n",
      "3.b. , GESZTU~b SZITA~a1\n",
      "@column 4\n",
      "1.a1. [...] , X MUSZEN# AN X KU6~a [...]\n",
      "1.a2. [...] , GAN~c |U4x6(N01)| NA2~a\n",
      "1.b. , [...] ZATU686~b\n",
      "2.a1. 1(N14)# 8(N01) , KAR2~a NUN~a# [...]\n",
      "2.a2A. 1(N14) , GA~a GAL~a BAR\n",
      "2.a2B. , 1(N04)# PAP~a IB~a\n",
      "2.a3. 1(N01) , EN~a AB~b SZEN~a UB SZUR2~a\n",
      "2.a4. 1(N01) , SAL UNUG~a SZITA~a1 AL#?\n",
      "2.a5. 1(N01) , NA~a? MUSZEN UMUN2 KU3~a GI\n",
      "2.b. , UNUG~a [...] GESZTU~b SZITA~a1 ZATU686~a\n",
      "3.a1. 3(N01) , |GA~a.ZATU753| MIR~b\n",
      "3.a2. 1(N01)# , AB~a# [...]\n",
      "3.b. , ZATU753 E2~a [...]\n",
      "4.a. 1(N01) , |GA~a.ZATU753| AB~a\n",
      "4.b1. , E2~a#\n",
      "4.b2. , BU~a KA~a\n",
      "@column 5\n",
      "1.a. 1(N01) , SZAKIR~c ZATU752 BA E2~a GIBIL NUN~a\n",
      "1.b. , GESZTU~b SZITA~a1 ZATU686~a\n",
      "2.a1. 3(N01) , E2~a PA~a 3(N57) |(UDU~axTAR)~a| KU6~a\n",
      "2.a2A1. 1(N01) , E2~a ALAN~b NUN~a# TAK4~a\n",
      "2.a2A2. 1(N01) , ZATU651@g TAK4~a ALAN~b\n",
      "2.a2B. , X KA~a X HI X\n",
      "2.a3. 1(N01) , SANGA~a GA~a AB~a\n",
      "2.a4. 1(N01) , GAL~a ZATU687 AB~a\n",
      "2.a5. 1(N01) , GA~a ARARMA2~a\n",
      "2.b. , GESZTU~b SZITA~a1 ZATU686~a\n",
      "3.a. 1(N01) , KASZ~b URI5 AN MUSZ3~a#\n",
      "3.b. , MUD NUN~a\n",
      "4.a. 1(N01) , EN~a BA ARARMA2~a\n",
      "4.b. , EN~a DUG~a AB~a# [...]\n",
      "@column 6\n",
      "1.a. [...] , [...] DUG~c UNUG~a\n",
      "1.b1A. [...] , |SILA3~axGARA2~a|#\n",
      "1.b1B1. [...] , [...] X\n",
      "1.b1B2. 1(N57) , DILMUN\n",
      "1.b2A. 4(N01) , |SILA3~axGA~a|\n",
      "1.b2B1. 1(N57) , EN~a SZE3? TUR NUN~a\n",
      "1.b2B2. 1(N57) , X AN MUSZ3~a EN~a X\n",
      "1.b2B3. 1(N57) , SIG2~b\n",
      "1.b2B4. 1(N57) , E2~a GU\n",
      "1.b3. 2(N01) , BA SILA3~a KASZ~b\n",
      "2.a. 1(N01) , KU6~a\n",
      "2.b1A. 6(N01) , |SILA3~axGARA2~a|\n",
      "2.b1B1. 1(N57) , EN~a# SAG#\n",
      "2.b1B2. 1(N57) , HI E2~a DILMUN NUN~a\n",
      "2.b1B3. 1(N57) , NAMESZDA\n",
      "2.b1B4. 1(N57) , GESZTU~a? DIM~a\n",
      "2.b1B5. 1(N57) , SZA SZU\n",
      "2.b1B6. 1(N57) , GI BAD\n",
      "2.b2. 1(N01) , |SILA3~axGA~a| |SIxSZE3| EN~a# NUN~a#\n",
      "2.b3. 5(N14) , BA SILA3~a KASZ~b\n",
      "3. , [...]\n",
      "@reverse\n",
      "@column 1\n",
      "1. 1(N34)# 5(N14) 6(N01) [...] , X X NA~a [...]\n",
      "@column 2\n",
      "1. , |GA~a.ZATU753| [...]\n"
     ]
    }
   ],
   "source": [
    "bigTablet = T.nodeFromSection(('P003808',))\n",
    "sourceLines = getSource(bigTablet)\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"images/P003808-obverse-photo.png\" width=\"100%\"/>\n",
    "\n",
    "> From [CDLI](https://cdli.ucla.edu/search/search_results.php?SearchMode=Text&ObjectID=P003808)\n",
    "\n",
    "> This is the [detail image](https://cdli.ucla.edu/dl/photo/P003808_d.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass operations\n",
    "\n",
    "We have a mass of data, and we want to do meaningful things with that mass.\n",
    "Here are a few ways to address all nodes, and significant subsets of all nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walking all nodes\n",
    "\n",
    "The generator `N()` provides you with all nodes, one by one, in a sequence.\n",
    "They come in the natural order, as we have seen above:\n",
    "\n",
    "* first things first\n",
    "* bigger things before the smaller things they contain.\n",
    "\n",
    "Let's print the first 20 nodes, together with their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:44.748180Z",
     "start_time": "2018-02-26T20:34:44.724526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150862 : tablet\n",
      "180733 : comment\n",
      "     1 : sign\n",
      "180734 : comment\n",
      "     2 : sign\n",
      "157258 : face\n",
      "166700 : column\n",
      "229498 : line\n",
      "266423 : case\n",
      "196539 : cluster\n",
      "     3 : sign\n",
      "     4 : sign\n",
      "     5 : sign\n",
      "166701 : column\n",
      "229499 : line\n",
      "266424 : case\n",
      "     6 : sign\n",
      "     7 : sign\n",
      "     8 : sign\n",
      "196540 : cluster\n"
     ]
    }
   ],
   "source": [
    "LIMIT = 20\n",
    "\n",
    "times = 0\n",
    "for n in N():\n",
    "    print(f'{n:>6} : {F.otype.v(n)}')\n",
    "    times += 1\n",
    "    if times >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All signs\n",
    "\n",
    "Suppose we are only interested in the signs, not how they are organized in cases, lines,\n",
    "columns, faces and tablets.\n",
    "\n",
    "Suppose we just want to count them.\n",
    "\n",
    "We could use `N()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:46.759221Z",
     "start_time": "2018-02-26T20:34:46.442619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146955\n"
     ]
    }
   ],
   "source": [
    "times = 0\n",
    "for n in N():\n",
    "    if F.otype.v(n) != 'sign':\n",
    "        continue\n",
    "    times += 1\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, TF makes it a bit easier to get to all sign nodes, or nodes from whatever type.\n",
    "\n",
    "We have already used the `F.feature.v(n)` idiom.\n",
    "But you can do more with features, beyond fetching particular values.\n",
    "\n",
    "You can also retrieve the sequence of nodes that support a particular value.\n",
    "\n",
    "We want to retrieve all nodes that support the value `sign` in their `otype` feature.\n",
    "\n",
    "Here we go, and note that we use `.s(value)` instead of `.v(node)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:48.773789Z",
     "start_time": "2018-02-26T20:34:48.754461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146955"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signs = F.otype.s('sign')\n",
    "len(signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signs have a feature `grapheme`, filled with the name of the sign, without variants (allographs), modifiers, and flags. Let's see the first 20 graphemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:50.425889Z",
     "start_time": "2018-02-26T20:34:50.405590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 : \n",
      " 2 : \n",
      " 3 : …\n",
      " 4 : X\n",
      " 5 : X\n",
      " 6 : N14\n",
      " 7 : X\n",
      " 8 : SANGA\n",
      " 9 : …\n",
      "10 : \n",
      "11 : \n",
      "12 : X\n",
      "13 : X\n",
      "14 : X\n",
      "15 : X\n",
      "16 : X\n",
      "17 : X\n",
      "18 : X\n",
      "19 : X\n",
      "20 : X\n"
     ]
    }
   ],
   "source": [
    "for sign in signs[0:20]:\n",
    "    print(f'{sign:>2} : {F.grapheme.v(sign)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note:\n",
    "\n",
    "* there are empty signs\n",
    "* there is the sign `…`\n",
    "\n",
    "During conversion, we have put empty signs in metadata lines and rulings.\n",
    "That is the mechanism by which TF knows where in the corpus they are positioned.\n",
    "They do not belong to the material that corresponds to tablet content, except maybe in the\n",
    "case of rulings.\n",
    "\n",
    "The sign `…` originates from `...` in transcriptions, which is mostly surrounded by\n",
    "`[ ]`. The brackets signify uncertainty, and can be put around other signs as well,\n",
    "even sequences of signs. These brackets denote *clusters*, a node type that we will encounter\n",
    "later.\n",
    "\n",
    "So, the expression `[...]` in the source translates to a *cluster* in TF, with just one\n",
    "sign in it, which has *grapheme* value `…`. \n",
    "Of course, this is not a real grapheme, and it will be easy to weed out such graphemes if\n",
    "you do not need to take them into account. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particular signs\n",
    "\n",
    "Suppose we want to get all occurrences of the grapheme `SANGA`.\n",
    "\n",
    "We can use the same trick as for getting the `signs`: we ask for the nodes that support\n",
    "the value `SANGA` in their `grapheme` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:54.427318Z",
     "start_time": "2018-02-26T20:34:54.389150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sangas = F.grapheme.s('SANGA')\n",
    "len(sangas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of what you can do with such a set, let's pick only those SANGAs that\n",
    "do not have a variant. We want `SANGA`, but not `SANGA~a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:55.820445Z",
     "start_time": "2018-02-26T20:34:55.801494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pureSangas = [s for s in sangas if F.variant.v(s) is None]\n",
    "len(pureSangas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, all sangas are with variant (allograph) in this corpus. Are they all `~a`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:57.247793Z",
     "start_time": "2018-02-26T20:34:57.227965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aSangas = [s for s in sangas if F.variant.v(s) == 'a']\n",
    "len(aSangas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all of them, let's see what other variants occur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:34:58.633993Z",
     "start_time": "2018-02-26T20:34:58.602794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65752 SANGA~b\n",
      "122525 SANGA~b\n",
      "122536 SANGA~b\n",
      "122577 SANGA~b\n",
      "122593 SANGA~b\n",
      "123008 SANGA~b\n",
      "123011 SANGA~b\n",
      "123019 SANGA~b\n",
      "123025 SANGA~b\n",
      "123052 SANGA~b\n",
      "124094 SANGA~b\n",
      "124783 SANGA~b\n",
      "127407 SANGA~b\n",
      "133550 SANGA~b\n",
      "133681 SANGA~c\n",
      "135991 SANGA~b\n",
      "138239 SANGA~b\n",
      "142282 SANGA~c\n",
      "All variants: b, c\n"
     ]
    }
   ],
   "source": [
    "sangaVariants = set()\n",
    "otherSangas = []\n",
    "\n",
    "for s in sangas:\n",
    "    if s not in aSangas:\n",
    "        otherSangas.append(s)\n",
    "        variant = F.variant.v(s)\n",
    "        sangaVariants.add(variant)\n",
    "        print(f'{s:>6} SANGA~{variant}')\n",
    "print(f'All variants: {\", \".join(sorted(sangaVariants))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From instance to context\n",
    "\n",
    "We want to know where those other SANGA variants are.\n",
    "\n",
    "Earlier we saw how we could get nodes if we knew the section.\n",
    "Here we need the opposite. We know a few nodes, and want to get the section.\n",
    "TF has a function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:00.247960Z",
     "start_time": "2018-02-26T20:35:00.228079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P273433', 'obverse:2', '3')\n",
      "('P000884', 'obverse:1', '2')\n",
      "('P000884', 'obverse:2', '1')\n",
      "('P000886', 'obverse:2', '2')\n",
      "('P000888', 'obverse:1', '1')\n",
      "('P000958', 'obverse:2', '3')\n",
      "('P000958', 'obverse:2', '4')\n",
      "('P000958', 'obverse:2', '7')\n",
      "('P000958', 'obverse:3', '2')\n",
      "('P000958', 'obverse:5', '2')\n",
      "('P001078', 'obverse:2', '2')\n",
      "('P001161', 'obverse:1', '1')\n",
      "('P001377', 'obverse:3', '3')\n",
      "('P002079', 'obverse:1', '1')\n",
      "('P002207', 'obverse:1', '1')\n",
      "('P003233', 'obverse:2', '2')\n",
      "('P000121', 'obverse:2', '3')\n",
      "('P003454', 'obverse:2', '2')\n"
     ]
    }
   ],
   "source": [
    "for s in otherSangas:\n",
    "    print(T.sectionFromNode(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see the source code line of these sangas, we can do it by what we have learned so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:01.670191Z",
     "start_time": "2018-02-26T20:35:01.650089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53330: 3.b. 2(N14) 6(N01) , SANGA~b? \n",
      " 1292: 2. 2(N01) , SANGA~b MA\n",
      " 1296: 1. 1(N01)# , X SANGA~b#?\n",
      " 1322: 2. 1(N01)# , ZATU713# SANGA~b#\n",
      " 1339: 1. [...] 2(N01)# , HASZHUR# SANGA~b# [...]\n",
      " 1786: 3. 1(N01) , UMUN2# SANGA~b#\n",
      " 1787: 4. 1(N01) , ZATU678# SANGA~b?\n",
      " 1790: 7. 1(N01) , SUG5 SANGA~b\n",
      " 1793: 2. 1(N01) , BU~a SANGA~b\n",
      " 1807: 2. 1(N01)# , SANGA~b#\n",
      " 2687: 2. 3(N01)# [...] , SANGA~b# KUR@g~a# [...]\n",
      " 3280: 1. [...] 3(N01)# , SANGA~b\n",
      " 5564: 3. [...] 1(N01) , SANGA~b#\n",
      "10490: 1. 2(N14)#? , SANGA~b\n",
      "10622: 1. , SANGA~c GIR3~b DUB~c\n",
      "12763: 2. 1(N52)# , SANGA~b\n",
      "14583: 3'. , SANGA~b? IB~b \n",
      "18084: 2. 1(N34) , SANGA~c 1(N58)\n"
     ]
    }
   ],
   "source": [
    "for s in otherSangas:\n",
    "    for case in L.u(s, otype='case'):\n",
    "        srcLine = F.srcLn.v(case)\n",
    "        if srcLine is not None:\n",
    "            print(f'{F.srcLnNum.v(case):>5}: {srcLine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency list\n",
    "\n",
    "TF has a standard function that generates a frequency list for any feature of your choice.\n",
    "\n",
    "Let's do the modifiers (`@`*mod*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:03.453062Z",
     "start_time": "2018-02-26T20:35:03.434195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('g', 648), ('t', 251), ('n', 39), ('r', 6), ('s', 4), ('c', 1), ('v', 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.modifier.freqList()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a tuple of tuples (*modifier*, *amount of occurrences*), ordered in decreasing frequency.\n",
    "We can print the list a bit more neatly as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:04.840527Z",
     "start_time": "2018-02-26T20:35:04.821024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 648 x g\n",
      " 251 x t\n",
      "  39 x n\n",
      "   6 x r\n",
      "   4 x s\n",
      "   1 x c\n",
      "   1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, amount) in F.modifier.freqList():\n",
    "    print(f'{amount:>4} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can call this for any feature.\n",
    "So let us do it for graphemes. Note that we get a frequency list for the bare graphemes, ignoring\n",
    "variants and modifiers. So maybe this is not that useful.\n",
    "\n",
    "Before we print out the complete list, let's make sure the list is not forbiddingly long.\n",
    "Or rather, let us print only the top twenty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:06.478082Z",
     "start_time": "2018-02-26T20:35:06.361970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29618 x …\n",
      "21676 x N01\n",
      "17128 x \n",
      "6956 x X\n",
      "5924 x N14\n",
      "1970 x EN\n",
      "1846 x N57\n",
      "1835 x N34\n",
      "1349 x SZE\n",
      "1241 x GAL\n",
      "1125 x DUG\n",
      "1069 x AN\n",
      "1046 x U4\n",
      " 892 x NUN\n",
      " 881 x SAL\n",
      " 879 x PAP\n",
      " 877 x E2\n",
      " 875 x GI\n",
      " 788 x BA\n",
      " 747 x SANGA\n"
     ]
    }
   ],
   "source": [
    "for (value, amount) in F.grapheme.freqList()[0:20]:\n",
    "    print(f'{amount:>4} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structures\n",
    "\n",
    "Some node types represent things with a nested structure. We have seen *quads* above,\n",
    "an other example are *clusters* of quads. Clusters are called *brackets* in the\n",
    "[Oracc primer](http://oracc.museum.upenn.edu/doc/help/editinginatf/primer/inlinetutorial/index.html).\n",
    "\n",
    "In TF, we have two mechanisms to specify that something is a part of an other thing.\n",
    "One we have already encountered: `L.d(`*node*`)`, which gives you the nodes of all things whose signs\n",
    "are contained in the signs belonging to *node*.\n",
    "\n",
    "But for some purposes this is to coarse.\n",
    "Consider the complex quad we encountered before:\n",
    "\n",
    "```\n",
    "|SZU2.((HI+1(N57))+(HI+1(N57)))|\n",
    "```\n",
    "\n",
    "This quad has sub-quads `SZU2`, `(HI+1(N57))+(HI+1(N57))`, and the last one\n",
    "has sub-quads `HI+1(N57)` and `HI+1(N57)`, which have in turn sub-quads `HI` and `1(N57)`.\n",
    "\n",
    "If we only look at embedding, it is a bit awkward to produce the sub-quads per level, because\n",
    "if we ask for all sub-quads embedded in the outer quad, we'll get all sub-quads mentioned, regardless\n",
    "of level. \n",
    "\n",
    "So we need an extra device, and TF offers a very generic one for this: *edge features*.\n",
    "\n",
    "Whereas the *features* we have seen so far, such as `otype`, `grapheme`, and `variant`\n",
    "annotate nodes, there are also features that annotate pairs of nodes.\n",
    "A pair of nodes is called an *edge*, and indicates that there is a relationship between nodes.\n",
    "Edge features give these relationships a name, and can annotate the relationships as well.\n",
    "\n",
    "We could use edge features to relate lines to other, similar lines in the corpus, and annotate it\n",
    "with the degree of similarity.\n",
    "\n",
    "In the case of quads and clusters, we have generated edges in TF between clusters and their components,\n",
    "and between quads and their components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quads\n",
    "\n",
    "The components of quads are either sub-quads or signs.\n",
    "Sub-quads are also quads in TF, and they are always a composition.\n",
    "Whenever a member of a sub-quad is no longer a composition, it is a *sign*.\n",
    "\n",
    "Let's try to unravel the structure of this example quad by TF means.\n",
    "\n",
    "#### Getting a big quad\n",
    "First we need to get the node of this quad. Above we have seen the source code of the tablet in which\n",
    "it occurs, from that we can pick the node of the case it is in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:17.307161Z",
     "start_time": "2018-02-26T20:35:17.289339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257531"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = T.nodeFromSection(('P005381', 'obverse:2', '1'))\n",
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that in order to specify a column, you have to specify it as *face type*`:`*column number*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:19.017990Z",
     "start_time": "2018-02-26T20:35:18.998533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 3(N04) , |GISZ.TE| GAR |SZU2.((HI+1(N57))+(HI+1(N57)))| GI4~a'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case = L.d(line, otype='case')[0]\n",
    "F.srcLn.v(case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to identify our super-quad, we list all quad nodes that are part of this case.\n",
    "For every quad we list the node numbers of the signs contained in it.\n",
    "\n",
    "In order to know what signs are contained in any given node, we use the feature `oslots`.\n",
    "Like the feature `otype`, this is a standard feature that is always available in a TF dataset.\n",
    "\n",
    "Unlike `otype`, `oslots` is an edge feature: there is an edge between every node and every slot contained in it.\n",
    "\n",
    "Whereas you use `F` to do stuff with node features, you use `E` to do business with edge features.\n",
    "\n",
    "And whereas you use `F.feature.v(node)` to get the feature value of a node, you use \n",
    "`E.oslots.s(node)` to get the nodes for which there is an `oslots` edge from `node` to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:20.862981Z",
     "start_time": "2018-02-26T20:35:20.845276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149987 (111485, 111486)\n",
      "149988 (111488, 111489, 111490, 111491, 111492)\n",
      "149989 (111489, 111490, 111491, 111492)\n",
      "149990 (111489, 111490)\n",
      "149991 (111491, 111492)\n"
     ]
    }
   ],
   "source": [
    "for node in L.d(case, otype='quad'):\n",
    "    print(f'{node:>6} {E.oslots.s(node)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On the basis of this see what the biggest quad is.\n",
    "We could have been a bit more friendly to our selves by showing the actual graphemes in the quads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:22.357197Z",
     "start_time": "2018-02-26T20:35:22.333786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149987 GISZ TE\n",
      "149988 SZU2 HI N57 HI N57\n",
      "149989 HI N57 HI N57\n",
      "149990 HI N57\n",
      "149991 HI N57\n"
     ]
    }
   ],
   "source": [
    "for node in L.d(case, otype='quad'):\n",
    "    print(f'{node:>6} {\" \".join(F.grapheme.v(s) for s in E.oslots.s(node))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let us get the node of the biggest quad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:24.197517Z",
     "start_time": "2018-02-26T20:35:24.172796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149988"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigQuad = sorted(\n",
    "    (\n",
    "        quad \n",
    "        for quad in L.d(case, otype='quad')\n",
    "    ),\n",
    "    key = lambda q: -len(E.oslots.s(q))\n",
    ")[0]\n",
    "bigQuad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo and behold, it is precisely the big quad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unraveling a quad\n",
    "\n",
    "Now we are going to retrieve its components by following edges.\n",
    "We have made `sub` edges from quads to their components.\n",
    "\n",
    "In order to follow the `sub` edges from a node, you use \n",
    "\n",
    "`E.sub.f(node)`.\n",
    "\n",
    "You can also get the `sub` edges *to* a node:\n",
    "\n",
    "`E.sub.t(node)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:27.388818Z",
     "start_time": "2018-02-26T20:35:27.370469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111488, 149989)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.sub.f(bigQuad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us unravel the whole structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:28.798646Z",
     "start_time": "2018-02-26T20:35:28.773893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SZU2, <<HI, N57>, <HI, N57>>>'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unravelQuad(quad):\n",
    "    if F.otype.v(quad) == 'sign':\n",
    "        return F.grapheme.v(quad)\n",
    "    subQuads = E.sub.f(quad)\n",
    "    unraveledSubQuads = [unravelQuad(subQuad) for subQuad in subQuads]\n",
    "    return f'<{\", \".join(unraveledSubQuads)}>'\n",
    "\n",
    "unravelQuad(bigQuad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later we see how we can get the exact representation of this quad back, including the operators `.` and `+`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collecting quads by depth\n",
    "\n",
    "We want to sort all complex quads by the depth of their structure.\n",
    "We can use the same function that we wrote for getting the depth of a case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the depth of the big quad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:35:42.772477Z",
     "start_time": "2018-02-26T20:35:42.754856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depthStructure(bigQuad, 'quad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of quads by depth\n",
    "\n",
    "We want to know how many quads there are, how deeply composed they get, and how often deep compositions\n",
    "occur.\n",
    "\n",
    "This is the recipe:\n",
    "we visit all quads, examine their depths, and tally the appropriate depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:36:12.791254Z",
     "start_time": "2018-02-26T20:36:12.746758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3735 x depth 1\n",
      "  170 x depth 2\n",
      "    1 x depth 3\n"
     ]
    }
   ],
   "source": [
    "depthDistribution = collections.Counter()\n",
    "\n",
    "for quad in F.otype.s('quad'):\n",
    "    depth = depthStructure(quad, 'quad')\n",
    "    depthDistribution[depth] += 1\n",
    "    \n",
    "for (depth, amount) in sorted(\n",
    "    depthDistribution.items(),\n",
    "    key=lambda x: (-x[1], x[0]),\n",
    "):\n",
    "    print(f'{amount:>5} x depth {depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out we had spotted the deepest quad already.\n",
    "Let's finish off by looking which tablets show how many quads with depth >= 2.\n",
    "\n",
    "The code is much like above, but now we do not tally the depth of a quad, but the tablet\n",
    "it occurs in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:36:26.576146Z",
     "start_time": "2018-02-26T20:36:26.532944Z"
    }
   },
   "outputs": [],
   "source": [
    "tabletQuad = collections.Counter()\n",
    "\n",
    "for quad in F.otype.s('quad'):\n",
    "    depth = depthStructure(quad, 'quad')\n",
    "    if depth >= 2:\n",
    "        tablet = L.u(quad, otype='tablet')[0]\n",
    "        tabletQuad[tablet] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at the output, let us sort the tablets found on decreasing amount of complex quads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:36:30.914549Z",
     "start_time": "2018-02-26T20:36:30.897605Z"
    }
   },
   "outputs": [],
   "source": [
    "tabletQuadList = sorted(\n",
    "    tabletQuad,\n",
    "    key=lambda t: (-tabletQuad[t], t),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not interested in tablets with just one complex quad.\n",
    "\n",
    "We collect the tablets by their node, but when we output the results, we\n",
    "want to show the tablet's number, which is stored in the feature `catalogId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:36:34.514758Z",
     "start_time": "2018-02-26T20:36:34.491376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    6 complex quads in tablet P212396\n",
      "    6 complex quads in tablet P003520\n",
      "    6 complex quads in tablet P003809\n",
      "    4 complex quads in tablet P005152\n",
      "    3 complex quads in tablet P003591\n",
      "    3 complex quads in tablet P471693\n",
      "    3 complex quads in tablet P006378\n",
      "    3 complex quads in tablet P325754\n",
      "    3 complex quads in tablet P235782\n",
      "    3 complex quads in tablet P005323\n",
      "    2 complex quads in tablet P003528\n",
      "    2 complex quads in tablet P004846\n",
      "    2 complex quads in tablet P004893\n",
      "    2 complex quads in tablet P000440\n",
      "    2 complex quads in tablet P000468\n",
      "    2 complex quads in tablet P000514\n",
      "    2 complex quads in tablet P000157\n",
      "    2 complex quads in tablet P000441\n",
      "    2 complex quads in tablet P000442\n",
      "    2 complex quads in tablet P002820\n",
      "    2 complex quads in tablet P003768\n",
      "    2 complex quads in tablet P003613\n",
      "    2 complex quads in tablet P006038\n",
      "    2 complex quads in tablet P005093\n",
      "    2 complex quads in tablet P005188\n",
      "    2 complex quads in tablet P005317\n",
      "    2 complex quads in tablet P005332\n",
      "    2 complex quads in tablet P005381\n",
      "    2 complex quads in tablet P005474\n",
      "    2 complex quads in tablet P003527\n",
      "    2 complex quads in tablet P003578\n",
      "    2 complex quads in tablet P001412\n",
      "    2 complex quads in tablet P003251\n",
      "    2 complex quads in tablet P004112\n",
      "    1 complex quad  in 83 other tablets\n"
     ]
    }
   ],
   "source": [
    "singles = 0\n",
    "\n",
    "for tablet in tabletQuadList:\n",
    "    amount = tabletQuad[tablet]\n",
    "    if amount == 1:\n",
    "        singles += 1\n",
    "    else:\n",
    "        print(f'{amount:>5} complex quads in tablet {F.catalogId.v(tablet)}')\n",
    "print(f'{1:>5} complex quad  in {singles} other tablets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, for the record, we'll have a look at the source code of one of the tablets at the top of the list.\n",
    "We have already defined a function `getSource(tablet)` above, which comes in handy here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:36:39.361520Z",
     "start_time": "2018-02-26T20:36:39.347854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P212396 = CDLB 2003/4 \n",
      "#atf: lang qpc \n",
      "@obverse \n",
      "1.a. 8(N01)# , GAR |U4x2(N57)| AB~a \n",
      "1.a. 8(N01)# , GAR |U4x2(N57)| AB~a \n",
      "1.b. 1(N28) , |U4x1(N57)| SZE~a \n",
      "1.c. 2(N39~a) 1(N24) , |U4.1(N14)| SZE~a \n",
      "1.d1. 1(N01)# [...] , [...] SZE~a \n",
      "1.d2. 4(N14)# , X [...] \n",
      "2.a. 1(N14) , |U4x1(N01)| |LAGAB~axSZITA~a1| PAP~a#? \n",
      "2.b. 1(N24) , |U4x1(N57)| \n",
      "2.c. 1(N04) 1(N01) 1(N41) 1(N39~a) , |U4x(1(N14).2(N01))|# [...] \n",
      "3.a. 1(N01) , X |U4x1(N01)|? GUG2#? \n",
      "3.b. 2(N41) 2(N29A~b) , |U4x(1(N14).2(N01))| \n",
      "4.a. 5(N01)#? , |U4x1(N01)|#? X \n",
      "4.b1. 2(N39~a) 1(N24) , |U4x1(N01)| \n",
      "4.b2. 1(N28)#? , SZE~a# BULUG3?# [...] \n",
      "4.c. 1(N14) 1(N01) 1(N39~a) , |U4x(1(N14).2(N01))| \n",
      "@reverse \n",
      "1.a. X? 1(N28)# , |U4x1(N57)|# SZE~a \n",
      "1.a. X? 1(N28)# , |U4x1(N57)|# SZE~a \n",
      "1.b. 2(N01)# 1(N24)# , |U4x1(N01)|# \n",
      "1.c. 4(N14)# 1(N01) 1(N39~a) , |U4x(1(N14).2(N01))|# SZE~a# \n",
      "1.d. [...] 2(N01)?# [...] , SZE~a# TAR~a 1(N30~e) \n",
      "2.a. 1(N41) , |U4x1(N01)| \n",
      "2.b. 2(N04)# 4(N41)# 2(N29~a)# , |U4x(1(N14).2(N01))| \n",
      "2.c. 1(N41) 1(N39~a) 1(N24~b) 1(N29A~b)# 1(N30~a)# [...] , [...] \n",
      "3. 5(N14)# 1(N04) 1(N24) 1(N26) 1(N31)#? , SZE~a# |U4x(1(N14).2(N01))|# \n",
      "4. KASZ~b DA~a AN AB~a |GI&GI|#? BAR?# \n"
     ]
    }
   ],
   "source": [
    "sourceLines = getSource(tabletQuadList[0])\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusters\n",
    "\n",
    "Clusters are groups of consecutive quads between brackets.\n",
    "\n",
    "Clusters can be nested.\n",
    "As with quads, we find the members of a cluster by following `sub` edges.\n",
    "\n",
    "#### Kinds of clusters\n",
    "\n",
    "In our corpus we encounter several types of brackets:\n",
    "\n",
    "* `( )a` for proper names\n",
    "* `[ ]` for uncertainty\n",
    "* `< >` for supplied material.\n",
    "\n",
    "The first thing is to get on overview of the distribution of these kinds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:36:43.777399Z",
     "start_time": "2018-02-26T20:36:43.711227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32321 x a uncertain-cluster\n",
      "  637 x a properName-cluster\n",
      "    1 x a supplied-cluster\n"
     ]
    }
   ],
   "source": [
    "clusterKindDistribution = collections.Counter()\n",
    "\n",
    "for cluster in F.otype.s('cluster'):\n",
    "    kind = F.kind.v(cluster)\n",
    "    clusterKindDistribution[kind] += 1\n",
    "\n",
    "for (kind, amount) in sorted(\n",
    "    clusterKindDistribution.items(),\n",
    "    key=lambda x: (-x[1], x[0]),\n",
    "):\n",
    "    print(f'{amount:>5} x a {kind:>8}-cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversion to TF has transformed `[...]` to a cluster of one sign with grapheme `…`.\n",
    "These are trivial clusters and we want to exclude them from further analysis, so we redo the counting.\n",
    "\n",
    "First we make a sequence of all non-trivial clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:36:46.596990Z",
     "start_time": "2018-02-26T20:36:46.455459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3385"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realClusters = [\n",
    "    c \n",
    "    for c in F.otype.s('cluster')\n",
    "    if (\n",
    "        F.kind.v(c) != 'uncertain' or\n",
    "        len(E.oslots.s(c)) > 1 or \n",
    "        F.grapheme.v(E.oslots.s(c)[0]) != '…'\n",
    "    )\n",
    "]\n",
    "len(realClusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we redo the same analysis, but we start with the filtered cluster sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:36:49.106391Z",
     "start_time": "2018-02-26T20:36:49.082023Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2747 x a uncertain-cluster\n",
      "  637 x a properName-cluster\n",
      "    1 x a supplied-cluster\n"
     ]
    }
   ],
   "source": [
    "clusterKindDistribution = collections.Counter()\n",
    "\n",
    "for cluster in realClusters:\n",
    "    kind = F.kind.v(cluster)\n",
    "    clusterKindDistribution[kind] += 1\n",
    "\n",
    "for (kind, amount) in sorted(\n",
    "    clusterKindDistribution.items(),\n",
    "    key=lambda x: (-x[1], x[0]),\n",
    "):\n",
    "    print(f'{amount:>5} x a {kind:>8}-cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lengths of clusters\n",
    "\n",
    "How long are clusters in general?\n",
    "There are two possible ways to measure the length of a cluster:\n",
    "\n",
    "* the amount of signs it occupies;\n",
    "* the amount of top-level members it has (quads or signs)\n",
    "\n",
    "By now, the pattern to answer questions like this is becoming familiar.\n",
    "\n",
    "We express the logic in a function, that takes the way of measuring\n",
    "as a parameter.\n",
    "In that way, we can easily provide a cluster-length distribution based\n",
    "on measurements in signs and in quads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:36:52.292833Z",
     "start_time": "2018-02-26T20:36:52.273041Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeDistribution(nodes, measure):\n",
    "    distribution = collections.Counter()\n",
    "\n",
    "    for node in nodes:\n",
    "        m = measure(node)\n",
    "        distribution[m] += 1\n",
    "\n",
    "    for (m, amount) in sorted(\n",
    "        distribution.items(),\n",
    "        key=lambda x: (-x[1], x[0]),\n",
    "    ):\n",
    "        print(f'{amount:>5} x a measure of {m:>8}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:36:53.610060Z",
     "start_time": "2018-02-26T20:36:53.592280Z"
    }
   },
   "outputs": [],
   "source": [
    "def lengthInSigns(node):\n",
    "    return len(L.d(node, otype='sign'))\n",
    "\n",
    "def lengthInMembers(node):\n",
    "    return len(E.sub.f(node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can show the length distributions of clusters by just calling `computeDistribution()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:02.770395Z",
     "start_time": "2018-02-26T20:37:02.737591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2691 x a measure of        1\n",
      "  434 x a measure of        2\n",
      "  205 x a measure of        3\n",
      "   41 x a measure of        4\n",
      "    9 x a measure of        5\n",
      "    3 x a measure of        6\n",
      "    2 x a measure of        7\n"
     ]
    }
   ],
   "source": [
    "computeDistribution(realClusters, lengthInSigns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:03.896408Z",
     "start_time": "2018-02-26T20:37:03.867457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2679 x a measure of        1\n",
      "  452 x a measure of        2\n",
      "  194 x a measure of        3\n",
      "   44 x a measure of        4\n",
      "   11 x a measure of        5\n",
      "    4 x a measure of        6\n",
      "    1 x a measure of        7\n"
     ]
    }
   ],
   "source": [
    "computeDistribution(realClusters, lengthInMembers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look closely at the code for these functions, there is nothing in it that \n",
    "is specific for clusters.\n",
    "\n",
    "The measures are in terms of the totally generic `oslots` function, and the fairly generic\n",
    "`sub` edges, which are also defined for quads.\n",
    "\n",
    "So, in one go, we can obtain a length distribution of quads.\n",
    "\n",
    "Note that quads can also be sub-quads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:07.364824Z",
     "start_time": "2018-02-26T20:37:07.328273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3717 x a measure of        2\n",
      "  181 x a measure of        3\n",
      "    7 x a measure of        4\n",
      "    1 x a measure of        5\n"
     ]
    }
   ],
   "source": [
    "computeDistribution(F.otype.s('quad'), lengthInSigns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:08.559408Z",
     "start_time": "2018-02-26T20:37:08.527664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3887 x a measure of        2\n",
      "   19 x a measure of        3\n"
     ]
    }
   ],
   "source": [
    "computeDistribution(F.otype.s('quad'), lengthInMembers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signs\n",
    "\n",
    "The main characteristic of a sign is its `grapheme`.\n",
    "Everything we do with signs, is complicated by the fact that signs can be *augmented* with\n",
    "primes, variants, modifiers and flags.\n",
    "\n",
    "Below we show how you can get frequency lists of signs, with or without taking\n",
    "augments into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing results to file\n",
    "\n",
    "We also want to write the results to files in your `_temp` directory, within this repo.\n",
    "\n",
    "`writeFreqs` writes distribution data of data items called `dataName`\n",
    "to a file `fileName.txt`.\n",
    "In fact, it writes two files: \n",
    "* `fileName-alpha.txt`, ordered by data items\n",
    "* `fileName-freq.txt`, ordered by frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:11.644537Z",
     "start_time": "2018-02-26T20:37:11.612308Z"
    }
   },
   "outputs": [],
   "source": [
    "def writeFreqs(fileName, data, dataName):\n",
    "    print(f'There are {len(data)} {dataName}s')\n",
    "\n",
    "    for (sortName, sortKey) in (\n",
    "        ('alpha', lambda x: (x[0], -x[1])),\n",
    "        ('freq', lambda x: (-x[1], x[0])),\n",
    "    ):\n",
    "        with open(f'{TEMP_DIR}/{fileName}-{sortName}.txt', 'w') as fh:\n",
    "            for (item, freq) in sorted(data, key=sortKey):\n",
    "                if item != '':\n",
    "                    fh.write(f'{freq:>5} x {item}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:13.067136Z",
     "start_time": "2018-02-26T20:37:12.947310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 667 bare graphemes\n"
     ]
    }
   ],
   "source": [
    "writeFreqs('grapheme-plain', F.grapheme.freqList(), 'bare grapheme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a look at your TEMP_DIR and you see two generated files:\n",
    "\n",
    "* `graphemes-plain-alpha.txt` (sorted by grapheme)\n",
    "* `graphemes-plain-freq.txt` (sorted by frequency)\n",
    "\n",
    "But we can do better, we also want the prime, variants, and modifiers taken into account.\n",
    "\n",
    "Let us first see what they can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prime\n",
    "\n",
    "The prime is a feature with two values: 1 or 0. 1 means: there is a prime.\n",
    "Below you see how often that occurs.\n",
    "Note that we count all primes here: on signs, case numbers and column numbers.\n",
    "\n",
    "For more info and a check on the occurrences of primes, see [checks](checks.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:15.791161Z",
     "start_time": "2018-02-26T20:37:15.769534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5184 x 1\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.prime.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variant\n",
    "\n",
    "The variant or *allograph* is what occurs after the grapheme and after the `~` symbol, which should be digits and/or\n",
    "lowercase letters except the `x`.\n",
    "\n",
    "Here is the frequency list of variant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:17.245392Z",
     "start_time": "2018-02-26T20:37:17.202992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23804 x a\n",
      " 4172 x b\n",
      " 1532 x c\n",
      " 1356 x a1\n",
      "  703 x b1\n",
      "  194 x a2\n",
      "  187 x d\n",
      "  127 x b2\n",
      "   85 x f\n",
      "   73 x a3\n",
      "   40 x e\n",
      "   29 x c2\n",
      "   22 x c1\n",
      "   22 x c3\n",
      "   17 x v\n",
      "   14 x c5\n",
      "   13 x b3\n",
      "   12 x a0\n",
      "   12 x d1\n",
      "   11 x c4\n",
      "    6 x a4\n",
      "    6 x g\n",
      "    5 x d2\n",
      "    4 x d4\n",
      "    4 x h\n",
      "    2 x 3a\n",
      "    2 x d3\n",
      "    1 x h2\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.variant.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifier\n",
    "\n",
    "The modifier is what occurs after the grapheme and after the `@` symbol, which should be digits and/or\n",
    "lowercase letters except the `x`.\n",
    "\n",
    "Sometimes modifiers occur inside a repeat, then we have stored the modifier in the feature\n",
    "*modifierInner*, as in\n",
    "\n",
    "```\n",
    "7(N34@f)\n",
    "```\n",
    "\n",
    "Here is the frequency list of *modifier* and *modifierInner* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:20.500671Z",
     "start_time": "2018-02-26T20:37:20.482349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  648 x g\n",
      "  251 x t\n",
      "   39 x n\n",
      "    6 x r\n",
      "    4 x s\n",
      "    1 x c\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifier.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T16:07:34.976083Z",
     "start_time": "2018-02-26T16:07:34.959597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 x f\n",
      "   15 x t\n",
      "    1 x r\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifierInner.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full grapheme overview\n",
    "\n",
    "We make a frequency list of all full graphemes, i.e. the grapheme including variant, modifier, and prime.\n",
    "We show them as they appear in transcriptions.\n",
    "\n",
    "First we show on what node types primes, variants and modifiers occur.\n",
    "We only deal with cases where they occur on signs, ignoring the cases where they occur on (sub)quads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:23.965370Z",
     "start_time": "2018-02-26T20:37:22.952767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prime     :  4652 x case\n",
      "prime     :   523 x column\n",
      "prime     :     9 x sign\n",
      "variant   : 32455 x sign\n",
      "modifier  :   950 x sign\n"
     ]
    }
   ],
   "source": [
    "for feature in ('prime', 'variant', 'modifier'):\n",
    "    nodeTypes = collections.Counter()\n",
    "    for n in N():\n",
    "        if Fs(feature).v(n):\n",
    "            nodeTypes[F.otype.v(n)] += 1\n",
    "    for (value, frequency) in nodeTypes.items():\n",
    "        print(f'{feature:<10}: {frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the write out the full grapheme distribution.\n",
    "Note that we use a new function, `atfFromSign`. We discuss this one and friends in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:26.574750Z",
     "start_time": "2018-02-26T20:37:25.912702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29618 x ...\n",
      "17128 x \n",
      "12996 x 1(N01)\n",
      " 6956 x X\n",
      " 3081 x 2(N01)\n",
      " 2606 x 1(N14)\n",
      " 1849 x EN~a\n",
      " 1603 x 3(N01)\n",
      " 1357 x 2(N14)\n",
      " 1308 x SZE~a\n",
      " 1304 x 5(N01)\n",
      " 1224 x GAL~a\n",
      " 1119 x 4(N01)\n",
      " 1069 x AN\n",
      " 1045 x U4\n",
      " 1001 x 1(N34)\n",
      "  881 x SAL\n",
      "  874 x GI\n",
      "  854 x PAP~a\n",
      "  801 x 1(N57)\n",
      "There are 1529 full graphemes\n"
     ]
    }
   ],
   "source": [
    "fullGraphemes = collections.Counter()\n",
    "\n",
    "for n in F.otype.s('sign'):\n",
    "    fullGrapheme = CUNEI.atfFromSign(n)\n",
    "    fullGraphemes[fullGrapheme] += 1\n",
    "    \n",
    "for (value, frequency) in sorted(fullGraphemes.items(), key=lambda x: (-x[1], x[0]))[0:20]:\n",
    "    print(f'{frequency:>5} x {value}')\n",
    "    \n",
    "writeFreqs('grapheme-full', fullGraphemes.items(), 'full grapheme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at your `_temp` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation\n",
    "\n",
    "For line based concepts, such as tablet, face, column, case, comment, you can get the source\n",
    "material by requesting the feature *srcLn*.\n",
    "\n",
    "For inline concepts, such as clusters, quads, and signs, there is no such feature, so one has\n",
    "to wind down the TF data and produce the right ASCII characters.\n",
    "However, it is not completely trivial to generate ATF representations for those entities.\n",
    "Several subtleties are involved.\n",
    "\n",
    "In order to free you (and myself) from spelling out the logic over and over again, I have bundled a\n",
    "few functions that generate ATF representations from TF data:\n",
    "\n",
    "* `atfFromSign(sign, flags=False)`\n",
    "\n",
    "  Returns the ATF representation for a sign, including primes, repeats, variants, modifiers,\n",
    "  and, optionally, flags.\n",
    "\n",
    "\n",
    "* `atfFromQuad(quad, flags=False)`\n",
    "\n",
    "  Returns the ATF representation for a quad, including variants, modifiers,\n",
    "  and, optionally, flags. For the signs belonging to this quad, the\n",
    "  `flags` argument will determine whether the flags will be represented.\n",
    "\n",
    "* `atfFromCluster(cluster)`\n",
    "\n",
    "  Returns the ATF representation for a cluster, including the brackets.\n",
    "  All quads belonging to the cluster will be represented with flags.\n",
    "  Nested clusters will also be represented.\n",
    "\n",
    "These functions have been added to Text-Fabric itself, as a submodule.\n",
    "If you have installed TF (newest version), you have to say in the beginning:\n",
    "\n",
    "```python\n",
    "from tf.cunei import Cunei\n",
    "```\n",
    "\n",
    "And then after you have loaded the TF-API (`api = ...`):\n",
    "\n",
    "```python\n",
    "CUNEI = Cunei(api)\n",
    "```\n",
    "\n",
    "And then you can use the functions:\n",
    "\n",
    "```python\n",
    "print(CUNEI.atfFromQuad(q)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us pick a sign, a quad, and a cluster to represent.\n",
    "We pick them from our example tablet P005138."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:30.408389Z",
     "start_time": "2018-02-26T20:37:30.385988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 3(N04) , |GISZ.TE| GAR |SZU2.((HI+1(N57))+(HI+1(N57)))| GI4~a'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = T.nodeFromSection(('P005381', 'obverse:2', '1'))\n",
    "case = L.d(line, otype='case')[0]\n",
    "F.srcLn.v(case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we stored the big quad in the variable `bigQuad`. \n",
    "Let's see what `atfFromQuad` will get from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:31.704082Z",
     "start_time": "2018-02-26T20:37:31.686548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|SZU2.((HI+1(N57))+(HI+1(N57)))|'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUNEI.atfFromQuad(bigQuad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In P000736 there is a nice quad to show off with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:34.280961Z",
     "start_time": "2018-02-26T20:37:34.257949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3. 1(N14) , |(SZAxHI@g~a)~b|#?'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = T.nodeFromSection(('P000736', 'obverse:2', '3'))\n",
    "case = [\n",
    "    case\n",
    "    for case in L.d(line, otype='case')\n",
    "    if F.fullNumber.v(case) == \"3\"\n",
    "][0]\n",
    "F.srcLn.v(case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the big quad.\n",
    "The first thing, `1(N14)`, is a simple sign, not a quad, so we need the first quad in the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:36.034506Z",
     "start_time": "2018-02-26T20:37:36.015496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|(SZAxHI@g~a)~b|'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quad = L.d(case, otype='quad')[0]\n",
    "CUNEI.atfFromQuad(quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right. Now with flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:37.971932Z",
     "start_time": "2018-02-26T20:37:37.954647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|(SZAxHI@g~a)~b|#?'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUNEI.atfFromQuad(quad, flags=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a cluster. Let's pick one with a cluster nested in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:39.570821Z",
     "start_time": "2018-02-26T20:37:39.548251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"2.b4'. , (IDIGNA [...])a \""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = T.nodeFromSection(('P471695', 'obverse:1', '2'))\n",
    "case = [\n",
    "    case\n",
    "    for case in L.d(line, otype='case')\n",
    "    if F.fullNumber.v(case) == \"2b4'\"\n",
    "][0]\n",
    "F.srcLn.v(case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick the outer cluster from this case. \n",
    "Remember that TF has order nodes so that nodes that have earlier slots\n",
    "come before nodes that have later slots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:43.309030Z",
     "start_time": "2018-02-26T20:37:43.286648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(IDIGNA [...])a'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigCluster = L.d(case, otype='cluster')[0]\n",
    "CUNEI.atfFromCluster(bigCluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collation\n",
    "\n",
    "We end this tutorial with a cliff hanger: collation.\n",
    "\n",
    "For the study of cuneiform corpora it is useful to know which signs co-occur: on tablets and faces,\n",
    "in columns and lines, and in cases.\n",
    "\n",
    "Here we just show how to compute collation information with respect to tablets.\n",
    "\n",
    "We refer to a future notebook [collation](collation.ipynb) that will be dedicated to the art and craft\n",
    "of collation.\n",
    "\n",
    "### TF ad\n",
    "Already the task of computing collation of signs for tablets shows a typical pattern in the modus operandi of Text-Fabric. In order to compute collation efficiently, we have to grab a significant swath of the data, and reorganise it before we can do business.\n",
    "\n",
    "**The bad news is**: Text-Fabric does not have the right organization for this particular problem.\n",
    "\n",
    "**The good news is**: You can put the data in the right order.\n",
    "\n",
    "**The best news is**: because of the IKEA-like organization of the data in TF, you can easily\n",
    "put your bits and pieces in a cart, walk outside, and stack it in new ways to your liking.\n",
    "Indeed, the bit that draws the data from TF and puts it into the required form, is only\n",
    "a few lines of code.\n",
    "\n",
    "### Back to collation\n",
    "\n",
    "This is what we do:\n",
    "\n",
    "* we collect all pairs of signs that co-occur on a tablet\n",
    "* we compute a measure of co-occurrence: \n",
    "  * closer together is better\n",
    "  * more tablets with the same co-occurence is better\n",
    "  \n",
    "We explain the steps as we go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect sign-pairs\n",
    "\n",
    "We want signs with primes, variants and modifiers, but without flags.\n",
    "\n",
    "In a first round, we collect all pairs of signs that have a co-occurrence on a tablet.\n",
    "\n",
    "Suppose two signs co-occur on a tablet.\n",
    "Both may have multiple occurrences.\n",
    "\n",
    "The question is: what is a sensible measure for the the degree of co-occurrence of that pair on\n",
    "that tablet?\n",
    "\n",
    "In this tutorial we ignore the faces, columns, lines and cases that the signs occur in.\n",
    "The only thing that counts is the distance between two occurrences, seen as slots.\n",
    "Every sign has a sequence number, its slot number, which tells you where the sign stands in the whole\n",
    "corpus. The distance between two slots is just the difference of those slots as numbers.\n",
    "\n",
    "The distance between two signs on a tablet is the minumum distance you can find between an occurence\n",
    "of the one and an occurrence of the other.\n",
    "\n",
    "In fact, we turn distance into closeness.\n",
    "If, on a tablet of 200 signs long, there are signs with occurrences on 40 and 60,\n",
    "their distance is 20, but there closeness is 200 - 20 = 180.\n",
    "We shall make that closeness proportional to the length of the tablet (in signs): \n",
    "180 / 200 = 0.9\n",
    "\n",
    "The same signs may co-occur on other tablet. We also compute the relative closeness there.\n",
    "In the end, we add it all up.\n",
    "\n",
    "So every pair of signs gets a measure that expresses the total relative closeness of its co-occurrences\n",
    "on all tablets where they co-occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to visit nodes multiple times and get their atf representation,\n",
    "so we do it once for all and store them.\n",
    "\n",
    "We exclude the empty graphemes and the `…` , `X` graphemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:47.406938Z",
     "start_time": "2018-02-26T20:37:46.846170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6 = 3(N14)\n",
      " 8 = SANGA~a\n",
      "22 = 3(N14)\n",
      "24 = 1(N14)\n",
      "25 = SUHUR\n",
      "28 = 1(N01)\n",
      "29 = DUG~b\n",
      "30 = 1(N57)\n",
      "41 = 1(N46)\n",
      "42 = 2(N19)\n",
      "43 = 4(N41)\n",
      "44 = AB~a\n",
      "45 = APIN~a\n",
      "46 = NUN~a\n",
      "51 = SZE~a\n",
      "52 = DU\n",
      "53 = NUN~a\n",
      "58 = n\n",
      "60 = KA~a\n",
      "61 = n\n",
      "62 = 2(N14)\n"
     ]
    }
   ],
   "source": [
    "NA = {'', '…', 'X'}\n",
    "\n",
    "signFromNode = dict()\n",
    "\n",
    "for tablet in F.otype.s('tablet'):\n",
    "    for s in L.d(tablet, otype='sign'):\n",
    "        if F.grapheme.v(s) in NA:\n",
    "            continue\n",
    "        signFromNode[s] = CUNEI.atfFromSign(s)\n",
    "len(signFromNode)\n",
    "\n",
    "LIMIT = 20\n",
    "n = 0\n",
    "for i in sorted(signFromNode):\n",
    "    print(f'{i:>2} = {signFromNode[i]}')\n",
    "    n += 1\n",
    "    if n > LIMIT:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T15:06:05.444996Z",
     "start_time": "2018-02-26T15:06:05.427419Z"
    }
   },
   "source": [
    "Now we work per tablet.\n",
    "First we collect the relevant sign slots in a list.\n",
    "\n",
    "Then we loop through all distinct pairs of slots of that list, and store the difference between the slots\n",
    "for each pair.\n",
    "If we encounter the same pair with a smaller difference, we replace the bigger difference with the smaller one.\n",
    "We end up with a dictionary that gives for each pair of signs the minimal difference.\n",
    "\n",
    "Then we turn distance into closeness and make it proportional to the length of the tablet, for all pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:50.558370Z",
     "start_time": "2018-02-26T20:37:49.280242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6903"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = collections.Counter()\n",
    "\n",
    "for tablet in F.otype.s('tablet'):\n",
    "    slots = L.d(tablet, otype='sign')\n",
    "    length = slots[-1] - slots[0]\n",
    "    thesePairs = {}\n",
    "    for i in range(len(slots)):\n",
    "        if i not in signFromNode:\n",
    "            continue\n",
    "        signI = signFromNode[i]\n",
    "        for j in range(i + 1, len(slots)):\n",
    "            if j not in signFromNode:\n",
    "                continue\n",
    "            signJ = signFromNode[j]\n",
    "            if signJ == signI:\n",
    "                continue\n",
    "            pair = (signI, signJ) if signI < signJ else (signJ, signI)\n",
    "            difference = j - i\n",
    "            oldDifference = thesePairs.get(pair, None)\n",
    "            if oldDifference is None or oldDifference > difference:\n",
    "                thesePairs[pair] = difference\n",
    "    for ((signI, signJ), difference) in thesePairs.items():\n",
    "        relativeCloseness = (length - difference) / length\n",
    "        pairs[(signI, signJ)] += relativeCloseness\n",
    "\n",
    "len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is quicker than expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:52.400597Z",
     "start_time": "2018-02-26T20:37:52.363942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3(N14)     <=> SANGA~a    at closeness 3946.86\n",
      "1(N14)     <=> 3(N14)     at closeness 1691.75\n",
      "1(N14)     <=> SUHUR      at closeness 1658.29\n",
      "3(N14)     <=> SUHUR      at closeness 1574.87\n",
      "1(N01)     <=> DUG~b      at closeness 1371.65\n",
      "1(N01)     <=> SUHUR      at closeness 1368.98\n",
      "1(N01)     <=> 1(N14)     at closeness 1336.39\n",
      "1(N57)     <=> DUG~b      at closeness 1309.85\n",
      "1(N01)     <=> 1(N57)     at closeness 1281.73\n",
      "DUG~b      <=> SUHUR      at closeness 1280.59\n",
      "1(N01)     <=> 3(N14)     at closeness 1270.95\n",
      "1(N14)     <=> DUG~b      at closeness 1250.23\n",
      "1(N57)     <=> SUHUR      at closeness 1197.27\n",
      "3(N14)     <=> DUG~b      at closeness 1189.53\n",
      "1(N14)     <=> 1(N57)     at closeness 1169.12\n",
      "1(N57)     <=> 3(N14)     at closeness 1112.83\n",
      "1(N14)     <=> SANGA~a    at closeness 1060.48\n",
      "SANGA~a    <=> SUHUR      at closeness  990.93\n",
      "1(N01)     <=> SANGA~a    at closeness  814.83\n",
      "1(N46)     <=> 2(N19)     at closeness  772.78\n",
      "DUG~b      <=> SANGA~a    at closeness  764.58\n",
      "2(N19)     <=> 4(N41)     at closeness  736.66\n",
      "1(N46)     <=> 4(N41)     at closeness  725.33\n",
      "1(N57)     <=> SANGA~a    at closeness  718.78\n",
      "4(N41)     <=> AB~a       at closeness  702.48\n",
      "2(N19)     <=> AB~a       at closeness  691.95\n",
      "1(N46)     <=> 1(N57)     at closeness  682.80\n",
      "1(N46)     <=> AB~a       at closeness  681.43\n",
      "AB~a       <=> APIN~a     at closeness  670.23\n",
      "1(N46)     <=> DUG~b      at closeness  669.51\n",
      "4(N41)     <=> APIN~a     at closeness  660.45\n",
      "1(N01)     <=> 1(N46)     at closeness  656.21\n",
      "2(N19)     <=> APIN~a     at closeness  650.68\n",
      "1(N46)     <=> APIN~a     at closeness  640.91\n",
      "APIN~a     <=> NUN~a      at closeness  638.94\n",
      "1(N57)     <=> 2(N19)     at closeness  638.38\n",
      "AB~a       <=> NUN~a      at closeness  629.88\n",
      "2(N19)     <=> DUG~b      at closeness  626.17\n",
      "4(N41)     <=> NUN~a      at closeness  620.81\n",
      "1(N46)     <=> SUHUR      at closeness  616.34\n",
      "1(N01)     <=> 2(N19)     at closeness  613.95\n",
      "2(N19)     <=> NUN~a      at closeness  611.75\n",
      "1(N14)     <=> 1(N46)     at closeness  603.05\n",
      "1(N46)     <=> NUN~a      at closeness  602.69\n",
      "1(N57)     <=> 4(N41)     at closeness  600.62\n",
      "4(N41)     <=> DUG~b      at closeness  589.28\n",
      "1(N01)     <=> 4(N41)     at closeness  577.94\n",
      "2(N19)     <=> SUHUR      at closeness  577.29\n",
      "1(N46)     <=> 3(N14)     at closeness  576.47\n",
      "1(N57)     <=> AB~a       at closeness  565.68\n",
      "1(N14)     <=> 2(N19)     at closeness  565.07\n",
      "AB~a       <=> DUG~b      at closeness  555.15\n",
      "1(N01)     <=> AB~a       at closeness  544.83\n",
      "4(N41)     <=> SUHUR      at closeness  543.93\n",
      "2(N19)     <=> 3(N14)     at closeness  540.64\n",
      "NUN~a      <=> SZE~a      at closeness  536.97\n",
      "1(N57)     <=> APIN~a     at closeness  533.40\n",
      "1(N14)     <=> 4(N41)     at closeness  532.59\n",
      "DU         <=> SZE~a      at closeness  532.19\n",
      "DU         <=> NUN~a      at closeness  530.46\n",
      "APIN~a     <=> DUG~b      at closeness  523.63\n",
      "1(N01)     <=> APIN~a     at closeness  513.86\n",
      "AB~a       <=> SUHUR      at closeness  513.06\n",
      "APIN~a     <=> SZE~a      at closeness  510.51\n",
      "3(N14)     <=> 4(N41)     at closeness  509.92\n",
      "AB~a       <=> SZE~a      at closeness  503.43\n",
      "1(N57)     <=> NUN~a      at closeness  503.01\n",
      "1(N14)     <=> AB~a       at closeness  502.54\n",
      "4(N41)     <=> SZE~a      at closeness  496.35\n",
      "DUG~b      <=> NUN~a      at closeness  493.95\n",
      "APIN~a     <=> DU         at closeness  493.85\n",
      "1(N01)     <=> NUN~a      at closeness  493.65\n",
      "2(N19)     <=> SZE~a      at closeness  489.27\n",
      "AB~a       <=> DU         at closeness  484.54\n",
      "APIN~a     <=> SUHUR      at closeness  484.54\n",
      "1(N14)     <=> APIN~a     at closeness  482.79\n",
      "1(N46)     <=> SZE~a      at closeness  482.18\n",
      "3(N14)     <=> AB~a       at closeness  481.49\n",
      "4(N41)     <=> DU         at closeness  477.74\n",
      "2(N19)     <=> DU         at closeness  470.93\n",
      "1(N46)     <=> DU         at closeness  464.12\n",
      "NUN~a      <=> SUHUR      at closeness  457.70\n",
      "3(N14)     <=> APIN~a     at closeness  455.22\n",
      "1(N14)     <=> NUN~a      at closeness  448.63\n",
      "NUN~a      <=> n          at closeness  433.38\n",
      "3(N14)     <=> NUN~a      at closeness  430.51\n",
      "DU         <=> n          at closeness  424.35\n",
      "KA~a       <=> n          at closeness  423.95\n",
      "SZE~a      <=> n          at closeness  419.07\n",
      "1(N57)     <=> SZE~a      at closeness  404.29\n",
      "KA~a       <=> NUN~a      at closeness  402.83\n",
      "2(N14)     <=> n          at closeness  398.62\n",
      "DUG~b      <=> SZE~a      at closeness  397.20\n",
      "2(N14)     <=> KA~a       at closeness  394.23\n",
      "DU         <=> KA~a       at closeness  390.50\n",
      "1(N46)     <=> SANGA~a    at closeness  390.39\n",
      "1(N01)     <=> SZE~a      at closeness  390.23\n",
      "1(N57)     <=> DU         at closeness  389.24\n",
      "APIN~a     <=> n          at closeness  387.42\n",
      "2(N14)     <=> NUN~a      at closeness  386.13\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for ((signI, signJ), closeness) in sorted(pairs.items(), key=lambda x: (-x[1], x[0]))[0:100]:\n",
    "    print(f'{signI:<10} <=> {signJ:<10} at closeness {closeness:>7.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print all collocations to the file\n",
    "[collocations-tablet.tsv](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/collocations-tablet.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:54.888472Z",
     "start_time": "2018-02-26T20:37:54.844257Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{REPORT_DIR}/collocations-tablet.tsv', 'w') as fh:\n",
    "    fh.write(f'sign1\\tsign2\\tcloseness\\n')\n",
    "    for ((signI, signJ), closeness) in sorted(pairs.items(), key=lambda x: (-x[1], x[0])):\n",
    "        fh.write(f'{signI}\\t{signJ}\\t{closeness:>7.2f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we show an overview of how the closeness of collocated pairs is distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T20:37:56.768712Z",
     "start_time": "2018-02-26T20:37:56.719806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 420 pairs with closeness ~    0\n",
      "1445 pairs with closeness ~    1\n",
      " 703 pairs with closeness ~    2\n",
      " 384 pairs with closeness ~    3\n",
      " 336 pairs with closeness ~    4\n",
      " 163 pairs with closeness ~    5\n",
      " 258 pairs with closeness ~    6\n",
      " 171 pairs with closeness ~    7\n",
      " 107 pairs with closeness ~    8\n",
      " 125 pairs with closeness ~    9\n",
      "  88 pairs with closeness ~   10\n",
      "  80 pairs with closeness ~   11\n",
      " 107 pairs with closeness ~   12\n",
      "  91 pairs with closeness ~   13\n",
      " 101 pairs with closeness ~   14\n",
      " 104 pairs with closeness ~   15\n",
      " 120 pairs with closeness ~   16\n",
      "  67 pairs with closeness ~   17\n",
      "  68 pairs with closeness ~   18\n",
      "  75 pairs with closeness ~   19\n",
      "  63 pairs with closeness ~   20\n",
      "  58 pairs with closeness ~   21\n",
      "  55 pairs with closeness ~   22\n",
      "  43 pairs with closeness ~   23\n",
      "  61 pairs with closeness ~   24\n",
      "  65 pairs with closeness ~   25\n",
      "  60 pairs with closeness ~   26\n",
      "  29 pairs with closeness ~   27\n",
      "  26 pairs with closeness ~   28\n",
      "  24 pairs with closeness ~   29\n",
      "  25 pairs with closeness ~   30\n",
      "  25 pairs with closeness ~   31\n",
      "  32 pairs with closeness ~   32\n",
      "  19 pairs with closeness ~   33\n",
      "  23 pairs with closeness ~   34\n",
      "  28 pairs with closeness ~   35\n",
      "  17 pairs with closeness ~   36\n",
      "  20 pairs with closeness ~   37\n",
      "  14 pairs with closeness ~   38\n",
      "  17 pairs with closeness ~   39\n",
      "  18 pairs with closeness ~   40\n",
      "   9 pairs with closeness ~   41\n",
      "  11 pairs with closeness ~   42\n",
      "  27 pairs with closeness ~   43\n",
      "  19 pairs with closeness ~   44\n",
      "  19 pairs with closeness ~   45\n",
      "  18 pairs with closeness ~   46\n",
      "  15 pairs with closeness ~   47\n",
      "  19 pairs with closeness ~   48\n",
      "  15 pairs with closeness ~   49\n",
      "  18 pairs with closeness ~   50\n",
      "  16 pairs with closeness ~   51\n",
      "  17 pairs with closeness ~   52\n",
      "  15 pairs with closeness ~   53\n",
      "  16 pairs with closeness ~   54\n",
      "  15 pairs with closeness ~   55\n",
      "   9 pairs with closeness ~   56\n",
      "  10 pairs with closeness ~   57\n",
      "  11 pairs with closeness ~   58\n",
      "  12 pairs with closeness ~   59\n",
      "  13 pairs with closeness ~   60\n",
      "  10 pairs with closeness ~   61\n",
      "  12 pairs with closeness ~   62\n",
      "  10 pairs with closeness ~   63\n",
      "   5 pairs with closeness ~   64\n",
      "  10 pairs with closeness ~   65\n",
      "  15 pairs with closeness ~   66\n",
      "  12 pairs with closeness ~   67\n",
      "   7 pairs with closeness ~   68\n",
      "   5 pairs with closeness ~   69\n",
      "  11 pairs with closeness ~   70\n",
      "   6 pairs with closeness ~   71\n",
      "   8 pairs with closeness ~   72\n",
      "  11 pairs with closeness ~   73\n",
      "  14 pairs with closeness ~   74\n",
      "   6 pairs with closeness ~   75\n",
      "   6 pairs with closeness ~   76\n",
      "   6 pairs with closeness ~   77\n",
      "   7 pairs with closeness ~   78\n",
      "   6 pairs with closeness ~   79\n",
      "   6 pairs with closeness ~   80\n",
      "  11 pairs with closeness ~   81\n",
      "   5 pairs with closeness ~   82\n",
      "  10 pairs with closeness ~   83\n",
      "   8 pairs with closeness ~   84\n",
      "  11 pairs with closeness ~   85\n",
      "  11 pairs with closeness ~   86\n",
      "   9 pairs with closeness ~   87\n",
      "   9 pairs with closeness ~   88\n",
      "   8 pairs with closeness ~   89\n",
      "   9 pairs with closeness ~   90\n",
      "   5 pairs with closeness ~   91\n",
      "   6 pairs with closeness ~   92\n",
      "   8 pairs with closeness ~   93\n",
      "   7 pairs with closeness ~   94\n",
      "   8 pairs with closeness ~   95\n",
      "   4 pairs with closeness ~   96\n",
      "  12 pairs with closeness ~   97\n",
      "   7 pairs with closeness ~   98\n",
      "   8 pairs with closeness ~   99\n",
      "   8 pairs with closeness ~  100\n",
      "   7 pairs with closeness ~  101\n",
      "   4 pairs with closeness ~  102\n",
      "   4 pairs with closeness ~  103\n",
      "   5 pairs with closeness ~  104\n",
      "   3 pairs with closeness ~  105\n",
      "   5 pairs with closeness ~  106\n",
      "   4 pairs with closeness ~  107\n",
      "   4 pairs with closeness ~  108\n",
      "   4 pairs with closeness ~  109\n",
      "   5 pairs with closeness ~  110\n",
      "   4 pairs with closeness ~  111\n",
      "   3 pairs with closeness ~  112\n",
      "   5 pairs with closeness ~  113\n",
      "   7 pairs with closeness ~  114\n",
      "   5 pairs with closeness ~  115\n",
      "   8 pairs with closeness ~  116\n",
      "   3 pairs with closeness ~  117\n",
      "   5 pairs with closeness ~  118\n",
      "   3 pairs with closeness ~  119\n",
      "   5 pairs with closeness ~  120\n",
      "   5 pairs with closeness ~  121\n",
      "   5 pairs with closeness ~  122\n",
      "   4 pairs with closeness ~  123\n",
      "   4 pairs with closeness ~  124\n",
      "   5 pairs with closeness ~  125\n",
      "   3 pairs with closeness ~  126\n",
      "   3 pairs with closeness ~  127\n",
      "   3 pairs with closeness ~  128\n",
      "   3 pairs with closeness ~  129\n",
      "   4 pairs with closeness ~  130\n",
      "   3 pairs with closeness ~  131\n",
      "   3 pairs with closeness ~  132\n",
      "   2 pairs with closeness ~  133\n",
      "   1 pairs with closeness ~  134\n",
      "   2 pairs with closeness ~  135\n",
      "   2 pairs with closeness ~  137\n",
      "   1 pairs with closeness ~  138\n",
      "   2 pairs with closeness ~  140\n",
      "   1 pairs with closeness ~  141\n",
      "   1 pairs with closeness ~  142\n",
      "   1 pairs with closeness ~  143\n",
      "   1 pairs with closeness ~  144\n",
      "   1 pairs with closeness ~  154\n",
      "   1 pairs with closeness ~  155\n",
      "   2 pairs with closeness ~  157\n",
      "   2 pairs with closeness ~  159\n",
      "   1 pairs with closeness ~  160\n",
      "   1 pairs with closeness ~  161\n",
      "   1 pairs with closeness ~  163\n",
      "   1 pairs with closeness ~  164\n",
      "   7 pairs with closeness ~  165\n",
      "   1 pairs with closeness ~  166\n",
      "   1 pairs with closeness ~  167\n",
      "   2 pairs with closeness ~  168\n",
      "   2 pairs with closeness ~  169\n",
      "   4 pairs with closeness ~  171\n",
      "   1 pairs with closeness ~  173\n",
      "   4 pairs with closeness ~  174\n",
      "   1 pairs with closeness ~  176\n",
      "   1 pairs with closeness ~  177\n",
      "   1 pairs with closeness ~  178\n",
      "   2 pairs with closeness ~  179\n",
      "   2 pairs with closeness ~  180\n",
      "   2 pairs with closeness ~  181\n",
      "   2 pairs with closeness ~  182\n",
      "   1 pairs with closeness ~  183\n",
      "   2 pairs with closeness ~  185\n",
      "   1 pairs with closeness ~  186\n",
      "   2 pairs with closeness ~  187\n",
      "   3 pairs with closeness ~  188\n",
      "   1 pairs with closeness ~  189\n",
      "   2 pairs with closeness ~  190\n",
      "   1 pairs with closeness ~  191\n",
      "   2 pairs with closeness ~  192\n",
      "   1 pairs with closeness ~  194\n",
      "   1 pairs with closeness ~  196\n",
      "   2 pairs with closeness ~  197\n",
      "   1 pairs with closeness ~  198\n",
      "   1 pairs with closeness ~  201\n",
      "   1 pairs with closeness ~  202\n",
      "   1 pairs with closeness ~  203\n",
      "   1 pairs with closeness ~  204\n",
      "   1 pairs with closeness ~  205\n",
      "   1 pairs with closeness ~  206\n",
      "   2 pairs with closeness ~  208\n",
      "   1 pairs with closeness ~  209\n",
      "   2 pairs with closeness ~  210\n",
      "   2 pairs with closeness ~  211\n",
      "   1 pairs with closeness ~  212\n",
      "   2 pairs with closeness ~  213\n",
      "   2 pairs with closeness ~  214\n",
      "   3 pairs with closeness ~  216\n",
      "   1 pairs with closeness ~  217\n",
      "   2 pairs with closeness ~  218\n",
      "   3 pairs with closeness ~  219\n",
      "   1 pairs with closeness ~  220\n",
      "   3 pairs with closeness ~  221\n",
      "   2 pairs with closeness ~  222\n",
      "   2 pairs with closeness ~  223\n",
      "   1 pairs with closeness ~  224\n",
      "   2 pairs with closeness ~  225\n",
      "   2 pairs with closeness ~  227\n",
      "   2 pairs with closeness ~  228\n",
      "   1 pairs with closeness ~  229\n",
      "   2 pairs with closeness ~  230\n",
      "   2 pairs with closeness ~  231\n",
      "   1 pairs with closeness ~  232\n",
      "   2 pairs with closeness ~  233\n",
      "   1 pairs with closeness ~  235\n",
      "   2 pairs with closeness ~  236\n",
      "   1 pairs with closeness ~  237\n",
      "   3 pairs with closeness ~  239\n",
      "   3 pairs with closeness ~  240\n",
      "   1 pairs with closeness ~  241\n",
      "   2 pairs with closeness ~  242\n",
      "   4 pairs with closeness ~  244\n",
      "   1 pairs with closeness ~  245\n",
      "   2 pairs with closeness ~  246\n",
      "   3 pairs with closeness ~  247\n",
      "   1 pairs with closeness ~  248\n",
      "   1 pairs with closeness ~  249\n",
      "   3 pairs with closeness ~  250\n",
      "   1 pairs with closeness ~  251\n",
      "   2 pairs with closeness ~  252\n",
      "   2 pairs with closeness ~  253\n",
      "   2 pairs with closeness ~  255\n",
      "   2 pairs with closeness ~  256\n",
      "   2 pairs with closeness ~  257\n",
      "   2 pairs with closeness ~  258\n",
      "   2 pairs with closeness ~  259\n",
      "   1 pairs with closeness ~  260\n",
      "   2 pairs with closeness ~  261\n",
      "   1 pairs with closeness ~  262\n",
      "   2 pairs with closeness ~  263\n",
      "   1 pairs with closeness ~  264\n",
      "   1 pairs with closeness ~  265\n",
      "   3 pairs with closeness ~  266\n",
      "   1 pairs with closeness ~  267\n",
      "   1 pairs with closeness ~  273\n",
      "   1 pairs with closeness ~  276\n",
      "   2 pairs with closeness ~  277\n",
      "   2 pairs with closeness ~  278\n",
      "   2 pairs with closeness ~  280\n",
      "   1 pairs with closeness ~  281\n",
      "   1 pairs with closeness ~  282\n",
      "   2 pairs with closeness ~  283\n",
      "   1 pairs with closeness ~  284\n",
      "   1 pairs with closeness ~  285\n",
      "   1 pairs with closeness ~  286\n",
      "   2 pairs with closeness ~  287\n",
      "   2 pairs with closeness ~  288\n",
      "   1 pairs with closeness ~  289\n",
      "   1 pairs with closeness ~  290\n",
      "   2 pairs with closeness ~  291\n",
      "   2 pairs with closeness ~  292\n",
      "   1 pairs with closeness ~  293\n",
      "   1 pairs with closeness ~  294\n",
      "   3 pairs with closeness ~  295\n",
      "   2 pairs with closeness ~  297\n",
      "   1 pairs with closeness ~  298\n",
      "   1 pairs with closeness ~  299\n",
      "   2 pairs with closeness ~  300\n",
      "   1 pairs with closeness ~  301\n",
      "   3 pairs with closeness ~  303\n",
      "   2 pairs with closeness ~  304\n",
      "   1 pairs with closeness ~  305\n",
      "   2 pairs with closeness ~  306\n",
      "   1 pairs with closeness ~  307\n",
      "   1 pairs with closeness ~  308\n",
      "   1 pairs with closeness ~  309\n",
      "   1 pairs with closeness ~  310\n",
      "   1 pairs with closeness ~  311\n",
      "   1 pairs with closeness ~  312\n",
      "   1 pairs with closeness ~  313\n",
      "   1 pairs with closeness ~  315\n",
      "   2 pairs with closeness ~  316\n",
      "   1 pairs with closeness ~  318\n",
      "   1 pairs with closeness ~  319\n",
      "   1 pairs with closeness ~  320\n",
      "   1 pairs with closeness ~  322\n",
      "   1 pairs with closeness ~  323\n",
      "   1 pairs with closeness ~  324\n",
      "   2 pairs with closeness ~  325\n",
      "   1 pairs with closeness ~  326\n",
      "   2 pairs with closeness ~  328\n",
      "   2 pairs with closeness ~  329\n",
      "   1 pairs with closeness ~  330\n",
      "   1 pairs with closeness ~  332\n",
      "   1 pairs with closeness ~  333\n",
      "   2 pairs with closeness ~  335\n",
      "   1 pairs with closeness ~  337\n",
      "   1 pairs with closeness ~  338\n",
      "   1 pairs with closeness ~  340\n",
      "   1 pairs with closeness ~  341\n",
      "   1 pairs with closeness ~  342\n",
      "   2 pairs with closeness ~  347\n",
      "   1 pairs with closeness ~  348\n",
      "   1 pairs with closeness ~  351\n",
      "   1 pairs with closeness ~  352\n",
      "   2 pairs with closeness ~  355\n",
      "   2 pairs with closeness ~  357\n",
      "   1 pairs with closeness ~  359\n",
      "   1 pairs with closeness ~  361\n",
      "   1 pairs with closeness ~  364\n",
      "   1 pairs with closeness ~  365\n",
      "   1 pairs with closeness ~  366\n",
      "   1 pairs with closeness ~  367\n",
      "   1 pairs with closeness ~  368\n",
      "   2 pairs with closeness ~  369\n",
      "   1 pairs with closeness ~  370\n",
      "   1 pairs with closeness ~  372\n",
      "   2 pairs with closeness ~  376\n",
      "   1 pairs with closeness ~  377\n",
      "   2 pairs with closeness ~  380\n",
      "   2 pairs with closeness ~  382\n",
      "   1 pairs with closeness ~  384\n",
      "   2 pairs with closeness ~  386\n",
      "   1 pairs with closeness ~  387\n",
      "   1 pairs with closeness ~  389\n",
      "   3 pairs with closeness ~  390\n",
      "   1 pairs with closeness ~  394\n",
      "   1 pairs with closeness ~  397\n",
      "   1 pairs with closeness ~  399\n",
      "   1 pairs with closeness ~  403\n",
      "   1 pairs with closeness ~  404\n",
      "   1 pairs with closeness ~  419\n",
      "   2 pairs with closeness ~  424\n",
      "   1 pairs with closeness ~  431\n",
      "   1 pairs with closeness ~  433\n",
      "   1 pairs with closeness ~  449\n",
      "   1 pairs with closeness ~  455\n",
      "   1 pairs with closeness ~  458\n",
      "   1 pairs with closeness ~  464\n",
      "   1 pairs with closeness ~  471\n",
      "   1 pairs with closeness ~  478\n",
      "   1 pairs with closeness ~  481\n",
      "   1 pairs with closeness ~  482\n",
      "   1 pairs with closeness ~  483\n",
      "   2 pairs with closeness ~  485\n",
      "   1 pairs with closeness ~  489\n",
      "   3 pairs with closeness ~  494\n",
      "   1 pairs with closeness ~  496\n",
      "   3 pairs with closeness ~  503\n",
      "   1 pairs with closeness ~  510\n",
      "   1 pairs with closeness ~  511\n",
      "   1 pairs with closeness ~  513\n",
      "   1 pairs with closeness ~  514\n",
      "   1 pairs with closeness ~  524\n",
      "   1 pairs with closeness ~  530\n",
      "   1 pairs with closeness ~  532\n",
      "   2 pairs with closeness ~  533\n",
      "   1 pairs with closeness ~  537\n",
      "   1 pairs with closeness ~  541\n",
      "   1 pairs with closeness ~  544\n",
      "   1 pairs with closeness ~  545\n",
      "   1 pairs with closeness ~  555\n",
      "   1 pairs with closeness ~  565\n",
      "   1 pairs with closeness ~  566\n",
      "   1 pairs with closeness ~  576\n",
      "   1 pairs with closeness ~  577\n",
      "   1 pairs with closeness ~  578\n",
      "   1 pairs with closeness ~  589\n",
      "   1 pairs with closeness ~  601\n",
      "   2 pairs with closeness ~  603\n",
      "   1 pairs with closeness ~  612\n",
      "   1 pairs with closeness ~  614\n",
      "   1 pairs with closeness ~  616\n",
      "   1 pairs with closeness ~  621\n",
      "   1 pairs with closeness ~  626\n",
      "   1 pairs with closeness ~  630\n",
      "   1 pairs with closeness ~  638\n",
      "   1 pairs with closeness ~  639\n",
      "   1 pairs with closeness ~  641\n",
      "   1 pairs with closeness ~  651\n",
      "   1 pairs with closeness ~  656\n",
      "   1 pairs with closeness ~  660\n",
      "   2 pairs with closeness ~  670\n",
      "   1 pairs with closeness ~  681\n",
      "   1 pairs with closeness ~  683\n",
      "   1 pairs with closeness ~  692\n",
      "   1 pairs with closeness ~  702\n",
      "   1 pairs with closeness ~  719\n",
      "   1 pairs with closeness ~  725\n",
      "   1 pairs with closeness ~  737\n",
      "   1 pairs with closeness ~  765\n",
      "   1 pairs with closeness ~  773\n",
      "   1 pairs with closeness ~  815\n",
      "   1 pairs with closeness ~  991\n",
      "   1 pairs with closeness ~ 1060\n",
      "   1 pairs with closeness ~ 1113\n",
      "   1 pairs with closeness ~ 1169\n",
      "   1 pairs with closeness ~ 1190\n",
      "   1 pairs with closeness ~ 1197\n",
      "   1 pairs with closeness ~ 1250\n",
      "   1 pairs with closeness ~ 1271\n",
      "   1 pairs with closeness ~ 1281\n",
      "   1 pairs with closeness ~ 1282\n",
      "   1 pairs with closeness ~ 1310\n",
      "   1 pairs with closeness ~ 1336\n",
      "   1 pairs with closeness ~ 1369\n",
      "   1 pairs with closeness ~ 1372\n",
      "   1 pairs with closeness ~ 1575\n",
      "   1 pairs with closeness ~ 1658\n",
      "   1 pairs with closeness ~ 1692\n",
      "   1 pairs with closeness ~ 3947\n"
     ]
    }
   ],
   "source": [
    "closenessDistribution = collections.Counter()\n",
    "for ((signI, signJ), closeness) in pairs.items():\n",
    "    closenessDistribution[int(round(closeness))] += 1\n",
    "\n",
    "for (closeness, amount) in sorted(closenessDistribution.items()):\n",
    "    print(f'{amount:>4} pairs with closeness ~ {closeness:>4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {
    "height": "607px",
    "left": "0px",
    "right": "1123px",
    "top": "110px",
    "width": "157px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
