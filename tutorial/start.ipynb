{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#What-is-Text-Fabric?\" data-toc-modified-id=\"What-is-Text-Fabric?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>What is Text-Fabric?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cuneiform-tablets-in-ATF\" data-toc-modified-id=\"Cuneiform-tablets-in-ATF-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Cuneiform tablets in ATF</a></span></li><li><span><a href=\"#Text-Fabric\" data-toc-modified-id=\"Text-Fabric-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Text-Fabric</a></span></li></ul></li><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Overview</a></span></li><li><span><a href=\"#More-information\" data-toc-modified-id=\"More-information-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>More information</a></span></li><li><span><a href=\"#Installing-Text-Fabric\" data-toc-modified-id=\"Installing-Text-Fabric-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Installing Text-Fabric</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prerequisites\" data-toc-modified-id=\"Prerequisites-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Prerequisites</a></span></li><li><span><a href=\"#TF-itself\" data-toc-modified-id=\"TF-itself-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>TF itself</a></span></li><li><span><a href=\"#Cuneiform-data\" data-toc-modified-id=\"Cuneiform-data-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Cuneiform data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tip\" data-toc-modified-id=\"Tip-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Tip</a></span></li></ul></li></ul></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#A-tour-around-the-TF-API\" data-toc-modified-id=\"A-tour-around-the-TF-API-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>A tour around the TF API</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sections:-tablet---column---line\" data-toc-modified-id=\"Sections:-tablet---column---line-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Sections: tablet - column - line</a></span></li><li><span><a href=\"#Navigation\" data-toc-modified-id=\"Navigation-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Navigation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Source-lines\" data-toc-modified-id=\"Source-lines-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Source lines</a></span></li><li><span><a href=\"#Source-lines:-refined\" data-toc-modified-id=\"Source-lines:-refined-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Source lines: refined</a></span></li><li><span><a href=\"#Lines-and-cases\" data-toc-modified-id=\"Lines-and-cases-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Lines and cases</a></span></li><li><span><a href=\"#Line-numbers\" data-toc-modified-id=\"Line-numbers-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;</span>Line numbers</a></span></li></ul></li><li><span><a href=\"#Mass-operations\" data-toc-modified-id=\"Mass-operations-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Mass operations</a></span></li><li><span><a href=\"#Walking-all-nodes\" data-toc-modified-id=\"Walking-all-nodes-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Walking all nodes</a></span></li><li><span><a href=\"#All-signs\" data-toc-modified-id=\"All-signs-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>All signs</a></span></li><li><span><a href=\"#Particular-signs\" data-toc-modified-id=\"Particular-signs-6.6\"><span class=\"toc-item-num\">6.6&nbsp;&nbsp;</span>Particular signs</a></span></li><li><span><a href=\"#From-instance-to-context\" data-toc-modified-id=\"From-instance-to-context-6.7\"><span class=\"toc-item-num\">6.7&nbsp;&nbsp;</span>From instance to context</a></span></li></ul></li><li><span><a href=\"#End\" data-toc-modified-id=\"End-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>End</a></span></li><li><span><a href=\"#Count-all-nodes\" data-toc-modified-id=\"Count-all-nodes-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Count all nodes</a></span></li><li><span><a href=\"#What-are-all-those-nodes?\" data-toc-modified-id=\"What-are-all-those-nodes?-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>What are all those nodes?</a></span></li><li><span><a href=\"#Count-individual-object-types\" data-toc-modified-id=\"Count-individual-object-types-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Count individual object types</a></span></li><li><span><a href=\"#Going-up\" data-toc-modified-id=\"Going-up-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Going up</a></span></li><li><span><a href=\"#Going-next\" data-toc-modified-id=\"Going-next-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Going next</a></span></li><li><span><a href=\"#Going-previous\" data-toc-modified-id=\"Going-previous-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Going previous</a></span></li><li><span><a href=\"#Going-down\" data-toc-modified-id=\"Going-down-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Going down</a></span></li><li><span><a href=\"#The-first-line\" data-toc-modified-id=\"The-first-line-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>The first line</a></span></li><li><span><a href=\"#Prime\" data-toc-modified-id=\"Prime-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>Prime</a></span></li><li><span><a href=\"#Variant\" data-toc-modified-id=\"Variant-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>Variant</a></span></li><li><span><a href=\"#Modifier\" data-toc-modified-id=\"Modifier-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>Modifier</a></span></li><li><span><a href=\"#Full-grapheme-overview\" data-toc-modified-id=\"Full-grapheme-overview-19\"><span class=\"toc-item-num\">19&nbsp;&nbsp;</span>Full grapheme overview</a></span></li><li><span><a href=\"#Search\" data-toc-modified-id=\"Search-20\"><span class=\"toc-item-num\">20&nbsp;&nbsp;</span>Search</a></span></li><li><span><a href=\"#Explore-additional-data\" data-toc-modified-id=\"Explore-additional-data-21\"><span class=\"toc-item-num\">21&nbsp;&nbsp;</span>Explore additional data</a></span></li><li><span><a href=\"#Add-your-own-data\" data-toc-modified-id=\"Add-your-own-data-22\"><span class=\"toc-item-num\">22&nbsp;&nbsp;</span>Add your own data</a></span></li><li><span><a href=\"#Export-to-Emdros-MQL\" data-toc-modified-id=\"Export-to-Emdros-MQL-23\"><span class=\"toc-item-num\">23&nbsp;&nbsp;</span>Export to Emdros MQL</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/quad.png\" width=\"300\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "This notebook gets you started with using\n",
    "[Text-Fabric](https://github.com/Dans-labs/text-fabric) for coding in cuneiform tablet transcriptions.\n",
    "\n",
    "## What is Text-Fabric?\n",
    "\n",
    "### Cuneiform tablets in ATF\n",
    "\n",
    "Cuneiform tablets have been transcribed in ATF files, in which the marks on a tablet are represented\n",
    "by ascii characters. The marks on a tablet have structure (they can be composed, they build cases and lines) and properties (they can be uncertain).\n",
    "\n",
    "When you search for tablet data in an ATF file, you can do so conveniently by using regular expressions.\n",
    "\n",
    "However, the ATF transcriptions have become packed with information. Not every transcriber uses ATF in the same way, and there are a few coding errors in the sources.\n",
    "\n",
    "That means that the most obvious search expressions will leave out cases. Either you live with that, or you refine your search expressions.\n",
    "\n",
    "An other issue is, that when you look for something, your search expressions must reflect the shape of not\n",
    "only your target, but also everything else. There is virtually no separation of concerns.\n",
    "\n",
    "### Text-Fabric\n",
    "\n",
    "Text-Fabric is a model for textual data with annotations that is optimized for efficient data analysis. Not only that, it also facilitates the creation of new, derived data, which can be added to the original data.\n",
    "Data combination is a feature of Text-Fabric.\n",
    "\n",
    "Text-Fabric is being used for the\n",
    "[Hebrew Bible](https://github.com/ETCBC/bhsa)\n",
    "and a large body of linguisitic annotations on top of it. The researchers of the \n",
    "[ETCBC](http://etcbc.nl) thought that a plain database is not a satisfactory text model,\n",
    "and that XML is too limited too express multiple hierarchies in a text smoothly.\n",
    "\n",
    "That's why they adopted a model by\n",
    "[Doedens](http://books.google.nl/books?id=9ggOBRz1dO4C)\n",
    "that reflects more of the essential properties of text (sequence, embedding). This model is the basis of MQL, a working text-database system.\n",
    "Text-Fabric is based on the same\n",
    "[model](https://github.com/Dans-labs/text-fabric/wiki/Data-model),\n",
    "and once the data is in Text-Fabric, it can be exported to MQL.\n",
    "\n",
    "See more on the effort of modeling the Hebrew Bible in Dirk's article\n",
    "[The Hebrew Bible as Data: Laboratory - Sharing - Experiences](https://doi.org/10.5334/bbi.18)\n",
    "\n",
    "With data in Text-Fabric, it becomes possible to build rich online interfaces on the data of ancient texts.\n",
    "For the Hebrew Bible, we have built\n",
    "[SHEBANQ](https://shebanq.ancient-data.org).\n",
    "\n",
    "Working with TF is a bit like buying from IKEA. You get your product in bits and pieces, and you assemble it yourself. TF decomposes any dataset into its components, nicely stacked per component, with every component uniquely labeled. You go to the store, make your selection, enter the warehouse, collect your parts, and, at home, assemble your product.\n",
    "\n",
    "In order to enjoy an IKEA product, you do not need to be a craftsman, but you do need to be able to handle a screw driver.\n",
    "\n",
    "In the TF world, it is the same. You do not have to be a professional programmer, but you do need to be able to program little things. A first course in Python is enough.\n",
    "\n",
    "Another parallel: in IKEA you take a package with components home, and there you assemble it. \n",
    "In TF it is likewise: you download the TF data, and then you write a little program. Inside that program you can call up the Text-Fabric tool, which act as the IKEA user manual. But your program takes control, not Text-Fabric.\n",
    "\n",
    "The best environment to enjoy Text-Fabric is in Python programs that you develop in a \n",
    "[Jupyter Notebook](http://jupyter.readthedocs.io/en/latest/).\n",
    "This tutorial is such a notebook. If you are reading it online, you see text bits and code bits,\n",
    "but you cannot execute the code bits.\n",
    "\n",
    "If you download this tutorial, and you have installed Python, Jupyter, and Text-Fabric,\n",
    "you can *execute* the code bits.\n",
    "\n",
    "## Overview\n",
    "\n",
    "* we tell you how to get Text-Fabric on your system\n",
    "* we tell you how to get a set of cuneiform tablet transcriptions on your system\n",
    "* we show how to explore the data:\n",
    "  * finding the relevant nodes\n",
    "  * moving from one place to an other\n",
    "  * collecting the relevant information\n",
    "  * perform analysis\n",
    "  * visualize your results\n",
    "\n",
    "## More information\n",
    "Chances are that a bit of reading about the underlying\n",
    "[data model](https://github.com/Dans-labs/text-fabric/wiki/Data-model)\n",
    "helps you to follow the exercises below, and vice versa.\n",
    "\n",
    "We have checked the conversion from the transcriptions to Text-Fabric extensively.\n",
    "Cruelly, you might say. You can follow the checks\n",
    "in a separate notebook [checks](checks.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Text-Fabric\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "You need to have Python on your system. Most systems have it out of the box,\n",
    "but alas, that is python2 and we need at least python 3.6.\n",
    "\n",
    "Install it from [python.org]() or from [Anaconda]().\n",
    "If you got it from python.org, you also have to install [Jupyter]().\n",
    "\n",
    "### TF itself\n",
    "\n",
    "```\n",
    "pip install text-fabric\n",
    "```\n",
    "\n",
    "if you have installed Python with the help of Anaconda, or\n",
    "\n",
    "```\n",
    "sudo -H pip3 install text-fabric\n",
    "```\n",
    "if you have installed Python from [python.org](https://www.python.org).\n",
    "\n",
    "###### Execute: If all this is done, the following cells can be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T09:45:11.924437Z",
     "start_time": "2018-02-25T09:45:11.900183Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T09:45:13.055892Z",
     "start_time": "2018-02-25T09:45:13.030404Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, collections\n",
    "from tf.fabric import Fabric\n",
    "from utils import Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuneiform data\n",
    "\n",
    "We have prepared a corpus of 6000 tablets, from the Uruk-III/IV period in Text-Fabric.\n",
    "We have downloaded the transcriptions from CDLI, and converted them to Text-Fabric.\n",
    "\n",
    "You can get the results from GitHub as follows.\n",
    "\n",
    "We suggest you make an appropriate directory in your home directory:\n",
    "\n",
    "```\n",
    "github/Dans-labs\n",
    "```\n",
    "\n",
    "then go to that directory in a terminal, and then say\n",
    "\n",
    "```\n",
    "git clone https://github.com/Dans-labs/Nino-cunei\n",
    "```\n",
    "\n",
    "After that your directory structure shold look like this:\n",
    "\n",
    "    your home direcectory\\\n",
    "    |                     - github\\\n",
    "    |                       |      - Dans-labs\\\n",
    "    |                       |        |         - Nino-cunei\n",
    "    \n",
    "#### Tip\n",
    "If you start computing with this tutorial, first copy its parent directory to somewhere else,\n",
    "outside your `Nino-cunei` directory.\n",
    "If you pull changes from the `Nino-cunei` repository later, your work will not be overwritten.\n",
    "Where you put your tutorial directory is up till you.\n",
    "It will work from any directory.\n",
    "\n",
    "###### Execute: it this has been done, you can execute the next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T09:45:16.270454Z",
     "start_time": "2018-02-25T09:45:16.245654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.2.0\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "33 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "REPO = '~/github/Dans-labs/Nino-cunei'\n",
    "SOURCE = 'uruk'\n",
    "VERSION = '0.1'\n",
    "CORPUS = f'{REPO}/tf/{SOURCE}/{VERSION}'\n",
    "SOURCE_DIR = os.path.expanduser(f'{REPO}/sources/cdli')\n",
    "TEMP_DIR = os.path.expanduser(f'{REPO}/_temp')\n",
    "TF = Fabric(locations=[CORPUS], modules=[''], silent=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "The transcriptions of the tablets in their TF form is organized in a model of nodes, edges and features.\n",
    "\n",
    "The things such as tablets, faces, columns, cases, and, at the most basic level, signs, are numbered.\n",
    "The signs correspond to number 1 ... ca. 120,000, in the same order as they occur in the corpus.\n",
    "All other things are built from signs. They have number from ca 120,000 to 450,000.\n",
    "\n",
    "In TF, we call these numbers *nodes*. Like a barcode, this number gives access to a whole bunch of\n",
    "information about the corresponding object.\n",
    "\n",
    "For example, lines have a property (in TF we call it a *feature*) called `fullNumber`. \n",
    "It contains the hierarchical number found at the start of the line in the transcription.\n",
    "\n",
    "If the node for a line is `n`, we can find its hierarchical number by saying\n",
    "\n",
    "```\n",
    "F.fullNumber.v(n)\n",
    "```\n",
    "\n",
    "In words, it reads as:\n",
    "\n",
    "* `F`: I want to look up a `F`eature\n",
    "* `fullNumber`: the name of the feature\n",
    "* `.v`: I want the value of that feature\n",
    "* `(n)`: for the given node `n`\n",
    "\n",
    "Seen in this way, the data is like a gigantic spreadsheet of 450,000 rows (the nodes),\n",
    "with 30 columns (the features).\n",
    "\n",
    "There is a bit more to it, since the nodes can be grouped together in ways we will see later on.\n",
    "\n",
    "###### Execute: the next cell loads most features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T09:48:03.497846Z",
     "start_time": "2018-02-25T09:48:02.255301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.00s B catalogId            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.03s B fullNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.03s B number               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.08s B grapheme             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.06s B srcLn                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.03s B srcLnNum             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B prime                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B repeat               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B variant              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B variantOuter         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifier             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierInner        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B modifierFirst        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B damage               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B uncertain            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B remarkable           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B written              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B kind                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B period               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B name                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B type                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B identifier           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B origNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B badNumbering         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B crossref             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B text                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B op                   from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.11s B sub                  from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B comments             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s Feature overview: 28 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  1.22s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    grapheme prime repeat\n",
    "    variant variantOuter\n",
    "    modifier modifierInner modifierFirst\n",
    "    damage uncertain remarkable written\n",
    "    kind\n",
    "    period name type identifier catalogId\n",
    "    number fullNumber origNumber badNumbering\n",
    "    crossref text\n",
    "    srcLn srcLnNum\n",
    "    op sub comments''')\n",
    "api.makeAvailableIn(globals())\n",
    "COMP = Compare(api, SOURCE_DIR, TEMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A tour around the TF API\n",
    "\n",
    "We have the data of over 6000 tablets at our fingertips now. But how can we see it?\n",
    "In a meaningful way?\n",
    "\n",
    "The following tour shows you the most important parts of the Text-Fabric API.\n",
    "It is a set of functions, defined in the TF package, that you can use in your own program.\n",
    "\n",
    "This notebook itself is our current program, and we have just loaded the API.\n",
    "\n",
    "See in the next cells, how we navigate to the tablets we want and pick our data from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sections: tablet - column - line\n",
    "\n",
    "Let's start with a single, specific tablet P448702.\n",
    "\n",
    "Here is its transcription, copied from the CDLI source.\n",
    "\n",
    "```\n",
    "&P448702 = www archaeo-auction 004 \n",
    "#atf: lang qpc \n",
    "@tablet \n",
    "@obverse \n",
    "@column 1 \n",
    "$ beginning broken \n",
    "1'. [n] , [...] KA~a \n",
    "2.a'. [n] 2(N14) 3(N01) , KASZ~b NUN~a \n",
    "2.b'. 3(N01) , KASZ~a? GI \n",
    "3'. [n] 6(N14)#? 4(N01) 2(N39~a) , X [...] \n",
    "@column 2 \n",
    "$ beginning broken \n",
    "$ blank space \n",
    "1'. , U4 |U4x1(N01)| SUKUD@inversum? NA \n",
    "@column 3 \n",
    "$ beginning broken \n",
    "$ blank space \n",
    "@reverse \n",
    "$ (not imaged) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a node for this tablet. How do we find it?\n",
    "\n",
    "The easiest way is to ask TF to find the node on the basis of a section specification.\n",
    "\n",
    "When we converted the transcriptions to TF, we made it so that tablets are the first\n",
    "section level, columns the second, and lines the third. \n",
    "\n",
    "In order to find the node corresponding to a section, we have to give a tuple\n",
    "`(tabletName, columnNumber, lineNumber)` to the appropriate function in TF.\n",
    "\n",
    "Here you may leave out `lineNumber` (to specify a column), or both `columnNumber` and `lineNumber` \n",
    "(to specify a tablet).\n",
    "The latter is our case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T09:48:31.999816Z",
     "start_time": "2018-02-25T09:48:31.971666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150865"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exampleTablet = T.nodeFromSection(('P448702',))\n",
    "exampleTablet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is the node, the barcode, as it were. It gives you access to all data we have stored of this\n",
    "tablet.\n",
    "\n",
    "One of the things we have stored for tablets, columns, and lines, is the original transcription line.\n",
    "Let's retrieve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T09:50:53.391355Z",
     "start_time": "2018-02-25T09:50:53.373224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&P448702 = www archaeo-auction 004 '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.srcLn.v(exampleTablet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the source line of the tablet header.\n",
    "How do we get the other source lines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigation\n",
    "\n",
    "We'll need another concept first.\n",
    "Things on a tablet have spatial relationships. \n",
    "While the transcriptions abstract from the physical relationships, there are still a few\n",
    "important ones left: sequence and embedding.\n",
    "\n",
    "At the most basic level we have signs. \n",
    "For all other levels, TF knows exactly which signs are part of the objects of those levels.\n",
    "\n",
    "And based on that knowledge, we can travel from objects to the objects embedded in it, and back,\n",
    "and to the right and left siblings.\n",
    "\n",
    "All these functions start with `L.`, and they take a starting node as argument.\n",
    "\n",
    "* `L.d()` goes \"down\": from enbedder to embeddee;\n",
    "* `L.u()` goes \"up\": from embeddee to embedder;\n",
    "* `L.p()` goes \"previous\": to the first left sibling;\n",
    "* `L.n()` goes \"next\": to the first left sibling.\n",
    "\n",
    "We can now find all the nodes contained in the example tablet.\n",
    "When we retrieve them, we also fetch their *type*: is it a face, a column, a sign?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:05:09.924796Z",
     "start_time": "2018-02-25T10:05:09.905831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180739 of type comment\n",
      "    56 of type sign\n",
      "157262 of type face\n",
      "166709 of type column\n",
      "180740 of type comment\n",
      "    57 of type sign\n",
      "229518 of type line\n",
      "266443 of type case\n",
      "196542 of type cluster\n",
      "    58 of type sign\n",
      "196543 of type cluster\n",
      "    59 of type sign\n",
      "    60 of type sign\n",
      "229519 of type line\n",
      "266444 of type case\n",
      "266445 of type case\n",
      "196544 of type cluster\n",
      "    61 of type sign\n",
      "    62 of type sign\n",
      "    63 of type sign\n",
      "    64 of type sign\n",
      "    65 of type sign\n",
      "266446 of type case\n",
      "266447 of type case\n",
      "    66 of type sign\n",
      "    67 of type sign\n",
      "    68 of type sign\n",
      "229520 of type line\n",
      "266448 of type case\n",
      "196545 of type cluster\n",
      "    69 of type sign\n",
      "    70 of type sign\n",
      "    71 of type sign\n",
      "    72 of type sign\n",
      "    73 of type sign\n",
      "196546 of type cluster\n",
      "    74 of type sign\n",
      "166710 of type column\n",
      "180741 of type comment\n",
      "    75 of type sign\n",
      "180742 of type comment\n",
      "    76 of type sign\n",
      "229521 of type line\n",
      "266449 of type case\n",
      "    77 of type sign\n",
      "146957 of type quad\n",
      "    78 of type sign\n",
      "    79 of type sign\n",
      "    80 of type sign\n",
      "    81 of type sign\n",
      "166711 of type column\n",
      "180743 of type comment\n",
      "    82 of type sign\n",
      "180744 of type comment\n",
      "    83 of type sign\n",
      "    84 of type sign\n",
      "157263 of type face\n",
      "180745 of type comment\n",
      "    85 of type sign\n",
      "    86 of type sign\n"
     ]
    }
   ],
   "source": [
    "for child in L.d(exampleTablet):\n",
    "    print(f'{child:>6} of type {F.otype.v(child)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note:\n",
    "\n",
    "* the numbers are not really important to us, only to the program.\n",
    "  Soon, we will stop showing them altogether\n",
    "* the order in which the nodes are delivered, is a natural one:\n",
    "  first things first, and bigger things before the smaller things they contain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source lines\n",
    "\n",
    "So in order to find all the source lines of this tablet, we can just take all these nodes,\n",
    "see whether they have a value for feature *srcLn*, retrieve it, an print it.\n",
    "\n",
    "Let's do it, and write this as a function, i.e. a recipe that we can apply to every tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:11:12.907636Z",
     "start_time": "2018-02-25T10:11:12.888399Z"
    }
   },
   "outputs": [],
   "source": [
    "def getSource(tablet):\n",
    "    sourceLines = []\n",
    "    sourceLines.append(F.srcLn.v(tablet))\n",
    "    for child in L.d(tablet):\n",
    "        sourceLine = F.srcLn.v(child)\n",
    "        if sourceLine:\n",
    "            sourceLines.append(sourceLine)\n",
    "    return sourceLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gets all source lines in a list.\n",
    "Let's apply it to our sample tablet, and print out the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:12:28.462504Z",
     "start_time": "2018-02-25T10:12:28.446603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P448702 = www archaeo-auction 004 \n",
      "#atf: lang qpc \n",
      "@obverse \n",
      "@column 1 \n",
      "$ beginning broken \n",
      "1'. [n] , [...] KA~a \n",
      "2.a'. [n] 2(N14) 3(N01) , KASZ~b NUN~a \n",
      "2.b'. 3(N01) , KASZ~a? GI \n",
      "3'. [n] 6(N14)#? 4(N01) 2(N39~a) , X [...] \n",
      "@column 2 \n",
      "$ beginning broken \n",
      "$ blank space \n",
      "1'. , U4 |U4x1(N01)| SUKUD@inversum? NA \n",
      "@column 3 \n",
      "$ beginning broken \n",
      "$ blank space \n",
      "@reverse \n",
      "$ (not imaged) \n"
     ]
    }
   ],
   "source": [
    "sourceLines = getSource(exampleTablet)\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nearly the original. The only difference we spot is that we have left out\n",
    "the `@tablet` line. This has been done because the `&P` line is the true header of the\n",
    "tablet. In fact, the `@tablet` line is not consistently present in the source.\n",
    "\n",
    "As you seen, the TF data is a bit more streamlined than the source transcriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source lines: refined\n",
    "\n",
    "If you just want the lines, and nothing else in between, you can instruct the `L.d` function to\n",
    "let through only nodes of a certain type.\n",
    "\n",
    "Let's improve the `getSource` function to give it an additional, optional argument that\n",
    "tells us the kind of object we want to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:18:03.516127Z",
     "start_time": "2018-02-25T10:18:03.496553Z"
    }
   },
   "outputs": [],
   "source": [
    "def getSource(tablet, nodeType=None):\n",
    "    sourceLines = []\n",
    "    sourceLines.append(F.srcLn.v(tablet))\n",
    "    for child in L.d(tablet, nodeType):\n",
    "        sourceLine = F.srcLn.v(child)\n",
    "        if sourceLine:\n",
    "            sourceLines.append(sourceLine)\n",
    "    return sourceLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call it without node type, we get the same results.\n",
    "\n",
    "Let's call it with `nodeType='face'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:19:31.825142Z",
     "start_time": "2018-02-25T10:19:31.808184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P448702 = www archaeo-auction 004 \n",
      "@obverse \n",
      "@reverse \n"
     ]
    }
   ],
   "source": [
    "sourceLines = getSource(exampleTablet, nodeType='face')\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see only the face specifiers.\n",
    "\n",
    "Now let's grab the lines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:20:40.729844Z",
     "start_time": "2018-02-25T10:20:40.710494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&P448702 = www archaeo-auction 004 \n",
      "1'. [n] , [...] KA~a \n",
      "2.a'. [n] 2(N14) 3(N01) , KASZ~b NUN~a \n",
      "2.b'. 3(N01) , KASZ~a? GI \n",
      "3'. [n] 6(N14)#? 4(N01) 2(N39~a) , X [...] \n",
      "1'. , U4 |U4x1(N01)| SUKUD@inversum? NA \n"
     ]
    }
   ],
   "source": [
    "sourceLines = getSource(exampleTablet, nodeType='case')\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lines and cases\n",
    "\n",
    "Note that we actually supplied `nodeType='case'`.\n",
    "This is because we have modelled the data in such a way, that a line corresponds to all\n",
    "transcription lines in a column that start with the same number.\n",
    "Lines are divided in cases and sub-cases according to the hierarchical line numbers.\n",
    "At the lowest level of sub-case we encounter the material that belong to single\n",
    "transcription lines.\n",
    "\n",
    "Also when lines only have a single case, we will have a case embedded in the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line numbers\n",
    "\n",
    "The TF data also has the original line numbers. Let us once again improve the `getSource` function by \n",
    "giving it an optional argument for fetching line numbers too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:31:09.284415Z",
     "start_time": "2018-02-25T10:31:09.259305Z"
    }
   },
   "outputs": [],
   "source": [
    "def getSource(tablet, nodeType=None, lineNumbers=False):\n",
    "    sourceLines = []\n",
    "    if lineNumbers:\n",
    "        sourceLines.append(f'{F.srcLnNum.v(tablet):>5}: {F.srcLn.v(tablet)}')\n",
    "    for child in L.d(tablet, nodeType):\n",
    "        sourceLine = F.srcLn.v(child)\n",
    "        lineNumber = ''\n",
    "        if sourceLine:\n",
    "            if lineNumbers:\n",
    "                lineNumber = f'{F.srcLnNum.v(child):>5}: '\n",
    "            sourceLines.append(f'{lineNumber}{sourceLine}')\n",
    "    return sourceLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print the lines with source line numbers, so that we can look them up in the\n",
    "source easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:31:10.874546Z",
     "start_time": "2018-02-25T10:31:10.860267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   50: &P448702 = www archaeo-auction 004 \n",
      "   56: 1'. [n] , [...] KA~a \n",
      "   57: 2.a'. [n] 2(N14) 3(N01) , KASZ~b NUN~a \n",
      "   58: 2.b'. 3(N01) , KASZ~a? GI \n",
      "   59: 3'. [n] 6(N14)#? 4(N01) 2(N39~a) , X [...] \n",
      "   63: 1'. , U4 |U4x1(N01)| SUKUD@inversum? NA \n"
     ]
    }
   ],
   "source": [
    "sourceLines = getSource(exampleTablet, nodeType='case', lineNumbers=True)\n",
    "print('\\n'.join(sourceLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll appreciate the way you can build up your own power tools as you go.\n",
    "The functions of TF provide a foundation, so that start when all the gory details\n",
    "have been taken care of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mass operations\n",
    "\n",
    "We have a mass of data, and we want to do meaningful things with that mass.\n",
    "Here are a few ways to address all nodes, and significant subsets of all nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walking all nodes\n",
    "\n",
    "The generator `N()` provides you with all nodes, one by one, in a sequence.\n",
    "They come in the natural order, as we have seen above:\n",
    "\n",
    "* first things first\n",
    "* bigger things before the smaller things they contain.\n",
    "\n",
    "Let's print the first 20 nodes, together with their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:42:35.674251Z",
     "start_time": "2018-02-25T10:42:35.655192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150862 : tablet\n",
      "180733 : comment\n",
      "     1 : sign\n",
      "180734 : comment\n",
      "     2 : sign\n",
      "157258 : face\n",
      "166700 : column\n",
      "229498 : line\n",
      "266423 : case\n",
      "196539 : cluster\n",
      "     3 : sign\n",
      "     4 : sign\n",
      "     5 : sign\n",
      "166701 : column\n",
      "229499 : line\n",
      "266424 : case\n",
      "     6 : sign\n",
      "     7 : sign\n",
      "     8 : sign\n",
      "196540 : cluster\n"
     ]
    }
   ],
   "source": [
    "LIMIT = 20\n",
    "\n",
    "times = 0\n",
    "for n in N():\n",
    "    print(f'{n:>6} : {F.otype.v(n)}')\n",
    "    times += 1\n",
    "    if times >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All signs\n",
    "\n",
    "Suppose we are only interested in the signs, not how they are organized in cases, lines,\n",
    "columns, faces and tablets.\n",
    "\n",
    "Suppose we just want to count them.\n",
    "\n",
    "We could use `N()` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:45:54.943562Z",
     "start_time": "2018-02-25T10:45:54.642380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146955\n"
     ]
    }
   ],
   "source": [
    "times = 0\n",
    "for n in N():\n",
    "    if F.otype.v(n) != 'sign':\n",
    "        continue\n",
    "    times += 1\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, TF makes it a bit easier to get to all sign nodes, or nodes from whatever type.\n",
    "\n",
    "We have already used the `F.feature.v(n)` idiom.\n",
    "But you can do more with features, beyond fetching particular values.\n",
    "\n",
    "You can also retrieve the sequence of nodes that support a particular value.\n",
    "\n",
    "We want to retrieve all nodes that support the value `sign` in their `otype` feature.\n",
    "\n",
    "Here we go, and note that we use `.s(value)` instead of `.v(node)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:49:42.613570Z",
     "start_time": "2018-02-25T10:49:42.595656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146955"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signs = F.otype.s('sign')\n",
    "len(signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signs have a feature `grapheme`, filled with the name of the sign, without variants (allographs), modifiers, and flags. Let's see the first 20 graphemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T10:52:21.192570Z",
     "start_time": "2018-02-25T10:52:21.175502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 : \n",
      " 2 : \n",
      " 3 : …\n",
      " 4 : X\n",
      " 5 : X\n",
      " 6 : N14\n",
      " 7 : X\n",
      " 8 : SANGA\n",
      " 9 : …\n",
      "10 : \n",
      "11 : \n",
      "12 : X\n",
      "13 : X\n",
      "14 : X\n",
      "15 : X\n",
      "16 : X\n",
      "17 : X\n",
      "18 : X\n",
      "19 : X\n",
      "20 : X\n"
     ]
    }
   ],
   "source": [
    "for sign in signs[0:20]:\n",
    "    print(f'{sign:>2} : {F.grapheme.v(sign)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note:\n",
    "\n",
    "* there are empty signs\n",
    "* there is the sign `…`\n",
    "\n",
    "During conversion, we have put empty signs in metadata lines and rulings.\n",
    "That is the mechanism by which TF knows where in the corpus they are positioned.\n",
    "The do not belong to the material that corresponds to tablet content, except maybe in the\n",
    "case of rulings.\n",
    "\n",
    "The sign `…` originates from `...` in transcriptions, which is mostly surrounded by\n",
    "`[ ]`. The brackets signify uncertainty, and can be put around other signs as well,\n",
    "even sequences of signs. These brackets denote *clusters*, a node type that we will encounter\n",
    "later.\n",
    "\n",
    "So, the expression `[...]` in the source translates to a *cluster* in TF, with just one\n",
    "sign in it, which has *grapheme* value `…`. \n",
    "Of course, this is not a real grapheme, and it will be easy to weed out such graphemes if\n",
    "you do not need to take them into account. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particular signs\n",
    "\n",
    "Suppose we want to get all occurrences of the grapheme `SANGA`.\n",
    "\n",
    "We can use the same trick as for getting the `signs`: we ask for the nodes that support\n",
    "the value `SANGA` in their `grapheme` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T11:02:40.512945Z",
     "start_time": "2018-02-25T11:02:40.476656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sangas = F.grapheme.s('SANGA')\n",
    "len(sangas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of what you can do with such a set, let's pick only those SANGAs that\n",
    "do not have a variant. We want `SANGA`, but not `SANGA~a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T11:05:04.803004Z",
     "start_time": "2018-02-25T11:05:04.784580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pureSangas = [s for s in sangas if F.variant.v(s) is None]\n",
    "len(pureSangas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, all sangas are an allograph in this corpus. Are they all `~a`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T11:06:52.038198Z",
     "start_time": "2018-02-25T11:06:52.016021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aSangas = [s for s in sangas if F.variant.v(s) == 'a']\n",
    "len(aSangas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all of them, let's see what other variants occur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T11:16:35.789761Z",
     "start_time": "2018-02-25T11:16:35.758553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65752 SANGA~b\n",
      "122525 SANGA~b\n",
      "122536 SANGA~b\n",
      "122577 SANGA~b\n",
      "122593 SANGA~b\n",
      "123008 SANGA~b\n",
      "123011 SANGA~b\n",
      "123019 SANGA~b\n",
      "123025 SANGA~b\n",
      "123052 SANGA~b\n",
      "124094 SANGA~b\n",
      "124783 SANGA~b\n",
      "127407 SANGA~b\n",
      "133550 SANGA~b\n",
      "133681 SANGA~c\n",
      "135991 SANGA~b\n",
      "138239 SANGA~b\n",
      "142282 SANGA~c\n",
      "All variants: b, c\n"
     ]
    }
   ],
   "source": [
    "sangaVariants = set()\n",
    "otherSangas = []\n",
    "\n",
    "for s in sangas:\n",
    "    if s not in aSangas:\n",
    "        otherSangas.append(s)\n",
    "        variant = F.variant.v(s)\n",
    "        sangaVariants.add(variant)\n",
    "        print(f'{s:>6} SANGA~{variant}')\n",
    "print(f'All variants: {\", \".join(sorted(sangaVariants))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From instance to context\n",
    "\n",
    "We want to know where those other SANGA variants are.\n",
    "\n",
    "Earlier we saw how we could get nodes if we knew the section.\n",
    "Here we need the opposite. We know a few nodes, and want to get the section.\n",
    "TF has a function for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T11:17:06.137439Z",
     "start_time": "2018-02-25T11:17:06.121157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P273433', 'obverse:2', '3')\n",
      "('P000884', 'obverse:1', '2')\n",
      "('P000884', 'obverse:2', '1')\n",
      "('P000886', 'obverse:2', '2')\n",
      "('P000888', 'obverse:1', '1')\n",
      "('P000958', 'obverse:2', '3')\n",
      "('P000958', 'obverse:2', '4')\n",
      "('P000958', 'obverse:2', '7')\n",
      "('P000958', 'obverse:3', '2')\n",
      "('P000958', 'obverse:5', '2')\n",
      "('P001078', 'obverse:2', '2')\n",
      "('P001161', 'obverse:1', '1')\n",
      "('P001377', 'obverse:3', '3')\n",
      "('P002079', 'obverse:1', '1')\n",
      "('P002207', 'obverse:1', '1')\n",
      "('P003233', 'obverse:2', '2')\n",
      "('P000121', 'obverse:2', '3')\n",
      "('P003454', 'obverse:2', '2')\n"
     ]
    }
   ],
   "source": [
    "for s in otherSangas:\n",
    "    print(T.sectionFromNode(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see the source code line of these sangas, we can do it by what we have learned so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T11:19:52.401362Z",
     "start_time": "2018-02-25T11:19:52.382458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53330: 3.b. 2(N14) 6(N01) , SANGA~b? \n",
      " 1292: 2. 2(N01) , SANGA~b MA\n",
      " 1296: 1. 1(N01)# , X SANGA~b#?\n",
      " 1322: 2. 1(N01)# , ZATU713# SANGA~b#\n",
      " 1339: 1. [...] 2(N01)# , HASZHUR# SANGA~b# [...]\n",
      " 1786: 3. 1(N01) , UMUN2# SANGA~b#\n",
      " 1787: 4. 1(N01) , ZATU678# SANGA~b?\n",
      " 1790: 7. 1(N01) , SUG5 SANGA~b\n",
      " 1793: 2. 1(N01) , BU~a SANGA~b\n",
      " 1807: 2. 1(N01)# , SANGA~b#\n",
      " 2687: 2. 3(N01)# [...] , SANGA~b# KUR@g~a# [...]\n",
      " 3280: 1. [...] 3(N01)# , SANGA~b\n",
      " 5564: 3. [...] 1(N01) , SANGA~b#\n",
      "10490: 1. 2(N14)#? , SANGA~b\n",
      "10622: 1. , SANGA~c GIR3~b DUB~c\n",
      "12763: 2. 1(N52)# , SANGA~b\n",
      "14583: 3'. , SANGA~b? IB~b \n",
      "18084: 2. 1(N34) , SANGA~c 1(N58)\n"
     ]
    }
   ],
   "source": [
    "for s in otherSangas:\n",
    "    for case in L.u(s, otype='case'):\n",
    "        srcLine = F.srcLn.v(case)\n",
    "        if srcLine is not None:\n",
    "            print(f'{F.srcLnNum.v(case):>5}: {srcLine}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End\n",
    "\n",
    "Here ends the reburbished tutorial.\n",
    "Below are fragments of the old tutorial.\n",
    "These will be gone or reworked in the final version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grapheme name of each sign is a column `grapheme` in that spreadsheet.\n",
    "\n",
    "The information whether a sign is damaged, constitutes a column `damaged`.\n",
    "\n",
    "The corpus contains over 20 columns, not only for the signs, but also for a 150,000+ more\n",
    "textual objects, such as *(sub)quads*, *clusters*, *lines*, *cases*, *columns*, *faces* and *tablets*.\n",
    "\n",
    "We also have features that contain the original lines of transcription.\n",
    "These features are filled for tablets, faces, columns, lines, and comments.\n",
    "\n",
    "Instead of putting that information in one big table, the data is organized in separate columns.\n",
    "We call those columns **features**.\n",
    "\n",
    "We just load the features we need for this tutorial.\n",
    "Later on, where we use them, it will become clear what they mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this all is that we have a bunch of special variables at our disposal\n",
    "that give us access to the text and data of the tablets.\n",
    "\n",
    "At this point it is helpful to throw a quick glance at the text-fabric\n",
    "[API documentation](https://github.com/Dans-labs/text-fabric/wiki/Api)\n",
    "especially the right side bar.\n",
    "\n",
    "The most essential thing for now is that we can use `F` to access the data in the features\n",
    "we've loaded.\n",
    "But there is more, such as `N`, which helps us to walk over the text, as we see in a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting\n",
    "\n",
    "In order to get acquainted with the data, we start with the simple task of counting.\n",
    "\n",
    "## Count all nodes\n",
    "We use the \n",
    "[`N()` generator](https://github.com/Dans-labs/text-fabric/wiki/Api#walking-through-nodes)\n",
    "to walk through the nodes.\n",
    "\n",
    "We compared the tablet data to a gigantic spreadsheet, where the rows correspond to the words.\n",
    "In Text-Fabric, we call the rows `slots`, because they are the textual positions that can be filled with words.\n",
    "\n",
    "We also mentioned that there are also other textual objects. \n",
    "They are the tablets, columns, lines, etc.\n",
    "They also correspond to rows in the big spreadsheet.\n",
    "\n",
    "In Text-Fabric we call all these rows *nodes*, and the `N()` generator\n",
    "carries us through those nodes in the textual order.\n",
    "\n",
    "Just one extra thing: the `info` statements generate timed messages.\n",
    "If you use them instead of `print` you'll get a sense of the amount of time that \n",
    "the various processing steps typically need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:12.522931Z",
     "start_time": "2018-02-25T07:43:12.427779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Counting nodes ...\n",
      "  0.08s 318107 nodes\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('Counting nodes ...')\n",
    "\n",
    "i = 0\n",
    "for n in N(): i += 1\n",
    "\n",
    "info('{} nodes'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see it: more than 400,000 nodes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are all those nodes?\n",
    "Every node has a type, like sign, or line, face.\n",
    "We know that we have many of them,\n",
    "but what exactly are they?\n",
    "\n",
    "Text-Fabric has two special features, `otype` and `oslots`, that must occur in every Text-Fabric data set.\n",
    "`otype` tells you for each node its type, and you can ask for the number of `slot`s in the text.\n",
    "\n",
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:16.236487Z",
     "start_time": "2018-02-25T07:43:16.212617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sign'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.slotType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:17.825314Z",
     "start_time": "2018-02-25T07:43:17.805172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146955"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxSlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:18.822218Z",
     "start_time": "2018-02-25T07:43:18.802670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318107"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:20.693642Z",
     "start_time": "2018-02-25T07:43:20.668236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tablet',\n",
       " 'face',\n",
       " 'column',\n",
       " 'line',\n",
       " 'case',\n",
       " 'cluster',\n",
       " 'quad',\n",
       " 'comment',\n",
       " 'sign')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain a bit more knowledge about the types of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:25.972331Z",
     "start_time": "2018-02-25T07:43:25.952538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tablet   average length 22.9761 from 150862 to 157257\n",
      "face     average length 14.3466 from 157258 to 166699\n",
      "column   average length  9.4888 from 166700 to 180732\n",
      "line     average length  3.5643 from 229498 to 266422\n",
      "case     average length  3.1821 from 266423 to 318107\n",
      "cluster  average length  1.0313 from 196539 to 229497\n",
      "quad     average length  2.0507 from 146956 to 150861\n",
      "comment  average length  1.0000 from 180733 to 196538\n",
      "sign     average length  1.0000 from      1 to 146955\n"
     ]
    }
   ],
   "source": [
    "for (nodeType, avLen, startNode, endNode) in C.levels.data:\n",
    "    print(f'{nodeType:<8} average length {avLen:>7.4f} from {startNode:>6} to {endNode:>6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the first *cluster*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:28.447234Z",
     "start_time": "2018-02-25T07:43:28.429645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196539"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = F.otype.s('cluster')[0]\n",
    "cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what is embedded in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:31.324225Z",
     "start_time": "2018-02-25T07:43:31.307019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node      3 of type sign\n"
     ]
    }
   ],
   "source": [
    "for n in L.d(cl):\n",
    "    print(f'node {n:>6} of type {F.otype.v(n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the third *sign*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:39.957015Z",
     "start_time": "2018-02-25T07:43:39.941306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sign'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.v(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:42.486298Z",
     "start_time": "2018-02-25T07:43:42.468692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 196539 of type cluster\n",
      "node 266423 of type case\n",
      "node 229498 of type line\n",
      "node 166700 of type column\n",
      "node 157258 of type face\n",
      "node 150862 of type tablet\n"
     ]
    }
   ],
   "source": [
    "for n in L.u(3):\n",
    "    print(f'node {n:>6} of type {F.otype.v(n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count individual object types\n",
    "This is an intuitive way to count the number of nodes in each type.\n",
    "Note in passing, how we use the `indent` in conjunction with `info` to produce neat timed \n",
    "and indented progress messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:46.194437Z",
     "start_time": "2018-02-25T07:43:46.073914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s counting objects ...\n",
      "   |     0.00s    6396 tablets\n",
      "   |     0.00s    9442 faces\n",
      "   |     0.01s   14033 columns\n",
      "   |     0.00s   36925 lines\n",
      "   |     0.01s   51685 cases\n",
      "   |     0.01s   32959 clusters\n",
      "   |     0.00s    3906 quads\n",
      "   |     0.00s   15806 comments\n",
      "   |     0.02s  146955 signs\n",
      "  0.09s Done\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('counting objects ...')\n",
    "\n",
    "for otype in F.otype.all:\n",
    "    i = 0\n",
    "\n",
    "    indent(level=1, reset=True)\n",
    "\n",
    "    for n in F.otype.s(otype): i+=1\n",
    "\n",
    "    info('{:>7} {}s'.format(i, otype))\n",
    "\n",
    "indent(level=0)\n",
    "info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locality\n",
    "\n",
    "We travel upwards and downwards, forwards and backwards through the nodes.\n",
    "The Locality-API (`L`) provides functions: `u()` for going up, and `d()` for going down,\n",
    "`n()` for going to next nodes and `p()` for going to previous nodes.\n",
    "\n",
    "These directions are indirect notions: nodes are just numbers, but by means of the\n",
    "`oslots` feature they are linked to slots. One node *contains* an other node, if the one is linked to a set of slots that contains the set of slots that the other is linked to.\n",
    "And one if next or previous to an other, if its slots follow of precede the slots of the other one.\n",
    "\n",
    "`L.u(node)` **Up** is going to nodes that embed `node`.\n",
    "\n",
    "`L.d(node)` **Down** is the opposite direction, to those that are contained in `node`.\n",
    "\n",
    "`L.n(node)` **Next** are the next *adjacent* nodes, i.e. nodes whose first slot comes immediately after the last slot of `node`.\n",
    "\n",
    "`L.p(node)` **Previous** are the previous *adjacent* nodes, i.e. nodes whose last slot comes immediately before the first slot of `node`.\n",
    "\n",
    "All these functions yield nodes of all possible otypes.\n",
    "By passing an optional parameter, you can restrict the results to nodes of that type.\n",
    "\n",
    "The result are ordered according to the order of things in the text.\n",
    "\n",
    "The functions return always a tuple, even if there is just one node in the result.\n",
    "\n",
    "## Going up\n",
    "We go from the first sign to the tablet it contains.\n",
    "Note the `[0]` at the end. You expect one tablet, yet `L` returns a tuple. \n",
    "To get the only element of that tuple, you need to do that `[0]`.\n",
    "\n",
    "If you are like me, you keep forgetting it, and that will lead to weird error messages later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:48.943792Z",
     "start_time": "2018-02-25T07:43:48.925269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150862\n"
     ]
    }
   ],
   "source": [
    "firstTablet = L.u(1, otype='tablet')[0]\n",
    "print(firstTablet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see all the containing objects of sign 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:50.905159Z",
     "start_time": "2018-02-25T07:43:50.880114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign 100 is contained in tablet 150866\n",
      "sign 100 is contained in face 157264\n",
      "sign 100 is contained in column 166712\n",
      "sign 100 is contained in line 229525\n",
      "sign 100 is contained in case 266453\n",
      "sign 100 is not contained in a cluster\n",
      "sign 100 is not contained in a quad\n",
      "sign 100 is not contained in a comment\n"
     ]
    }
   ],
   "source": [
    "w = 100\n",
    "for otype in F.otype.all:\n",
    "    if otype == F.otype.slotType: continue\n",
    "    up = L.u(w, otype=otype)\n",
    "    upNode = None if len(up) == 0 else up[0]\n",
    "    if upNode is None:\n",
    "        print('sign {} is not contained in a {}'.format(w, otype))\n",
    "    else:\n",
    "        print('sign {} is contained in {} {}'.format(w, otype, upNode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going next\n",
    "Let's go to the next nodes of the first tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:53.603117Z",
     "start_time": "2018-02-25T07:43:53.581980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10: sign          first slot=10    , last slot=10    \n",
      " 180735: comment       first slot=10    , last slot=10    \n",
      " 150863: tablet        first slot=10    , last slot=39    \n"
     ]
    }
   ],
   "source": [
    "afterFirstTablet = L.n(firstTablet)\n",
    "for n in afterFirstTablet:\n",
    "    print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "        n, F.otype.v(n),\n",
    "        E.oslots.s(n)[0],\n",
    "        E.oslots.s(n)[-1],\n",
    "    ))\n",
    "secondTablet = L.n(firstTablet, otype='tablet')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going previous\n",
    "\n",
    "And let's see what is right before the second tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:55.886088Z",
     "start_time": "2018-02-25T07:43:55.867096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 150862: tablet        first slot=1     , last slot=9     \n",
      " 157258: face          first slot=3     , last slot=9     \n",
      " 166701: column        first slot=6     , last slot=9     \n",
      " 229499: line          first slot=6     , last slot=9     \n",
      " 266424: case          first slot=6     , last slot=9     \n",
      " 196540: cluster       first slot=9     , last slot=9     \n",
      "      9: sign          first slot=9     , last slot=9     \n"
     ]
    }
   ],
   "source": [
    "for n in L.p(secondTablet):\n",
    "    print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "        n, F.otype.v(n),\n",
    "        E.oslots.s(n)[0],\n",
    "        E.oslots.s(n)[-1],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go to the columns of the second tablet, and just count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:58.940136Z",
     "start_time": "2018-02-25T07:43:58.922260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "columns = L.d(secondTablet, otype='column')\n",
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first line\n",
    "We pick the first line and the first sign, and explore what is above and below them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:01.224915Z",
     "start_time": "2018-02-25T07:44:01.165562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1\n",
      "   |   UP\n",
      "   |      |   180733          comment\n",
      "   |      |   150862          tablet\n",
      "   |   DOWN\n",
      "   |      |   \n",
      "Node 229498\n",
      "   |   UP\n",
      "   |      |   266423          case\n",
      "   |      |   166700          column\n",
      "   |      |   157258          face\n",
      "   |      |   150862          tablet\n",
      "   |   DOWN\n",
      "   |      |   166700          column\n",
      "   |      |   266423          case\n",
      "   |      |   196539          cluster\n",
      "   |      |   3               sign\n",
      "   |      |   4               sign\n",
      "   |      |   5               sign\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "firstLine = L.d(firstTablet, otype='line')[0]\n",
    "\n",
    "for n in [1, firstLine]:\n",
    "    indent(level=0)\n",
    "    info('Node {}'.format(n), tm=False)\n",
    "    indent(level=1)\n",
    "    info('UP', tm=False)\n",
    "    indent(level=2)\n",
    "    info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.u(n)]), tm=False)\n",
    "    indent(level=1)\n",
    "    info('DOWN', tm=False)\n",
    "    indent(level=2)\n",
    "    info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.d(n)]), tm=False)\n",
    "indent(level=0)\n",
    "info('Done', tm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text\n",
    "\n",
    "The `T` functions provide ways of printing out text, and they know about section levels.\n",
    "\n",
    "We use section levels `tablet`, `column`, `line`.\n",
    "`face` is a level of nodes, but not a section level.\n",
    "\n",
    "We will define our own function to get the literal transcription text back for\n",
    "tablets, faces, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:03.726103Z",
     "start_time": "2018-02-25T07:44:03.690701Z"
    }
   },
   "outputs": [],
   "source": [
    "oLevels = '''\n",
    "    tablet\n",
    "    face\n",
    "    column\n",
    "    case\n",
    "'''.strip().split()\n",
    "\n",
    "lowerLevel = dict((oLevels[n], oLevels[n+1]) for n in range(len(oLevels) - 1))\n",
    "\n",
    "def transObject(n):\n",
    "    kind = F.otype.v(n)\n",
    "    trans = []\n",
    "    trans.append(f'{F.srcLnNum.v(n):>7}: {F.srcLn.v(n)}')\n",
    "    for c in E.comments.f(n):\n",
    "        trans.append(f'{F.srcLnNum.v(c):>7}: {F.srcLn.v(c)}')\n",
    "    print('\\n'.join(trans))\n",
    "    subKind = lowerLevel.get(kind, None)\n",
    "    if subKind:\n",
    "        for m in L.d(n, otype=subKind):\n",
    "            if F.srcLn.v(m) is not None:\n",
    "                transObject(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:05.565633Z",
     "start_time": "2018-02-25T07:44:05.549084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1: &P006427 = HJN 0044\n",
      "      2: #version: 0.1\n",
      "      3: #atf: lang qpc\n",
      "      4: @obverse\n",
      "      5: @column 1\n",
      "      6: 1. [...] , X X\n",
      "      7: @column 2\n",
      "      8: 1. 3(N14) X SANGA~a? [...]\n"
     ]
    }
   ],
   "source": [
    "transObject(firstTablet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know the *P-number*, we can get the tablet with that P-number by means of\n",
    "`T.nodeFromSection()`.\n",
    "\n",
    "You pass this function a tuple, representing *tablet*, *column*, *line*, and it gives you back\n",
    "the node of the corresponding object.\n",
    "\n",
    "*column* and *line* are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:07.886926Z",
     "start_time": "2018-02-25T07:44:07.866952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150867"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabletId = 'P471695'\n",
    "tabletNode = T.nodeFromSection((tabletId,))\n",
    "tabletNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the transcription of this tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:09.836452Z",
     "start_time": "2018-02-25T07:44:09.818593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     87: &P471695 = Anonymous 0712 \n",
      "     88: #atf: lang qpc \n",
      "     90: @obverse \n",
      "     91: @column 1\n",
      "     92: 1.a. 3(N01) , APIN~a 3(N57) UR4~a \n",
      "     93: 1.b1. , (EN~a DU ZATU759)a \n",
      "     94: 1.b2. , (BAN~b KASZ~c)a \n",
      "     95: 1.b3. , (KI@n SAG)a \n",
      "     96: 2.a. 1(N14) 2(N01) , [...] \n",
      "     97: 2.b1. , (3(N57) PAP~a)a \n",
      "     98: 2.b2. , (SZU KI X)a \n",
      "     99: $ n lines broken  \n",
      "    100: 2.b3'. , (EN~a AN EZINU~d)a \n",
      "    101: 2.b4'. , (IDIGNA [...])a \n",
      "    102: $ rest broken \n",
      "    103: $ (for a total of 12 sub-cases with PNN) \n",
      "    104: @column 2\n",
      "    105: 1.a. 1(N01) , ISZ~a#? \n",
      "    106: 1.b1. , (PAP~a GIR3~c)a\n",
      "    107: $ blank space \n",
      "    108: $ rest broken \n",
      "    109: @reverse \n",
      "    110: $ beginning broken \n",
      "    111: 1'. [1(N14)] 6(N01)# , [...] \n",
      "    111: 1'. [1(N14)] 6(N01)# , [...] \n"
     ]
    }
   ],
   "source": [
    "transObject(tabletNode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphemes\n",
    "\n",
    "`F`\n",
    "gives access to all features.\n",
    "Every feature has a method\n",
    "`freqList()`\n",
    "to generate a frequency list of its values, higher frequencies first.\n",
    "Here are the graphemes (the top 20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:12.436594Z",
     "start_time": "2018-02-25T07:44:12.324263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29618 x …\n",
      "21676 x N01\n",
      "17128 x \n",
      " 6956 x X\n",
      " 5924 x N14\n",
      " 1970 x EN\n",
      " 1846 x N57\n",
      " 1835 x N34\n",
      " 1349 x SZE\n",
      " 1241 x GAL\n",
      " 1125 x DUG\n",
      " 1069 x AN\n",
      " 1046 x U4\n",
      "  892 x NUN\n",
      "  881 x SAL\n",
      "  879 x PAP\n",
      "  877 x E2\n",
      "  875 x GI\n",
      "  788 x BA\n",
      "  747 x SANGA\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.grapheme.freqList()[0:20]:\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a bit more: we'll write a file with all graphemes to your TEMP_DIR.\n",
    "In fact, we'll write two: one ordered by grapheme, and one ordered by frequency.\n",
    "\n",
    "In order to not clutter this notebook, we use a function `writeFreqs()`, defined in \n",
    "[utils](utils.py) in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:17.246731Z",
     "start_time": "2018-02-25T07:44:17.139349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 667 bare graphemes\n"
     ]
    }
   ],
   "source": [
    "COMP.writeFreqs('grapheme-plain', F.grapheme.freqList(), 'bare grapheme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a look at your TEMP_DIR and you see two generated files:\n",
    "\n",
    "* `graphemes-plain-alpha.txt` (sorted by grapheme)\n",
    "* `graphemes-plain-freq.txt` (sorted by frequency)\n",
    "\n",
    "But we can do better, we also want the prime, variants, and modifiers taken into account.\n",
    "\n",
    "Let us first see what they can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prime\n",
    "\n",
    "The prime is a feature with two values: 1 or 0. 1 means: there is a prime.\n",
    "Below you see how often that occurs.\n",
    "Note that we count all primes here: on signs, case numbers and column numbers.\n",
    "\n",
    "For more info and a check on the occurrences of primes, see [checks](checks.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:21.895691Z",
     "start_time": "2018-02-25T07:44:21.868102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5184 x 1\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.prime.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant\n",
    "\n",
    "The variant or allograph is what occurs after the grapheme and after the `~` symbol, which should be digits and/or\n",
    "lowercase letters except the `x`.\n",
    "\n",
    "Here is the frequency list of variant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:23.950506Z",
     "start_time": "2018-02-25T07:44:23.905553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23804 x a\n",
      " 4172 x b\n",
      " 1532 x c\n",
      " 1356 x a1\n",
      "  703 x b1\n",
      "  194 x a2\n",
      "  187 x d\n",
      "  127 x b2\n",
      "   85 x f\n",
      "   73 x a3\n",
      "   40 x e\n",
      "   29 x c2\n",
      "   22 x c1\n",
      "   22 x c3\n",
      "   17 x v\n",
      "   14 x c5\n",
      "   13 x b3\n",
      "   12 x a0\n",
      "   12 x d1\n",
      "   11 x c4\n",
      "    6 x a4\n",
      "    6 x g\n",
      "    5 x d2\n",
      "    4 x d4\n",
      "    4 x h\n",
      "    2 x 3a\n",
      "    2 x d3\n",
      "    1 x h2\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.variant.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifier\n",
    "\n",
    "The modifier is what occurs after the grapheme and after the `@` symbol, which should be digits and/or\n",
    "lowercase letters except the `x`.\n",
    "\n",
    "Here is the frequency list of *modifier* and *rmodifier* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:26.809651Z",
     "start_time": "2018-02-25T07:44:26.791269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  648 x g\n",
      "  251 x t\n",
      "   39 x n\n",
      "    6 x r\n",
      "    4 x s\n",
      "    1 x c\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifier.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:38.893781Z",
     "start_time": "2018-02-25T07:44:38.876426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 x f\n",
      "   15 x t\n",
      "    1 x r\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifierInner.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full grapheme overview\n",
    "\n",
    "We make a frequency list of all full graphemes, i.e. the grapheme including variant, modifier, and prime.\n",
    "We show as they appear in transcriptions.\n",
    "\n",
    "First we show on what node types primes, variants and modifiers occur.\n",
    "We only deal with cases where they occur on signs, ignoring the cases where they occur on (sub)quads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:46.592272Z",
     "start_time": "2018-02-25T07:44:45.610765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prime     :  4652 x case\n",
      "prime     :   523 x column\n",
      "prime     :     9 x sign\n",
      "variant   : 32455 x sign\n",
      "modifier  :   950 x sign\n"
     ]
    }
   ],
   "source": [
    "for feature in ('prime', 'variant', 'modifier'):\n",
    "    nodeTypes = collections.Counter()\n",
    "    for n in N():\n",
    "        if Fs(feature).v(n):\n",
    "            nodeTypes[F.otype.v(n)] += 1\n",
    "    for (value, frequency) in nodeTypes.items():\n",
    "        print(f'{feature:<10}: {frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the full graphemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:45:03.442045Z",
     "start_time": "2018-02-25T07:45:02.802767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29618 x ...\n",
      "17128 x \n",
      "12996 x 1(N01)\n",
      " 6956 x X\n",
      " 3081 x 2(N01)\n",
      " 2606 x 1(N14)\n",
      " 1849 x EN~a\n",
      " 1603 x 3(N01)\n",
      " 1357 x 2(N14)\n",
      " 1308 x SZE~a\n",
      " 1304 x 5(N01)\n",
      " 1224 x GAL~a\n",
      " 1119 x 4(N01)\n",
      " 1069 x AN\n",
      " 1045 x U4\n",
      " 1001 x 1(N34)\n",
      "  881 x SAL\n",
      "  874 x GI\n",
      "  854 x PAP~a\n",
      "  801 x 1(N57)\n",
      "There are 1529 full graphemes\n"
     ]
    }
   ],
   "source": [
    "fullGraphemes = collections.Counter()\n",
    "\n",
    "for n in F.otype.s('sign'):\n",
    "    fullGrapheme = COMP.strFromSign(n)\n",
    "    fullGraphemes[fullGrapheme] += 1\n",
    "    \n",
    "for (value, frequency) in sorted(fullGraphemes.items(), key=lambda x: (-x[1], x[0]))[0:20]:\n",
    "    print(f'{frequency:>5} x {value}')\n",
    "    \n",
    "COMP.writeFreqs('grapheme-full', fullGraphemes.items(), 'full grapheme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge features: left and right\n",
    "\n",
    "We have not talked about edges much. If the nodes correspond to the rows in the big spreadsheet,\n",
    "the edges point from one row to another.\n",
    "\n",
    "One edge we have encountered: the special feature `oslots`.\n",
    "Each non-slot node is linked by `oslots` to all of its slot nodes.\n",
    "\n",
    "An edge is really a feature as well.\n",
    "Whereas a node feature is a column of information,\n",
    "one cell per node, \n",
    "an edge feature is also a column of information, one cell per pair of nodes.\n",
    "\n",
    "In the tablets quads may be subdivided into subquads and signs, related by operators.\n",
    "If there is an operator *op* between `qLeft` and `qRight`, there is an \n",
    "edge between `qLeft` and `qRight` with feature `op` having value *op*.\n",
    "\n",
    "And if a quad is the result of an operator working on operands, which are sub-*quads* or *signs*,\n",
    "there will be edges between the big quad and its operands with feature `sub`, having no value.\n",
    "\n",
    "Likewise, there will be edges between *lines* and *cases* and their subcases, also\n",
    "having feature `sub` with no value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "By now you have an impression how to compute around in the Hebrew Bible.\n",
    "While this is still the beginning, I hope you already sense the power of unlimited programmatic access\n",
    "to all the bits and bytes in the data set.\n",
    "\n",
    "Here are a few directions for unleashing that power.\n",
    "\n",
    "## Search\n",
    "Text-Fabric contains a flexible search engine, that does not only work for the BHSA data,\n",
    "but also for data that you add to it.\n",
    "There is a tutorial dedicated to [search](search.ipynb).\n",
    "And if you already know MQL queries, you can build from that in\n",
    "[searchFromMQL](searchFromMQL.ipynb).\n",
    "\n",
    "## Explore additional data\n",
    "The ETCBC has a few other repositories with data that work in conjunction with the BHSA data.\n",
    "One of them you have already seen: \n",
    "[phono](https://github.com/ETCBC/phono),\n",
    "for phonetic transcriptions.\n",
    "\n",
    "There is also\n",
    "[parallels](https://github.com/ETCBC/parallels)\n",
    "for detecting parallel passages,\n",
    "and\n",
    "[valence](https://github.com/ETCBC/valence)\n",
    "for studying patterns around verbs that determine their meanings.\n",
    "\n",
    "## Add your own data\n",
    "If you study the additional data, you can observe how that data is created and also\n",
    "how it is turned into a text-fabric data module.\n",
    "The last step is incredibly easy. You can write out every Python dictionary where the keys are numbers\n",
    "and the values string or numbers as a Text-Fabric feature.\n",
    "When you are creating data, you have already constructed those dictionaries, so writing\n",
    "them out is just one method call.\n",
    "See for example how the\n",
    "[flowchart](https://github.com/ETCBC/valence/blob/master/programs/flowchart.ipynb#Add-sense-feature-to-valence-module)\n",
    "notebook in valence writes out verb sense data.\n",
    "![flow](images/valence.png)\n",
    "\n",
    "You can then easily share your new features on GitHub, so that your colleagues everywhere \n",
    "can try it out for themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Emdros MQL\n",
    "\n",
    "[EMDROS](http://emdros.org), written by Ulrik Petersen,\n",
    "is a text database system with the powerful *topographic* query language MQL.\n",
    "The ideas are based on a model devised by Christ-Jan Doedens in\n",
    "[Text Databases: One Database Model and Several Retrieval Languages](https://books.google.nl/books?id=9ggOBRz1dO4C).\n",
    "\n",
    "Text-Fabric's model of slots, nodes and edges is a fairly straightforward translation of the models of Christ-Jan Doedens and Ulrik Petersen.\n",
    "\n",
    "[SHEBANQ](https://shebanq.ancient-data.org) uses EMDROS to offer users to execute and save MQL queries against the Hebrew Text Database of the ETCBC.\n",
    "\n",
    "So it is kind of logical and convenient to be able to work with a Text-Fabric resource through MQL.\n",
    "\n",
    "If you have obtained an MQL dataset somehow, you can turn it into a text-fabric data set by `importMQL()`,\n",
    "which we will not show here.\n",
    "\n",
    "And if you want to export a Text-Fabric data set to MQL, that is also possible.\n",
    "\n",
    "After the `Fabric(modules=...)` call, you can call `exportMQL()` in order to save all features of the\n",
    "indicated modules into a big MQL dump, which can be imported by an EMDROS database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clean caches\n",
    "\n",
    "Text-Fabric pre-computes data for you, so that it can be loaded faster.\n",
    "If the original data is updated, Text-Fabric detects it, and will recompute that data.\n",
    "\n",
    "But there are cases, when the algorithms of Text-Fabric have changed, without any changes in the data, that you might\n",
    "want to clear the cache of precomputed results.\n",
    "\n",
    "There are two ways to do that:\n",
    "\n",
    "* Locate the `.tf` directory of your dataset, and remove all `.tfx` files in it.\n",
    "  This might be a bit awkward to do, because the `.tf` directory is hidden on Unix-like systems.\n",
    "* Call `TF.clearCache()`, which does exactly the same.\n",
    "\n",
    "It is not handy to execute the following cell all the time, that's why I have commented it out.\n",
    "So if you really want to clear the cache, remove the comment sign below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:48.202043Z",
     "start_time": "2018-02-20T21:14:48.189363Z"
    }
   },
   "outputs": [],
   "source": [
    "# TF.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
