{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/quad.png\" width=\"300\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "This notebook gets you started with using\n",
    "[Text-Fabric](https://github.com/Dans-labs/text-fabric) for coding in cuneiform tablet transcriptions.\n",
    "\n",
    "## What is Text-Fabric?\n",
    "\n",
    "### Cuneiform tablets in ATF\n",
    "\n",
    "Cuneiform tablets have been transcribed in ATF files, in which the marks on a tablet are represented\n",
    "by ascii characters. The marks on a tablet have structure (they can be composed, they build cases and lines) and properties (they can be uncertain).\n",
    "\n",
    "When you search for tablet data in an ATF file, you can do so conveniently by using regular expressions.\n",
    "\n",
    "However, the ATF transcriptions have become packed with information. Not every transcriber uses ATF in the same way, and there are a few coding errors in the sources.\n",
    "\n",
    "That means that the most obvious search expressions will leave out cases. Either you live with that, or you refine your search expressions.\n",
    "\n",
    "An other issue is, that when you look for something, your search expressions must reflect the shape of not\n",
    "only your target, but also everything else. There is virtually no separation of concerns.\n",
    "\n",
    "### Text-Fabric\n",
    "\n",
    "Text-Fabric is a model for textual data with annotations that is optimized for efficient data analysis. Not only that, it also facilitates the creation of new, derived data, which can be added to the original data.\n",
    "Data combination is a feature of Text-Fabric.\n",
    "\n",
    "Text-Fabric is being used for the [Hebrew Bible]() and a large body of linguisitic annotations on top of it. The researchers of the [ETCBC]() thought that a plain database is not a satisfactory text model, and that XML is too limited too express multiple hierarchies in a text smoothly.\n",
    "\n",
    "That's why they adopted a model by [Doedens]() that reflects more of the essential properties of text (sequence, embedding). This model is the basis of MQL, a working text-database system.\n",
    "Text-Fabric is based on the same model, and once the data is in Text-Fabric, it can be exported to MQL.\n",
    "\n",
    "With data in Text-Fabric, it becomes possible to build rich online interfaces on the data of ancient texts.\n",
    "For the Hebrew Bible, we have built [SHEBANQ]().\n",
    "\n",
    "Working with TF is a bit like buying from IKEA. You get your product in bits and pieces, and you assemble it yourself. TF decomposes any dataset into its components, nicely stacked per component, with every component uniquely labeled. You go to the store, make your selection, enter the warehouse, collect your parts, and, at home, assemble your product.\n",
    "\n",
    "In order to enjoy an IKEA product, you do not need to be a craftsman, but you do need to be able to handle a screw driver.\n",
    "\n",
    "In the TF world, it is the same. You do not have to be a professional programmer, but you do need to be able to program little things. A first course in Python is enough.\n",
    "\n",
    "Another parallel: in IKEA you take a package with components home, and there you assemble it. \n",
    "In TF it is likewise: you download the TF data, and then you write a little program. Inside that program you can call up the Text-Fabric tool, which act as the IKEA user manual. But your program takes control, not Text-Fabric.\n",
    "\n",
    "The best environment to enjoy Text-Fabric is in Python programs that you develop in a \n",
    "[Jupyter Notebook]().\n",
    "This tutorial is such a notebook. If you are reading it online, you see text bits and code bits,\n",
    "but you cannot execute the code bits.\n",
    "\n",
    "If you download this tutorial, and you have installed Python, Jupyter, and Text-Fabric,\n",
    "you can *execute* the code bits.\n",
    "\n",
    "## Overview\n",
    "\n",
    "* we tell you how to get Text-Fabric on your system\n",
    "* we tell you how to get a set of cuneiform tablet transcriptions on your system\n",
    "* we show how to explore the data:\n",
    "  * finding the relevant nodes\n",
    "  * moving from one place to an other\n",
    "  * collecting the relevant information\n",
    "  * perform analysis\n",
    "  * visualize your results\n",
    "\n",
    "## More information\n",
    "Chances are that a bit of reading about the underlying\n",
    "[data model](https://github.com/Dans-labs/text-fabric/wiki/Data-model)\n",
    "helps you to follow the exercises below, and vice versa.\n",
    "\n",
    "We have checked the conversion from the transcriptions to Text-Fabric extensively.\n",
    "Cruelly, you might say. You can follow the checks\n",
    "in a separate notebook [checks](checks.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Text-Fabric\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "You need to have Python on your system. Most systems have it out of the box,\n",
    "but alas, that is python2 and we need at least python 3.6.\n",
    "\n",
    "Install it from [python.org]() or from [Anaconda]().\n",
    "If you got it from python.org, you also have to install [Jupyter]().\n",
    "\n",
    "### TF itself\n",
    "\n",
    "```\n",
    "pip install text-fabric\n",
    "```\n",
    "\n",
    "if you have installed Python with the help of Anaconda, or\n",
    "\n",
    "```\n",
    "sudo -H pip3 install text-fabric\n",
    "```\n",
    "if you have installed Python from [python.org](https://www.python.org).\n",
    "\n",
    "###### Execute: If all this is done, the following cells can be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:28:40.626290Z",
     "start_time": "2018-02-25T07:28:40.603516Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:28:41.263545Z",
     "start_time": "2018-02-25T07:28:41.225618Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, collections\n",
    "from tf.fabric import Fabric\n",
    "from utils import Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuneiform data\n",
    "\n",
    "We have prepared a corpus of 6000 tablets, from the Uruk-III/IV period in Text-Fabric.\n",
    "We have downloaded the transcriptions from CDLI, and converted them to Text-Fabric.\n",
    "\n",
    "You can get the results from GitHub as follows.\n",
    "\n",
    "We suggest you make an appropriate directory in your home directory:\n",
    "\n",
    "```\n",
    "github/Dans-labs\n",
    "```\n",
    "\n",
    "then go to that directory in a terminal, and then say\n",
    "\n",
    "```\n",
    "git clone https://github.com/Dans-labs/Nino-cunei\n",
    "```\n",
    "\n",
    "After that your directory structure shold look like this:\n",
    "\n",
    "    your home direcectory\\\n",
    "    |                     - github\\\n",
    "    |                       |      - Dans-labs\\\n",
    "    |                       |        |         - Nino-cunei\n",
    "    \n",
    "#### Tip\n",
    "If you start computing with this tutorial, first copy its parent directory to somewhere else,\n",
    "outside your `Nino-cunei` directory.\n",
    "If you pull changes from the `Nino-cunei` repository later, your work will not be overwritten.\n",
    "Where you put your tutorial directory is up till you.\n",
    "It will work from any directory.\n",
    "\n",
    "###### Execute: it this has been done, you can execute the next cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:30:54.884329Z",
     "start_time": "2018-02-25T07:30:54.847354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.2.0\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "33 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "REPO = '~/github/Dans-labs/Nino-cunei'\n",
    "SOURCE = 'uruk'\n",
    "VERSION = '0.1'\n",
    "CORPUS = f'{REPO}/tf/{SOURCE}/{VERSION}'\n",
    "SOURCE_DIR = os.path.expanduser(f'{REPO}/sources/cdli')\n",
    "TEMP_DIR = os.path.expanduser(f'{REPO}/_temp')\n",
    "TF = Fabric(locations=[CORPUS], modules=[''], silent=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "The transcriptions of the tablets in their TF form is organized in a model of nodes, edges and features.\n",
    "\n",
    "The things such as tablets, faces, columns, cases, and, at the most basic level, signs, are numbered.\n",
    "The signs correspond to number 1 ... ca. 120,000, in the same order as they occur in the corpus.\n",
    "All other things are built from signs. They have number from ca 120,000 to 450,000.\n",
    "\n",
    "In TF, we call these numbers *nodes*. Like a barcode, this number gives access to a whole bunch of\n",
    "information about the corresponding object.\n",
    "\n",
    "For example, lines have a property (in TF we call it a *feature*) called `fullNumber`. \n",
    "It contains the hierarchical number found at the start of the line in the transcription.\n",
    "\n",
    "If the node for a line is `n`, we can find its hierarchical number by saying\n",
    "\n",
    "```\n",
    "F.fullNumber.v(n)\n",
    "```\n",
    "\n",
    "In words, it reads as:\n",
    "\n",
    "* `F`: I want to look up a `F`eature\n",
    "* `fullNumber`: the name of the feature\n",
    "* `.v`: I want the value of that feature\n",
    "* `(n)`: for the given node `n`\n",
    "\n",
    "Seen in this way, the data is like a gigantic spreadsheet of 450,000 rows (the nodes),\n",
    "with 30 columns (the features).\n",
    "\n",
    "There is a bit more to it, since the nodes can be grouped together in ways we will see in a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grapheme name of each sign is a column `grapheme` in that spreadsheet.\n",
    "\n",
    "The information whether a sign is damaged, constitutes a column `damaged`.\n",
    "\n",
    "The corpus contains over 20 columns, not only for the signs, but also for a 150,000+ more\n",
    "textual objects, such as *(sub)quads*, *clusters*, *lines*, *cases*, *columns*, *faces* and *tablets*.\n",
    "\n",
    "We also have features that contain the original lines of transcription.\n",
    "These features are filled for tablets, faces, columns, lines, and comments.\n",
    "\n",
    "Instead of putting that information in one big table, the data is organized in separate columns.\n",
    "We call those columns **features**.\n",
    "\n",
    "We just load the features we need for this tutorial.\n",
    "Later on, where we use them, it will become clear what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:42:58.410504Z",
     "start_time": "2018-02-25T07:42:57.313950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.00s B catalogId            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B fullNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B number               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.05s B grapheme             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.04s B srcLn                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B srcLnNum             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B prime                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B repeat               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B variant              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B variantOuter         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifier             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierInner        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierFirst        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B damage               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B uncertain            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B remarkable           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B written              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B kind                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B period               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B name                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B type                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B identifier           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B origNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B badNumbering         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B crossref             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B text                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B op                   from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.09s B sub                  from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B comments             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s Feature overview: 28 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  1.08s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    grapheme prime repeat\n",
    "    variant variantOuter\n",
    "    modifier modifierInner modifierFirst\n",
    "    damage uncertain remarkable written\n",
    "    kind\n",
    "    period name type identifier catalogId\n",
    "    number fullNumber origNumber badNumbering\n",
    "    crossref text\n",
    "    srcLn srcLnNum\n",
    "    op sub comments''')\n",
    "api.makeAvailableIn(globals())\n",
    "COMP = Compare(api, SOURCE_DIR, TEMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this all is that we have a bunch of special variables at our disposal\n",
    "that give us access to the text and data of the tablets.\n",
    "\n",
    "At this point it is helpful to throw a quick glance at the text-fabric\n",
    "[API documentation](https://github.com/Dans-labs/text-fabric/wiki/Api)\n",
    "especially the right side bar.\n",
    "\n",
    "The most essential thing for now is that we can use `F` to access the data in the features\n",
    "we've loaded.\n",
    "But there is more, such as `N`, which helps us to walk over the text, as we see in a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting\n",
    "\n",
    "In order to get acquainted with the data, we start with the simple task of counting.\n",
    "\n",
    "## Count all nodes\n",
    "We use the \n",
    "[`N()` generator](https://github.com/Dans-labs/text-fabric/wiki/Api#walking-through-nodes)\n",
    "to walk through the nodes.\n",
    "\n",
    "We compared the tablet data to a gigantic spreadsheet, where the rows correspond to the words.\n",
    "In Text-Fabric, we call the rows `slots`, because they are the textual positions that can be filled with words.\n",
    "\n",
    "We also mentioned that there are also other textual objects. \n",
    "They are the tablets, columns, lines, etc.\n",
    "They also correspond to rows in the big spreadsheet.\n",
    "\n",
    "In Text-Fabric we call all these rows *nodes*, and the `N()` generator\n",
    "carries us through those nodes in the textual order.\n",
    "\n",
    "Just one extra thing: the `info` statements generate timed messages.\n",
    "If you use them instead of `print` you'll get a sense of the amount of time that \n",
    "the various processing steps typically need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:12.522931Z",
     "start_time": "2018-02-25T07:43:12.427779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Counting nodes ...\n",
      "  0.08s 318107 nodes\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('Counting nodes ...')\n",
    "\n",
    "i = 0\n",
    "for n in N(): i += 1\n",
    "\n",
    "info('{} nodes'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see it: more than 400,000 nodes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are all those nodes?\n",
    "Every node has a type, like sign, or line, face.\n",
    "We know that we have many of them,\n",
    "but what exactly are they?\n",
    "\n",
    "Text-Fabric has two special features, `otype` and `oslots`, that must occur in every Text-Fabric data set.\n",
    "`otype` tells you for each node its type, and you can ask for the number of `slot`s in the text.\n",
    "\n",
    "Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:16.236487Z",
     "start_time": "2018-02-25T07:43:16.212617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sign'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.slotType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:17.825314Z",
     "start_time": "2018-02-25T07:43:17.805172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146955"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxSlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:18.822218Z",
     "start_time": "2018-02-25T07:43:18.802670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318107"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.maxNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:20.693642Z",
     "start_time": "2018-02-25T07:43:20.668236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tablet',\n",
       " 'face',\n",
       " 'column',\n",
       " 'line',\n",
       " 'case',\n",
       " 'cluster',\n",
       " 'quad',\n",
       " 'comment',\n",
       " 'sign')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain a bit more knowledge about the types of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:25.972331Z",
     "start_time": "2018-02-25T07:43:25.952538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tablet   average length 22.9761 from 150862 to 157257\n",
      "face     average length 14.3466 from 157258 to 166699\n",
      "column   average length  9.4888 from 166700 to 180732\n",
      "line     average length  3.5643 from 229498 to 266422\n",
      "case     average length  3.1821 from 266423 to 318107\n",
      "cluster  average length  1.0313 from 196539 to 229497\n",
      "quad     average length  2.0507 from 146956 to 150861\n",
      "comment  average length  1.0000 from 180733 to 196538\n",
      "sign     average length  1.0000 from      1 to 146955\n"
     ]
    }
   ],
   "source": [
    "for (nodeType, avLen, startNode, endNode) in C.levels.data:\n",
    "    print(f'{nodeType:<8} average length {avLen:>7.4f} from {startNode:>6} to {endNode:>6}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the first *cluster*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:28.447234Z",
     "start_time": "2018-02-25T07:43:28.429645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196539"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = F.otype.s('cluster')[0]\n",
    "cl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what is embedded in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:31.324225Z",
     "start_time": "2018-02-25T07:43:31.307019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node      3 of type sign\n"
     ]
    }
   ],
   "source": [
    "for n in L.d(cl):\n",
    "    print(f'node {n:>6} of type {F.otype.v(n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the third *sign*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:39.957015Z",
     "start_time": "2018-02-25T07:43:39.941306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sign'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.otype.v(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:42.486298Z",
     "start_time": "2018-02-25T07:43:42.468692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 196539 of type cluster\n",
      "node 266423 of type case\n",
      "node 229498 of type line\n",
      "node 166700 of type column\n",
      "node 157258 of type face\n",
      "node 150862 of type tablet\n"
     ]
    }
   ],
   "source": [
    "for n in L.u(3):\n",
    "    print(f'node {n:>6} of type {F.otype.v(n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count individual object types\n",
    "This is an intuitive way to count the number of nodes in each type.\n",
    "Note in passing, how we use the `indent` in conjunction with `info` to produce neat timed \n",
    "and indented progress messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:46.194437Z",
     "start_time": "2018-02-25T07:43:46.073914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s counting objects ...\n",
      "   |     0.00s    6396 tablets\n",
      "   |     0.00s    9442 faces\n",
      "   |     0.01s   14033 columns\n",
      "   |     0.00s   36925 lines\n",
      "   |     0.01s   51685 cases\n",
      "   |     0.01s   32959 clusters\n",
      "   |     0.00s    3906 quads\n",
      "   |     0.00s   15806 comments\n",
      "   |     0.02s  146955 signs\n",
      "  0.09s Done\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('counting objects ...')\n",
    "\n",
    "for otype in F.otype.all:\n",
    "    i = 0\n",
    "\n",
    "    indent(level=1, reset=True)\n",
    "\n",
    "    for n in F.otype.s(otype): i+=1\n",
    "\n",
    "    info('{:>7} {}s'.format(i, otype))\n",
    "\n",
    "indent(level=0)\n",
    "info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locality\n",
    "\n",
    "We travel upwards and downwards, forwards and backwards through the nodes.\n",
    "The Locality-API (`L`) provides functions: `u()` for going up, and `d()` for going down,\n",
    "`n()` for going to next nodes and `p()` for going to previous nodes.\n",
    "\n",
    "These directions are indirect notions: nodes are just numbers, but by means of the\n",
    "`oslots` feature they are linked to slots. One node *contains* an other node, if the one is linked to a set of slots that contains the set of slots that the other is linked to.\n",
    "And one if next or previous to an other, if its slots follow of precede the slots of the other one.\n",
    "\n",
    "`L.u(node)` **Up** is going to nodes that embed `node`.\n",
    "\n",
    "`L.d(node)` **Down** is the opposite direction, to those that are contained in `node`.\n",
    "\n",
    "`L.n(node)` **Next** are the next *adjacent* nodes, i.e. nodes whose first slot comes immediately after the last slot of `node`.\n",
    "\n",
    "`L.p(node)` **Previous** are the previous *adjacent* nodes, i.e. nodes whose last slot comes immediately before the first slot of `node`.\n",
    "\n",
    "All these functions yield nodes of all possible otypes.\n",
    "By passing an optional parameter, you can restrict the results to nodes of that type.\n",
    "\n",
    "The result are ordered according to the order of things in the text.\n",
    "\n",
    "The functions return always a tuple, even if there is just one node in the result.\n",
    "\n",
    "## Going up\n",
    "We go from the first sign to the tablet it contains.\n",
    "Note the `[0]` at the end. You expect one tablet, yet `L` returns a tuple. \n",
    "To get the only element of that tuple, you need to do that `[0]`.\n",
    "\n",
    "If you are like me, you keep forgetting it, and that will lead to weird error messages later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:48.943792Z",
     "start_time": "2018-02-25T07:43:48.925269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150862\n"
     ]
    }
   ],
   "source": [
    "firstTablet = L.u(1, otype='tablet')[0]\n",
    "print(firstTablet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see all the containing objects of sign 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:50.905159Z",
     "start_time": "2018-02-25T07:43:50.880114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sign 100 is contained in tablet 150866\n",
      "sign 100 is contained in face 157264\n",
      "sign 100 is contained in column 166712\n",
      "sign 100 is contained in line 229525\n",
      "sign 100 is contained in case 266453\n",
      "sign 100 is not contained in a cluster\n",
      "sign 100 is not contained in a quad\n",
      "sign 100 is not contained in a comment\n"
     ]
    }
   ],
   "source": [
    "w = 100\n",
    "for otype in F.otype.all:\n",
    "    if otype == F.otype.slotType: continue\n",
    "    up = L.u(w, otype=otype)\n",
    "    upNode = None if len(up) == 0 else up[0]\n",
    "    if upNode is None:\n",
    "        print('sign {} is not contained in a {}'.format(w, otype))\n",
    "    else:\n",
    "        print('sign {} is contained in {} {}'.format(w, otype, upNode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going next\n",
    "Let's go to the next nodes of the first tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:53.603117Z",
     "start_time": "2018-02-25T07:43:53.581980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10: sign          first slot=10    , last slot=10    \n",
      " 180735: comment       first slot=10    , last slot=10    \n",
      " 150863: tablet        first slot=10    , last slot=39    \n"
     ]
    }
   ],
   "source": [
    "afterFirstTablet = L.n(firstTablet)\n",
    "for n in afterFirstTablet:\n",
    "    print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "        n, F.otype.v(n),\n",
    "        E.oslots.s(n)[0],\n",
    "        E.oslots.s(n)[-1],\n",
    "    ))\n",
    "secondTablet = L.n(firstTablet, otype='tablet')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going previous\n",
    "\n",
    "And let's see what is right before the second tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:55.886088Z",
     "start_time": "2018-02-25T07:43:55.867096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 150862: tablet        first slot=1     , last slot=9     \n",
      " 157258: face          first slot=3     , last slot=9     \n",
      " 166701: column        first slot=6     , last slot=9     \n",
      " 229499: line          first slot=6     , last slot=9     \n",
      " 266424: case          first slot=6     , last slot=9     \n",
      " 196540: cluster       first slot=9     , last slot=9     \n",
      "      9: sign          first slot=9     , last slot=9     \n"
     ]
    }
   ],
   "source": [
    "for n in L.p(secondTablet):\n",
    "    print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "        n, F.otype.v(n),\n",
    "        E.oslots.s(n)[0],\n",
    "        E.oslots.s(n)[-1],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go to the columns of the second tablet, and just count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:43:58.940136Z",
     "start_time": "2018-02-25T07:43:58.922260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "columns = L.d(secondTablet, otype='column')\n",
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first line\n",
    "We pick the first line and the first sign, and explore what is above and below them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:01.224915Z",
     "start_time": "2018-02-25T07:44:01.165562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1\n",
      "   |   UP\n",
      "   |      |   180733          comment\n",
      "   |      |   150862          tablet\n",
      "   |   DOWN\n",
      "   |      |   \n",
      "Node 229498\n",
      "   |   UP\n",
      "   |      |   266423          case\n",
      "   |      |   166700          column\n",
      "   |      |   157258          face\n",
      "   |      |   150862          tablet\n",
      "   |   DOWN\n",
      "   |      |   166700          column\n",
      "   |      |   266423          case\n",
      "   |      |   196539          cluster\n",
      "   |      |   3               sign\n",
      "   |      |   4               sign\n",
      "   |      |   5               sign\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "firstLine = L.d(firstTablet, otype='line')[0]\n",
    "\n",
    "for n in [1, firstLine]:\n",
    "    indent(level=0)\n",
    "    info('Node {}'.format(n), tm=False)\n",
    "    indent(level=1)\n",
    "    info('UP', tm=False)\n",
    "    indent(level=2)\n",
    "    info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.u(n)]), tm=False)\n",
    "    indent(level=1)\n",
    "    info('DOWN', tm=False)\n",
    "    indent(level=2)\n",
    "    info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.d(n)]), tm=False)\n",
    "indent(level=0)\n",
    "info('Done', tm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text\n",
    "\n",
    "The `T` functions provide ways of printing out text, and they know about section levels.\n",
    "\n",
    "We use section levels `tablet`, `column`, `line`.\n",
    "`face` is a level of nodes, but not a section level.\n",
    "\n",
    "We will define our own function to get the literal transcription text back for\n",
    "tablets, faces, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:03.726103Z",
     "start_time": "2018-02-25T07:44:03.690701Z"
    }
   },
   "outputs": [],
   "source": [
    "oLevels = '''\n",
    "    tablet\n",
    "    face\n",
    "    column\n",
    "    case\n",
    "'''.strip().split()\n",
    "\n",
    "lowerLevel = dict((oLevels[n], oLevels[n+1]) for n in range(len(oLevels) - 1))\n",
    "\n",
    "def transObject(n):\n",
    "    kind = F.otype.v(n)\n",
    "    trans = []\n",
    "    trans.append(f'{F.srcLnNum.v(n):>7}: {F.srcLn.v(n)}')\n",
    "    for c in E.comments.f(n):\n",
    "        trans.append(f'{F.srcLnNum.v(c):>7}: {F.srcLn.v(c)}')\n",
    "    print('\\n'.join(trans))\n",
    "    subKind = lowerLevel.get(kind, None)\n",
    "    if subKind:\n",
    "        for m in L.d(n, otype=subKind):\n",
    "            if F.srcLn.v(m) is not None:\n",
    "                transObject(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:05.565633Z",
     "start_time": "2018-02-25T07:44:05.549084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1: &P006427 = HJN 0044\n",
      "      2: #version: 0.1\n",
      "      3: #atf: lang qpc\n",
      "      4: @obverse\n",
      "      5: @column 1\n",
      "      6: 1. [...] , X X\n",
      "      7: @column 2\n",
      "      8: 1. 3(N14) X SANGA~a? [...]\n"
     ]
    }
   ],
   "source": [
    "transObject(firstTablet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know the *P-number*, we can get the tablet with that P-number by means of\n",
    "`T.nodeFromSection()`.\n",
    "\n",
    "You pass this function a tuple, representing *tablet*, *column*, *line*, and it gives you back\n",
    "the node of the corresponding object.\n",
    "\n",
    "*column* and *line* are optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:07.886926Z",
     "start_time": "2018-02-25T07:44:07.866952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150867"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabletId = 'P471695'\n",
    "tabletNode = T.nodeFromSection((tabletId,))\n",
    "tabletNode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the transcription of this tablet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:09.836452Z",
     "start_time": "2018-02-25T07:44:09.818593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     87: &P471695 = Anonymous 0712 \n",
      "     88: #atf: lang qpc \n",
      "     90: @obverse \n",
      "     91: @column 1\n",
      "     92: 1.a. 3(N01) , APIN~a 3(N57) UR4~a \n",
      "     93: 1.b1. , (EN~a DU ZATU759)a \n",
      "     94: 1.b2. , (BAN~b KASZ~c)a \n",
      "     95: 1.b3. , (KI@n SAG)a \n",
      "     96: 2.a. 1(N14) 2(N01) , [...] \n",
      "     97: 2.b1. , (3(N57) PAP~a)a \n",
      "     98: 2.b2. , (SZU KI X)a \n",
      "     99: $ n lines broken  \n",
      "    100: 2.b3'. , (EN~a AN EZINU~d)a \n",
      "    101: 2.b4'. , (IDIGNA [...])a \n",
      "    102: $ rest broken \n",
      "    103: $ (for a total of 12 sub-cases with PNN) \n",
      "    104: @column 2\n",
      "    105: 1.a. 1(N01) , ISZ~a#? \n",
      "    106: 1.b1. , (PAP~a GIR3~c)a\n",
      "    107: $ blank space \n",
      "    108: $ rest broken \n",
      "    109: @reverse \n",
      "    110: $ beginning broken \n",
      "    111: 1'. [1(N14)] 6(N01)# , [...] \n",
      "    111: 1'. [1(N14)] 6(N01)# , [...] \n"
     ]
    }
   ],
   "source": [
    "transObject(tabletNode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphemes\n",
    "\n",
    "`F`\n",
    "gives access to all features.\n",
    "Every feature has a method\n",
    "`freqList()`\n",
    "to generate a frequency list of its values, higher frequencies first.\n",
    "Here are the graphemes (the top 20):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:12.436594Z",
     "start_time": "2018-02-25T07:44:12.324263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29618 x …\n",
      "21676 x N01\n",
      "17128 x \n",
      " 6956 x X\n",
      " 5924 x N14\n",
      " 1970 x EN\n",
      " 1846 x N57\n",
      " 1835 x N34\n",
      " 1349 x SZE\n",
      " 1241 x GAL\n",
      " 1125 x DUG\n",
      " 1069 x AN\n",
      " 1046 x U4\n",
      "  892 x NUN\n",
      "  881 x SAL\n",
      "  879 x PAP\n",
      "  877 x E2\n",
      "  875 x GI\n",
      "  788 x BA\n",
      "  747 x SANGA\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.grapheme.freqList()[0:20]:\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a bit more: we'll write a file with all graphemes to your TEMP_DIR.\n",
    "In fact, we'll write two: one ordered by grapheme, and one ordered by frequency.\n",
    "\n",
    "In order to not clutter this notebook, we use a function `writeFreqs()`, defined in \n",
    "[utils](utils.py) in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:17.246731Z",
     "start_time": "2018-02-25T07:44:17.139349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 667 bare graphemes\n"
     ]
    }
   ],
   "source": [
    "COMP.writeFreqs('grapheme-plain', F.grapheme.freqList(), 'bare grapheme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a look at your TEMP_DIR and you see two generated files:\n",
    "\n",
    "* `graphemes-plain-alpha.txt` (sorted by grapheme)\n",
    "* `graphemes-plain-freq.txt` (sorted by frequency)\n",
    "\n",
    "But we can do better, we also want the prime, variants, and modifiers taken into account.\n",
    "\n",
    "Let us first see what they can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prime\n",
    "\n",
    "The prime is a feature with two values: 1 or 0. 1 means: there is a prime.\n",
    "Below you see how often that occurs.\n",
    "Note that we count all primes here: on signs, case numbers and column numbers.\n",
    "\n",
    "For more info and a check on the occurrences of primes, see [checks](checks.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:21.895691Z",
     "start_time": "2018-02-25T07:44:21.868102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5184 x 1\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.prime.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant\n",
    "\n",
    "The variant or allograph is what occurs after the grapheme and after the `~` symbol, which should be digits and/or\n",
    "lowercase letters except the `x`.\n",
    "\n",
    "Here is the frequency list of variant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:23.950506Z",
     "start_time": "2018-02-25T07:44:23.905553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23804 x a\n",
      " 4172 x b\n",
      " 1532 x c\n",
      " 1356 x a1\n",
      "  703 x b1\n",
      "  194 x a2\n",
      "  187 x d\n",
      "  127 x b2\n",
      "   85 x f\n",
      "   73 x a3\n",
      "   40 x e\n",
      "   29 x c2\n",
      "   22 x c1\n",
      "   22 x c3\n",
      "   17 x v\n",
      "   14 x c5\n",
      "   13 x b3\n",
      "   12 x a0\n",
      "   12 x d1\n",
      "   11 x c4\n",
      "    6 x a4\n",
      "    6 x g\n",
      "    5 x d2\n",
      "    4 x d4\n",
      "    4 x h\n",
      "    2 x 3a\n",
      "    2 x d3\n",
      "    1 x h2\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.variant.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifier\n",
    "\n",
    "The modifier is what occurs after the grapheme and after the `@` symbol, which should be digits and/or\n",
    "lowercase letters except the `x`.\n",
    "\n",
    "Here is the frequency list of *modifier* and *rmodifier* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:26.809651Z",
     "start_time": "2018-02-25T07:44:26.791269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  648 x g\n",
      "  251 x t\n",
      "   39 x n\n",
      "    6 x r\n",
      "    4 x s\n",
      "    1 x c\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifier.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:38.893781Z",
     "start_time": "2018-02-25T07:44:38.876426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 x f\n",
      "   15 x t\n",
      "    1 x r\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifierInner.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full grapheme overview\n",
    "\n",
    "We make a frequency list of all full graphemes, i.e. the grapheme including variant, modifier, and prime.\n",
    "We show as they appear in transcriptions.\n",
    "\n",
    "First we show on what node types primes, variants and modifiers occur.\n",
    "We only deal with cases where they occur on signs, ignoring the cases where they occur on (sub)quads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:44:46.592272Z",
     "start_time": "2018-02-25T07:44:45.610765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prime     :  4652 x case\n",
      "prime     :   523 x column\n",
      "prime     :     9 x sign\n",
      "variant   : 32455 x sign\n",
      "modifier  :   950 x sign\n"
     ]
    }
   ],
   "source": [
    "for feature in ('prime', 'variant', 'modifier'):\n",
    "    nodeTypes = collections.Counter()\n",
    "    for n in N():\n",
    "        if Fs(feature).v(n):\n",
    "            nodeTypes[F.otype.v(n)] += 1\n",
    "    for (value, frequency) in nodeTypes.items():\n",
    "        print(f'{feature:<10}: {frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the full graphemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-25T07:45:03.442045Z",
     "start_time": "2018-02-25T07:45:02.802767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29618 x ...\n",
      "17128 x \n",
      "12996 x 1(N01)\n",
      " 6956 x X\n",
      " 3081 x 2(N01)\n",
      " 2606 x 1(N14)\n",
      " 1849 x EN~a\n",
      " 1603 x 3(N01)\n",
      " 1357 x 2(N14)\n",
      " 1308 x SZE~a\n",
      " 1304 x 5(N01)\n",
      " 1224 x GAL~a\n",
      " 1119 x 4(N01)\n",
      " 1069 x AN\n",
      " 1045 x U4\n",
      " 1001 x 1(N34)\n",
      "  881 x SAL\n",
      "  874 x GI\n",
      "  854 x PAP~a\n",
      "  801 x 1(N57)\n",
      "There are 1529 full graphemes\n"
     ]
    }
   ],
   "source": [
    "fullGraphemes = collections.Counter()\n",
    "\n",
    "for n in F.otype.s('sign'):\n",
    "    fullGrapheme = COMP.strFromSign(n)\n",
    "    fullGraphemes[fullGrapheme] += 1\n",
    "    \n",
    "for (value, frequency) in sorted(fullGraphemes.items(), key=lambda x: (-x[1], x[0]))[0:20]:\n",
    "    print(f'{frequency:>5} x {value}')\n",
    "    \n",
    "COMP.writeFreqs('grapheme-full', fullGraphemes.items(), 'full grapheme')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge features: left and right\n",
    "\n",
    "We have not talked about edges much. If the nodes correspond to the rows in the big spreadsheet,\n",
    "the edges point from one row to another.\n",
    "\n",
    "One edge we have encountered: the special feature `oslots`.\n",
    "Each non-slot node is linked by `oslots` to all of its slot nodes.\n",
    "\n",
    "An edge is really a feature as well.\n",
    "Whereas a node feature is a column of information,\n",
    "one cell per node, \n",
    "an edge feature is also a column of information, one cell per pair of nodes.\n",
    "\n",
    "In the tablets quads may be subdivided into subquads and signs, related by operators.\n",
    "If there is an operator *op* between `qLeft` and `qRight`, there is an \n",
    "edge between `qLeft` and `qRight` with feature `op` having value *op*.\n",
    "\n",
    "And if a quad is the result of an operator working on operands, which are sub-*quads* or *signs*,\n",
    "there will be edges between the big quad and its operands with feature `sub`, having no value.\n",
    "\n",
    "Likewise, there will be edges between *lines* and *cases* and their subcases, also\n",
    "having feature `sub` with no value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "By now you have an impression how to compute around in the Hebrew Bible.\n",
    "While this is still the beginning, I hope you already sense the power of unlimited programmatic access\n",
    "to all the bits and bytes in the data set.\n",
    "\n",
    "Here are a few directions for unleashing that power.\n",
    "\n",
    "## Search\n",
    "Text-Fabric contains a flexible search engine, that does not only work for the BHSA data,\n",
    "but also for data that you add to it.\n",
    "There is a tutorial dedicated to [search](search.ipynb).\n",
    "And if you already know MQL queries, you can build from that in\n",
    "[searchFromMQL](searchFromMQL.ipynb).\n",
    "\n",
    "## Explore additional data\n",
    "The ETCBC has a few other repositories with data that work in conjunction with the BHSA data.\n",
    "One of them you have already seen: \n",
    "[phono](https://github.com/ETCBC/phono),\n",
    "for phonetic transcriptions.\n",
    "\n",
    "There is also\n",
    "[parallels](https://github.com/ETCBC/parallels)\n",
    "for detecting parallel passages,\n",
    "and\n",
    "[valence](https://github.com/ETCBC/valence)\n",
    "for studying patterns around verbs that determine their meanings.\n",
    "\n",
    "## Add your own data\n",
    "If you study the additional data, you can observe how that data is created and also\n",
    "how it is turned into a text-fabric data module.\n",
    "The last step is incredibly easy. You can write out every Python dictionary where the keys are numbers\n",
    "and the values string or numbers as a Text-Fabric feature.\n",
    "When you are creating data, you have already constructed those dictionaries, so writing\n",
    "them out is just one method call.\n",
    "See for example how the\n",
    "[flowchart](https://github.com/ETCBC/valence/blob/master/programs/flowchart.ipynb#Add-sense-feature-to-valence-module)\n",
    "notebook in valence writes out verb sense data.\n",
    "![flow](images/valence.png)\n",
    "\n",
    "You can then easily share your new features on GitHub, so that your colleagues everywhere \n",
    "can try it out for themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Emdros MQL\n",
    "\n",
    "[EMDROS](http://emdros.org), written by Ulrik Petersen,\n",
    "is a text database system with the powerful *topographic* query language MQL.\n",
    "The ideas are based on a model devised by Christ-Jan Doedens in\n",
    "[Text Databases: One Database Model and Several Retrieval Languages](https://books.google.nl/books?id=9ggOBRz1dO4C).\n",
    "\n",
    "Text-Fabric's model of slots, nodes and edges is a fairly straightforward translation of the models of Christ-Jan Doedens and Ulrik Petersen.\n",
    "\n",
    "[SHEBANQ](https://shebanq.ancient-data.org) uses EMDROS to offer users to execute and save MQL queries against the Hebrew Text Database of the ETCBC.\n",
    "\n",
    "So it is kind of logical and convenient to be able to work with a Text-Fabric resource through MQL.\n",
    "\n",
    "If you have obtained an MQL dataset somehow, you can turn it into a text-fabric data set by `importMQL()`,\n",
    "which we will not show here.\n",
    "\n",
    "And if you want to export a Text-Fabric data set to MQL, that is also possible.\n",
    "\n",
    "After the `Fabric(modules=...)` call, you can call `exportMQL()` in order to save all features of the\n",
    "indicated modules into a big MQL dump, which can be imported by an EMDROS database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clean caches\n",
    "\n",
    "Text-Fabric pre-computes data for you, so that it can be loaded faster.\n",
    "If the original data is updated, Text-Fabric detects it, and will recompute that data.\n",
    "\n",
    "But there are cases, when the algorithms of Text-Fabric have changed, without any changes in the data, that you might\n",
    "want to clear the cache of precomputed results.\n",
    "\n",
    "There are two ways to do that:\n",
    "\n",
    "* Locate the `.tf` directory of your dataset, and remove all `.tfx` files in it.\n",
    "  This might be a bit awkward to do, because the `.tf` directory is hidden on Unix-like systems.\n",
    "* Call `TF.clearCache()`, which does exactly the same.\n",
    "\n",
    "It is not handy to execute the following cell all the time, that's why I have commented it out.\n",
    "So if you really want to clear the cache, remove the comment sign below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-20T21:14:48.202043Z",
     "start_time": "2018-02-20T21:14:48.189363Z"
    }
   },
   "outputs": [],
   "source": [
    "# TF.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
