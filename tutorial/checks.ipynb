{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Tablets\" data-toc-modified-id=\"Tablets-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Tablets</a></span></li><li><span><a href=\"#Faces\" data-toc-modified-id=\"Faces-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Faces</a></span></li><li><span><a href=\"#Columns\" data-toc-modified-id=\"Columns-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Columns</a></span></li><li><span><a href=\"#Lines\" data-toc-modified-id=\"Lines-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Lines</a></span></li><li><span><a href=\"#Graphemes\" data-toc-modified-id=\"Graphemes-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Graphemes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Primes\" data-toc-modified-id=\"Primes-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Primes</a></span></li><li><span><a href=\"#Variants-and-modifiers\" data-toc-modified-id=\"Variants-and-modifiers-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Variants and modifiers</a></span></li><li><span><a href=\"#Tweaks\" data-toc-modified-id=\"Tweaks-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Tweaks</a></span></li><li><span><a href=\"#Flags\" data-toc-modified-id=\"Flags-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Flags</a></span></li><li><span><a href=\"#All-signs\" data-toc-modified-id=\"All-signs-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>All signs</a></span></li></ul></li><li><span><a href=\"#Quads\" data-toc-modified-id=\"Quads-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Quads</a></span><ul class=\"toc-item\"><li><span><a href=\"#Outer-complex-quads\" data-toc-modified-id=\"Outer-complex-quads-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Outer complex quads</a></span></li><li><span><a href=\"#Variants:-inside-or-outside?\" data-toc-modified-id=\"Variants:-inside-or-outside?-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Variants: inside or outside?</a></span></li><li><span><a href=\"#Variants:-extra-level-of-brackets?\" data-toc-modified-id=\"Variants:-extra-level-of-brackets?-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Variants: extra level of brackets?</a></span></li><li><span><a href=\"#More-bracket-issues\" data-toc-modified-id=\"More-bracket-issues-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>More bracket issues</a></span></li><li><span><a href=\"#The-most-complex-quads\" data-toc-modified-id=\"The-most-complex-quads-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>The most complex quads</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks\n",
    "Various checks on the correctness of the transformation from ascii transcriptions to a text-fabric data set.\n",
    "\n",
    "The\n",
    "[diagnostics](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/diagnostics.tsv)\n",
    "of the transformation contains valueable issues that may be used to correct mistakes in the sources.\n",
    "Or, equally likely, they correspond to misunderstandings on my (Dirk's) part of the model\n",
    "that underlies the transcriptions.\n",
    "\n",
    "We will perform *grep* commands on the source files, and we will traverse node in Text-Fabric and collect information.\n",
    "\n",
    "Then we compare these sets of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:13.116155Z",
     "start_time": "2018-02-23T12:17:13.087129Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:13.142121Z",
     "start_time": "2018-02-23T12:17:13.118313Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, collections, re\n",
    "from glob import glob\n",
    "from tf.fabric import Fabric\n",
    "from utils import Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:13.159506Z",
     "start_time": "2018-02-23T12:17:13.144872Z"
    }
   },
   "outputs": [],
   "source": [
    "REPO = '~/github/Dans-labs/Nino-cunei'\n",
    "SOURCE = 'uruk'\n",
    "VERSION = '0.1'\n",
    "CORPUS = f'{REPO}/tf/{SOURCE}/{VERSION}'\n",
    "SOURCE_DIR = os.path.expanduser(f'{REPO}/sources/cdli')\n",
    "TEMP_DIR = os.path.expanduser(f'{REPO}/_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:13.180721Z",
     "start_time": "2018-02-23T12:17:13.162093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.2.0\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "31 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=[CORPUS], modules=[''], silent=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:14.051567Z",
     "start_time": "2018-02-23T12:17:13.182582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.00s B catalogId            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B fullNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B number               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.05s B grapheme             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.04s B srcLn                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B srcLnNum             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B prime                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B repeat               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B variant              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B variantOuter         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifier             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierInner        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierFirst        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B damage               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B uncertain            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B remarkable           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B written              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B period               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B name                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B type                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B identifier           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B origNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B badNumbering         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B op                   from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.04s B sub                  from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B comments             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s Feature overview: 26 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  0.85s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    grapheme prime repeat\n",
    "    variant variantOuter\n",
    "    modifier modifierInner modifierFirst\n",
    "    damage uncertain remarkable written\n",
    "    period name type identifier catalogId\n",
    "    number fullNumber origNumber badNumbering\n",
    "    srcLn srcLnNum\n",
    "    op sub comments\n",
    "''')\n",
    "api.makeAvailableIn(globals())\n",
    "COMP = Compare(api, SOURCE_DIR, TEMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablets\n",
    "We check whether we have the same sequence of tablet numbers.\n",
    "In TF, the tablet number is stored in the feature `catalogId`.\n",
    "\n",
    "Note that we also check on the order of the tablets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:14.087407Z",
     "start_time": "2018-02-23T12:17:14.054334Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfTablets():\n",
    "    tablets = []\n",
    "    for t in F.otype.s('tablet'):\n",
    "        (tablet, column, line) = T.sectionFromNode(t)\n",
    "        tablets.append((F.period.v(t), tablet, F.srcLnNum.v(t), F.catalogId.v(t)))\n",
    "    return tablets\n",
    "\n",
    "def grepTablets(gen):\n",
    "    tablets = []\n",
    "    prevTablet = None\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            print(f'GREP: skipping duplicate tablet \"{tablet}\"')\n",
    "            continue\n",
    "        if tablet != prevTablet:\n",
    "            tablets.append((period, tablet, ln, tablet))\n",
    "        prevTablet = tablet\n",
    "    return tablets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:14.366246Z",
     "start_time": "2018-02-23T12:17:14.089958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: skipping duplicate tablet \"P002176\"\n",
      "GREP: skipping duplicate tablet \"P252175\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ tablet\n",
      "IDENTICAL: all 6396 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 1 ◆ P006427\n",
      "=    : uruk-iii ◆ P006428 ◆ 11 ◆ P006428\n",
      "=    : uruk-iii ◆ P448701 ◆ 36 ◆ P448701\n",
      "=    : uruk-iii ◆ P448702 ◆ 50 ◆ P448702\n",
      "=    : uruk-iii ◆ P448703 ◆ 71 ◆ P448703\n",
      "=    : uruk-iii ◆ P471695 ◆ 87 ◆ P471695\n",
      "=    : uruk-iii ◆ P482082 ◆ 114 ◆ P482082\n",
      "=    : uruk-iii ◆ P482083 ◆ 127 ◆ P482083\n",
      "=    : uruk-iii ◆ P499393 ◆ 147 ◆ P499393\n",
      "=    : uruk-iii ◆ P504412 ◆ 166 ◆ P504412\n",
      "=    : uruk-iii ◆ P504413 ◆ 189 ◆ P504413\n",
      "=    : uruk-iii ◆ P006438 ◆ 199 ◆ P006438\n",
      "=    : uruk-iii ◆ P000014 ◆ 220 ◆ P000014\n",
      "=    : uruk-iii ◆ P000456 ◆ 297 ◆ P000456\n",
      "=    : uruk-iii ◆ P002718 ◆ 326 ◆ P002718\n",
      "=    : uruk-iii ◆ P000021 ◆ 341 ◆ P000021\n",
      "=    : uruk-iii ◆ P000023 ◆ 374 ◆ P000023\n",
      "=    : uruk-iii ◆ P000025 ◆ 403 ◆ P000025\n",
      "=    : uruk-iii ◆ P000167 ◆ 500 ◆ P000167\n",
      "=    : uruk-iii ◆ P000453 ◆ 531 ◆ P000453\n",
      "=     and 6376 more\n",
      "Number of results: TF 6396; GREP 6396\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('tablet',),\n",
    "    grepTablets,\n",
    "    tfTablets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faces\n",
    "\n",
    "We check whether we see the same faces with GREP and TF.\n",
    "\n",
    "Note that in TF we have inserted missing faces `@noface`.\n",
    "We leave them out again in the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:14.383370Z",
     "start_time": "2018-02-23T12:17:14.368504Z"
    }
   },
   "outputs": [],
   "source": [
    "FACES = set(\n",
    "    '''\n",
    "    obverse\n",
    "    reverse\n",
    "    top\n",
    "    bottom\n",
    "    left\n",
    "    seal\n",
    "    surface\n",
    "    edge\n",
    "'''.strip().split()\n",
    ")\n",
    "\n",
    "NOFACE = 'noface'\n",
    "\n",
    "facePat = re.compile('^@([a-z]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:14.408152Z",
     "start_time": "2018-02-23T12:17:14.385967Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfFaces():\n",
    "    faces = []\n",
    "    for tablet in F.otype.s('tablet'):\n",
    "        tabletName = F.catalogId.v(tablet)\n",
    "        period = F.period.v(tablet)\n",
    "        for face in L.d(tablet, otype='face'):\n",
    "            tp = F.type.v(face)\n",
    "            it = F.identifier.v(face) or None\n",
    "            ln = F.srcLnNum.v(face)\n",
    "            itStr = '' if it is None else f' {it}'\n",
    "            if tp != 'noface':\n",
    "                faces.append((period, tabletName, ln, f'@{tp}{itStr}'))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:14.427788Z",
     "start_time": "2018-02-23T12:17:14.410512Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepFaces(gen):\n",
    "    faces = []\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        match = facePat.match(line)\n",
    "        if match:\n",
    "            face = match.group(1)\n",
    "            if face in FACES:\n",
    "                faces.append((period, tablet, ln, line.strip()))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:14.803672Z",
     "start_time": "2018-02-23T12:17:14.430001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD : period ◆ tablet ◆ ln ◆ face\n",
      "IDENTICAL: all 9441 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 4 ◆ @obverse\n",
      "=    : uruk-iii ◆ P006428 ◆ 14 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448701 ◆ 39 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448701 ◆ 46 ◆ @reverse\n",
      "=    : uruk-iii ◆ P448702 ◆ 53 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448702 ◆ 67 ◆ @reverse\n",
      "=    : uruk-iii ◆ P448703 ◆ 74 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448703 ◆ 83 ◆ @reverse\n",
      "=    : uruk-iii ◆ P471695 ◆ 90 ◆ @obverse\n",
      "=    : uruk-iii ◆ P471695 ◆ 109 ◆ @reverse\n",
      "=    : uruk-iii ◆ P482082 ◆ 117 ◆ @obverse\n",
      "=    : uruk-iii ◆ P482082 ◆ 123 ◆ @reverse\n",
      "=    : uruk-iii ◆ P482083 ◆ 130 ◆ @obverse\n",
      "=    : uruk-iii ◆ P482083 ◆ 143 ◆ @reverse\n",
      "=    : uruk-iii ◆ P499393 ◆ 150 ◆ @obverse\n",
      "=    : uruk-iii ◆ P499393 ◆ 162 ◆ @reverse\n",
      "=    : uruk-iii ◆ P504412 ◆ 169 ◆ @obverse\n",
      "=    : uruk-iii ◆ P504412 ◆ 185 ◆ @reverse\n",
      "=    : uruk-iii ◆ P504413 ◆ 192 ◆ @obverse\n",
      "=    : uruk-iii ◆ P504413 ◆ 195 ◆ @reverse\n",
      "=     and 9421 more\n",
      "Number of results: TF 9441; GREP 9441\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('face',),\n",
    "    grepFaces,\n",
    "    tfFaces,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns\n",
    "\n",
    "We check whether we see the same columns with GREP and TF.\n",
    "\n",
    "Note that in TF we have inserted missing columns as `@column 0`.\n",
    "We leave them out again in the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:14.831649Z",
     "start_time": "2018-02-23T12:17:14.806443Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfColumns():\n",
    "    columns = []\n",
    "    for tablet in F.otype.s('tablet'):\n",
    "        tabletName = F.catalogId.v(tablet)\n",
    "        period = F.period.v(tablet)\n",
    "        for face in L.d(tablet, otype='face'):\n",
    "            tp = F.type.v(face)\n",
    "            for column in L.d(face, otype='column'):\n",
    "                number = F.number.v(column)\n",
    "                prime = F.prime.v(column)\n",
    "                ln = F.srcLnNum.v(column)\n",
    "                primeStr = \"'\" if prime else ''\n",
    "                if number != '0':\n",
    "                    columns.append((period, tabletName, ln, tp, f'@column {number}{primeStr}'))\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:14.888092Z",
     "start_time": "2018-02-23T12:17:14.834346Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepColumns(gen):\n",
    "    columns = []\n",
    "    columnPat = re.compile('^@col')\n",
    "    correctPat = re.compile('^@([a-z]+)(\\s*)(\\S*)')\n",
    "    curFace = NOFACE\n",
    "    prevTablet = None\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        if tablet != prevTablet:\n",
    "            curFace = NOFACE\n",
    "        prevTablet = tablet\n",
    "\n",
    "        match = facePat.match(line)\n",
    "        if match:\n",
    "            face = match.group(1)\n",
    "            if face in FACES:\n",
    "                curFace = face\n",
    "\n",
    "        if columnPat.match(line):\n",
    "            if not line.startswith('@column '):\n",
    "                match = correctPat.match(line)\n",
    "                if match:\n",
    "                    colSpec = match.group(1)\n",
    "                    sep = match.group(2)\n",
    "                    colNum = match.group(3)\n",
    "                    line = f'@column {colNum}'\n",
    "                    print(f'GREP: corrected \"{colSpec}{sep}{colNum}\" => \"{line}\"')\n",
    "                else:\n",
    "                    print(f'GREP: found \"{line}\"')\n",
    "                \n",
    "            columns.append((period, tablet, ln, curFace, line.strip()))\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:15.447631Z",
     "start_time": "2018-02-23T12:17:14.891232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: corrected \"columm 4\" => \"@column 4\"\n",
      "GREP: corrected \"column3\" => \"@column 3\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ face ◆ column\n",
      "IDENTICAL: all 13123 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 5 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P006427 ◆ 7 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 15 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 18 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 21 ◆ obverse ◆ @column 3\n",
      "=    : uruk-iii ◆ P006428 ◆ 29 ◆ obverse ◆ @column 4\n",
      "=    : uruk-iii ◆ P006428 ◆ 32 ◆ obverse ◆ @column 5\n",
      "=    : uruk-iii ◆ P448701 ◆ 40 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 43 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P448702 ◆ 54 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P448702 ◆ 60 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P448702 ◆ 64 ◆ obverse ◆ @column 3\n",
      "=    : uruk-iii ◆ P448703 ◆ 75 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P448703 ◆ 81 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P471695 ◆ 91 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P471695 ◆ 104 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P482082 ◆ 118 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P482083 ◆ 131 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P482083 ◆ 138 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P499393 ◆ 151 ◆ obverse ◆ @column 1\n",
      "=     and 13103 more\n",
      "Number of results: TF 13123; GREP 13123\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('face', 'column'),\n",
    "    grepColumns,\n",
    "    tfColumns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lines\n",
    "\n",
    "We check whether we see the same line numbers with GREP and TF.\n",
    "\n",
    "During the conversion to TF we have \n",
    "detected bad numberings in some columns\n",
    "and stored that fact in the `badNumbering` feature.\n",
    "\n",
    "One way to look at them is in the raw TF file\n",
    "[badNumbering.tf](https://github.com/Dans-labs/Nino-cunei/blob/master/tf/uruk/0.1/badNumbering.tf).\n",
    "\n",
    "There you see case nodes with values `1` (duplicate numbers) or `2` (wrong order).\n",
    "\n",
    "Here is an overview of the cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:15.465790Z",
     "start_time": "2018-02-23T12:17:15.450728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26 x 2\n",
      "  3 x 1\n"
     ]
    }
   ],
   "source": [
    "for (val, amount) in F.badNumbering.freqList():\n",
    "    print(f'{amount:>3} x {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For full detail, see the\n",
    "[diagnostics](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/diagnostics.tsv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the numbered lines in the transcriptions do not correspond to the TF node type `line`,\n",
    "but to `case`. \n",
    "Because these lines are filled with material of the smallest cases (those that do not have\n",
    "sub-cases).\n",
    "\n",
    "In TF these are the cases that have the feature `fullNumber`.\n",
    "\n",
    "In TF we have removed the dots from numbers, but kept them otherwise unchanged.\n",
    "In order to make the comparison, we also remove the dots after grepping numbers from the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:15.493818Z",
     "start_time": "2018-02-23T12:17:15.468967Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfLines():\n",
    "    cases = []\n",
    "    for tablet in F.otype.s('tablet'):\n",
    "        tabletName = F.catalogId.v(tablet)\n",
    "        period = F.period.v(tablet)\n",
    "        for case in L.d(tablet, otype='case'):\n",
    "            fullNumber = F.fullNumber.v(case)\n",
    "            if fullNumber is None:\n",
    "                continue\n",
    "            ln = F.srcLnNum.v(case)\n",
    "            origNumber = F.origNumber.v(case)\n",
    "            theNumber = fullNumber if origNumber is None else origNumber \n",
    "            cases.append((period, tabletName, ln, f'{theNumber}'))\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:15.517846Z",
     "start_time": "2018-02-23T12:17:15.496466Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepLines(gen):\n",
    "    cases = []\n",
    "    lineNumScan = re.compile('^((?:[a-zA-Z0-9.\\'-]+)|(?=[|\\[]))')\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "\n",
    "        match = lineNumScan.match(line)\n",
    "        if match:\n",
    "            caseNum = match.group(1)\n",
    "            caseNumClean = caseNum.replace('.', '').strip()\n",
    "            cases.append((period, tablet, ln, caseNumClean))\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:15.953337Z",
     "start_time": "2018-02-23T12:17:15.520403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD : period ◆ tablet ◆ ln ◆ lineNum\n",
      "IDENTICAL: all 42170 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ 1\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 16 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 17 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 19 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 20 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 22 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 23 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 24 ◆ 3\n",
      "=    : uruk-iii ◆ P006428 ◆ 25 ◆ 4\n",
      "=    : uruk-iii ◆ P006428 ◆ 26 ◆ 5\n",
      "=    : uruk-iii ◆ P006428 ◆ 27 ◆ 6\n",
      "=    : uruk-iii ◆ P006428 ◆ 28 ◆ 7\n",
      "=    : uruk-iii ◆ P006428 ◆ 30 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 31 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 33 ◆ 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 41 ◆ 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 42 ◆ 2\n",
      "=    : uruk-iii ◆ P448701 ◆ 44 ◆ 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 45 ◆ 2\n",
      "=     and 42150 more\n",
      "Number of results: TF 42170; GREP 42170\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('lineNum',),\n",
    "    grepLines,\n",
    "    tfLines,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have defined a function to produce a string value for a full grapheme, including \n",
    "repeats, primes, variants and modifiers.\n",
    "See [utils](utils.py).\n",
    "\n",
    "A complication is that there are missing line numbers in a few cases, \n",
    "so the usual grep pattern does not pick them up.\n",
    "\n",
    "There a lines that start with `[` and with `|`, so we have to take care we get them.\n",
    "\n",
    "There are also line numbers with a hyphen in it, such as `6-7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:15.969449Z",
     "start_time": "2018-02-23T12:17:15.956325Z"
    }
   },
   "outputs": [],
   "source": [
    "lineNumPat = '^(?:(?:[a-zA-Z0-9.\\'-]+\\s+)|(?=[|\\[]))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primes\n",
    "\n",
    "First an overview of the occurrence of primes.\n",
    "\n",
    "**N.B.:** This gathers primes on *signs*, *column* numbers and *case* numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:15.988837Z",
     "start_time": "2018-02-23T12:17:15.972324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5184 x 1\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.prime.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want so see the node types of primed entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:16.075390Z",
     "start_time": "2018-02-23T12:17:16.048475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4652 x case\n",
      "  523 x column\n",
      "    9 x sign\n"
     ]
    }
   ],
   "source": [
    "primed = collections.Counter()\n",
    "for n in F.prime.s(1):\n",
    "    primed[F.otype.v(n)] += 1\n",
    "for x in sorted(primed.items()):\n",
    "    print(f'{x[1]:>5} x {x[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us check the primes with grep, directly in the source files.\n",
    "We look into lines starting with a (hierarchical number), followed by space,\n",
    "and then later a single of double prime, but not one within a grapheme, such as `GA'AR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:16.373241Z",
     "start_time": "2018-02-23T12:17:16.343359Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfPrimes():\n",
    "    primes = []\n",
    "    for n in F.prime.s(1):\n",
    "        if F.otype.v(n) != 'sign':\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        primes.append((F.period.v(t), tablet, F.srcLnNum.v(case), f\"{COMP.strFromSign(n)}\"))\n",
    "    return primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:16.417556Z",
     "start_time": "2018-02-23T12:17:16.376263Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepPrimes(gen):\n",
    "    primes = []\n",
    "    primePat = re.compile(f'{lineNumPat}(.*[\\'\"][^A].*)')\n",
    "    graphemePat = re.compile('(?:[0-9N]+\\([^)]+[\\'\"]\\))|(?:[A-Z0-9~@a-wyz\\'-]+\\')')\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        match = primePat.match(line)\n",
    "        if match:\n",
    "            material = match.group(1)\n",
    "            if '\"' in material:\n",
    "                print(f'GREP: in \"{material}\": replacing \" by \\'')\n",
    "                material = material.replace('\"', \"'\")\n",
    "            graphemes = graphemePat.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                primes.append((period, tablet, ln, grapheme))\n",
    "    return primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:16.615542Z",
     "start_time": "2018-02-23T12:17:16.420651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: in \"3(N41) 1(N24\")# , [TAR~a] \": replacing \" by '\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "IDENTICAL: all 9 items\n",
      "=    : uruk-iii ◆ P411604 ◆ 48967 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49069 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49071 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49073 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49075 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411539 ◆ 49391 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P006437 ◆ 54446 ◆ 1(N30c')\n",
      "=    : uruk-iii ◆ P464140 ◆ 55938 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P464140 ◆ 55939 ◆ 1(N24')\n",
      "=     no more items\n",
      "Number of results: TF 9; GREP 9\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepPrimes,\n",
    "    tfPrimes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants and modifiers\n",
    "\n",
    "Overview of variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:16.704247Z",
     "start_time": "2018-02-23T12:17:16.672415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23804 x a\n",
      " 4172 x b\n",
      " 1532 x c\n",
      " 1356 x a1\n",
      "  703 x b1\n",
      "  194 x a2\n",
      "  187 x d\n",
      "  127 x b2\n",
      "   85 x f\n",
      "   73 x a3\n",
      "   40 x e\n",
      "   29 x c2\n",
      "   22 x c1\n",
      "   22 x c3\n",
      "   17 x v\n",
      "   14 x c5\n",
      "   13 x b3\n",
      "   12 x a0\n",
      "   12 x d1\n",
      "   11 x c4\n",
      "    6 x a4\n",
      "    6 x g\n",
      "    5 x d2\n",
      "    4 x d4\n",
      "    4 x h\n",
      "    2 x 3a\n",
      "    2 x d3\n",
      "    1 x h2\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.variant.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of modifiers outside a repeat expression, like `1(N57)@t`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:16.992791Z",
     "start_time": "2018-02-23T12:17:16.977465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  648 x g\n",
      "  251 x t\n",
      "   39 x n\n",
      "    6 x r\n",
      "    4 x s\n",
      "    1 x c\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifier.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of modifiers within a repeat expression, like `7(N34@f)#`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:17.273469Z",
     "start_time": "2018-02-23T12:17:17.258767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 x f\n",
      "   15 x t\n",
      "    1 x r\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifierInner.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are many variants and considerably fewer modifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look for variants and modifiers in the TF resource and by GREPping them from the sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:17.842247Z",
     "start_time": "2018-02-23T12:17:17.805073Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfVarMod():\n",
    "    varmods = []\n",
    "    for n in F.otype.s('sign'):\n",
    "        variant = F.variant.v(n)\n",
    "        modifier = F.modifier.v(n)\n",
    "        modifierInner = F.modifierInner.v(n)\n",
    "        if variant is None and modifier is None and modifierInner is None:\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        position = (F.period.v(t), tablet, F.srcLnNum.v(case))\n",
    "        varmods.append((*position, f\"{COMP.strFromSign(n)}\"))\n",
    "\n",
    "        written = F.written.v(n)\n",
    "        if written is not None:\n",
    "            if '~' in written:\n",
    "                varmods.append((*position, written))\n",
    "\n",
    "    return varmods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order\n",
    "Modifiers and variants may come in any order.\n",
    "The conversion has set *modifierFirst* on those items where the modifier precedes the variant.\n",
    "\n",
    "Hence, when we fetch data from TF, we can and do put modifiers and variants in the right order.\n",
    "\n",
    "Examples:\n",
    "\n",
    "```\n",
    "3. 1(N14) 8(N01) , RAD~a@g ERIM~a SZU2 A?\n",
    "```\n",
    "\n",
    "and cases with modifier and then variant:\n",
    "\n",
    "```\n",
    "4. 2(N01) , URUDU@g~b SZU2#\n",
    "```\n",
    "\n",
    "both from the same tablet P003407.\n",
    "\n",
    "#### Uppercase\n",
    "We encounter modifiers or variants in uppercase.\n",
    "The conversion has brought them to lower case.\n",
    "When we fetch data by grep, we perform this lowercasing before making the comparison.\n",
    "\n",
    "#### Stray modifier\n",
    "Somewhere in the source is `SUKUD@inversum`.\n",
    "The conversion translates the `@inversum` to `@v`.\n",
    "We have to mimick that when we do grep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaks\n",
    "During conversion, we found some problems in the sources and tweaked them.\n",
    "When we grep, we must repeat those tweaks, in order to get comparable results.\n",
    "\n",
    "See the [diagnostics](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/diagnostics.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:18.423290Z",
     "start_time": "2018-02-23T12:17:18.367230Z"
    }
   },
   "outputs": [],
   "source": [
    "TWEAK_MATERIAL = (\n",
    "#    ('4\"', \"4'\"),\n",
    "#    ('[,', ''),\n",
    "    ('SA|L', 'SAL|'),\n",
    "    ('~x(', '~v ('),\n",
    "    ('~x', '~v'),\n",
    "    ('U2@~b', 'U2~b'),\n",
    "#    (')|U', ') |U'),\n",
    "    ('1N(02)', '1(N02)'),\n",
    "    ('(1N', '1(N'),\n",
    "#    ('~A', '~a'),\n",
    "    ('{', '('),\n",
    "    ('}', ')'),\n",
    "#    ('sag-apin', 'sag-apin'),\n",
    "#    ('@inversum', '@v'),\n",
    "     (('KI@', -1), 'KI!'),\n",
    ")\n",
    "\n",
    "def tweakBeforeGrep(material):\n",
    "    for (pat, rep) in TWEAK_MATERIAL:\n",
    "        if type(pat) is tuple:\n",
    "            (pat, pos) = pat\n",
    "            if pos == 0:\n",
    "                condition = material.startswith(pat)\n",
    "                mark = ' (at start)'\n",
    "            elif pos == -1:\n",
    "                condition = material.endswith(pat)\n",
    "                mark = ' (at end)'\n",
    "        else:\n",
    "            pos = None\n",
    "            condition = pat in material\n",
    "            mark = ''\n",
    "\n",
    "        if condition:\n",
    "            print(f'GREP: tweak \"{pat}\" => \"{rep}\"')\n",
    "            if pos is None:\n",
    "                material = material.replace(pat, rep)\n",
    "            elif pos == 0:\n",
    "                material = material.replace(pat, rep, 1)\n",
    "            else:\n",
    "                material = material[0:-len(pat)] + rep\n",
    "    return material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:18.456952Z",
     "start_time": "2018-02-23T12:17:18.425485Z"
    }
   },
   "outputs": [],
   "source": [
    "upperPat = re.compile('[~]([A-Z])')\n",
    "\n",
    "def lower(match):\n",
    "    return f'~{match.group(1).lower()}'\n",
    "\n",
    "def graphemeTweaks(grapheme):\n",
    "    if '@inversum' in grapheme:\n",
    "        print(f'GREP: \"@inversum\" => \"@v\"')\n",
    "        grapheme = grapheme.replace('@inversum', '@v')\n",
    "    if '~a~a' in grapheme:\n",
    "        print(f'GREP: \"~a~a\" => \"~a\"')\n",
    "        grapheme = grapheme.replace('~a~a', '~a')\n",
    "    if upperPat.search(grapheme):\n",
    "        print(f'GREP: uppercase variant/modifier in grapheme changed to lowercase')\n",
    "        grapheme = upperPat.sub(lower, grapheme)\n",
    "    if '\"' in grapheme:\n",
    "        print(f'GREP: double prime replaced by single one')\n",
    "        grapheme = grapheme.replace('\"', \"'\")\n",
    "    if '?#' in grapheme:\n",
    "        print(f'GREP: flags order \"?#\" changed into \"#?\"')\n",
    "        grapheme = grapheme.replace('?#', '#?')\n",
    "    return grapheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:18.487465Z",
     "start_time": "2018-02-23T12:17:18.459707Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepVarMod(gen):\n",
    "    varmods = []\n",
    "    varmodPat = re.compile(f'{lineNumPat}(.*[@~].*)')\n",
    "    graphemePat = re.compile(\n",
    "    '''\n",
    "    (?:\n",
    "        [0-9N]+\\([^)]+[@~][^)]+\\)\n",
    "    )|(?:\n",
    "        [0-9N]+\\([^)]+\\)@[a-z]\n",
    "    )|(?:\n",
    "        [A-Z0-9a-wyz\\'-]+[@~][0-9~@a-wyzA-WYZ]+\n",
    "    )\n",
    "    ''', re.X)\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        line = tweakBeforeGrep(line.strip())\n",
    "        match = varmodPat.match(line)\n",
    "        if match:\n",
    "            material = match.group(1)\n",
    "            graphemes = graphemePat.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                grapheme = graphemeTweaks(grapheme)\n",
    "                varmods.append((period, tablet, ln, grapheme))\n",
    "    return varmods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:20.624758Z",
     "start_time": "2018-02-23T12:17:18.490529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"@inversum\" => \"@v\"\n",
      "GREP: tweak \"SA|L\" => \"SAL|\"\n",
      "GREP: tweak \"1N(02)\" => \"1(N02)\"\n",
      "GREP: tweak \"{\" => \"(\"\n",
      "GREP: tweak \"}\" => \")\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: tweak \"KI@\" => \"KI!\"\n",
      "GREP: tweak \"(1N\" => \"1(N\"\n",
      "GREP: tweak \"~x(\" => \"~v (\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: tweak \"U2@~b\" => \"U2~b\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "IDENTICAL: all 32807 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ SANGA~a\n",
      "=    : uruk-iii ◆ P006428 ◆ 26 ◆ DUG~b\n",
      "=    : uruk-iii ◆ P448701 ◆ 42 ◆ AB~a\n",
      "=    : uruk-iii ◆ P448701 ◆ 42 ◆ APIN~a\n",
      "=    : uruk-iii ◆ P448701 ◆ 42 ◆ NUN~a\n",
      "=    : uruk-iii ◆ P448701 ◆ 45 ◆ SZE~a\n",
      "=    : uruk-iii ◆ P448701 ◆ 45 ◆ NUN~a\n",
      "=    : uruk-iii ◆ P448702 ◆ 56 ◆ KA~a\n",
      "=    : uruk-iii ◆ P448702 ◆ 57 ◆ KASZ~b\n",
      "=    : uruk-iii ◆ P448702 ◆ 57 ◆ NUN~a\n",
      "=    : uruk-iii ◆ P448702 ◆ 58 ◆ KASZ~a\n",
      "=    : uruk-iii ◆ P448702 ◆ 59 ◆ 2(N39~a)\n",
      "=    : uruk-iii ◆ P448702 ◆ 63 ◆ SUKUD@v\n",
      "=    : uruk-iii ◆ P471695 ◆ 92 ◆ APIN~a\n",
      "=    : uruk-iii ◆ P471695 ◆ 92 ◆ UR4~a\n",
      "=    : uruk-iii ◆ P471695 ◆ 93 ◆ EN~a\n",
      "=    : uruk-iii ◆ P471695 ◆ 94 ◆ BAN~b\n",
      "=    : uruk-iii ◆ P471695 ◆ 94 ◆ KASZ~c\n",
      "=    : uruk-iii ◆ P471695 ◆ 95 ◆ KI@n\n",
      "=    : uruk-iii ◆ P471695 ◆ 97 ◆ PAP~a\n",
      "=     and 32787 more\n",
      "Number of results: TF 32807; GREP 32807\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepVarMod,\n",
    "    tfVarMod,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flags\n",
    "\n",
    "We have several features for flags: \n",
    "\n",
    "mark | feature | comments\n",
    "----|---\n",
    "`*`|*collation* | not encountered in uruk iii-iv\n",
    "`#`|*damage*\n",
    "`?`|*uncertain*\n",
    "`!`|*remarkable*\n",
    "`!(`ggg`)`|*written*\n",
    "\n",
    "#### A bit of research\n",
    "We start by surveying the possible values, including on which node types they occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:22.031126Z",
     "start_time": "2018-02-23T12:17:20.627480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19945 x sign-damage-1\n",
      "  3727 x sign-uncertain-1\n",
      "  1045 x quad-damage-1\n",
      "   321 x quad-uncertain-1\n",
      "    11 x sign-remarkable-1\n",
      "     2 x sign-written-KASKAL\n",
      "     1 x sign-written-GURUSZ~a\n",
      "     1 x sign-written-IB~a\n"
     ]
    }
   ],
   "source": [
    "flagFeatures = '''\n",
    "    damage\n",
    "    remarkable\n",
    "    written\n",
    "    uncertain\n",
    "'''.strip().split()\n",
    "\n",
    "flagNodeOverview = collections.Counter()\n",
    "flagNodeTypes = set()\n",
    "\n",
    "for n in N():\n",
    "    for ft in flagFeatures:\n",
    "        value = Fs(ft).v(n)\n",
    "        if not value: continue\n",
    "        nType = F.otype.v(n)\n",
    "        flagNodeTypes.add(nType)\n",
    "        flagNodeOverview[f'{nType}-{ft}-{value}'] += 1\n",
    "for (combi, amount) in sorted(flagNodeOverview.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f'{amount:>6} x {combi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see whether there are any cooccurrences of flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:23.553982Z",
     "start_time": "2018-02-23T12:17:22.033775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128414 x     *     -    *     -    *     -    *     \n",
      " 18385 x   damage  -    *     -    *     -    *     \n",
      "  2605 x   damage  -    *     -    *     -uncertain \n",
      "  1442 x     *     -    *     -    *     -uncertain \n",
      "    11 x     *     -remarkable-    *     -    *     \n",
      "     3 x     *     -    *     - written  -    *     \n",
      "     1 x     *     -    *     - written  -uncertain \n"
     ]
    }
   ],
   "source": [
    "flagCombis = collections.Counter()\n",
    "\n",
    "for n in N():\n",
    "    if F.otype.v(n) not in flagNodeTypes:\n",
    "        continue\n",
    "    values = []\n",
    "    for ft in flagFeatures:\n",
    "        rawValue = Fs(ft).v(n)\n",
    "        value = f'{\"*\":^10}' if rawValue is None else f'{ft:^10}' if rawValue else f'{\"\":^10}'\n",
    "        values.append(value)\n",
    "\n",
    "    combi = '-'.join(values)\n",
    "    flagCombis[combi] += 1\n",
    "\n",
    "for (combi, amount) in sorted(flagCombis.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f'{amount:>6} x {combi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to address the question about order of flags.\n",
    "\n",
    "A quick inspection in the corpus yields:\n",
    "\n",
    "* damage-uncertain (`#?`) and uncertain-damage (`?#`), but the latter is very rare and all cases\n",
    "  occur in the diagnostics;\n",
    "* uncertain-remarkable (`?!`) does not occur, and remarkable-written-uncertain (`!(`ggg`)?` does occur.\n",
    "\n",
    "Based on this observation, and assuming that the order between *damage* and *uncertain* is not relevant,\n",
    "we produce flags always in the order:\n",
    "\n",
    "* *damage* *remarkable* *written* *uncertain*\n",
    "\n",
    "When grepping, we have to normalize `?#` to `#?`.\n",
    "\n",
    "There is one weird case, diagnosed by the conversion, in tablet P471687:\n",
    "\n",
    "```\n",
    "C1. |DUGb+?|\n",
    "```\n",
    "\n",
    "Here we see an operator `+` of which the second operand `?` consists of a flag without a grapheme.\n",
    "This occurs only once, so I think it is a mistake.\n",
    "\n",
    "Yet we'll find it when we search with TF, so we exclude it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:23.577300Z",
     "start_time": "2018-02-23T12:17:23.556740Z"
    }
   },
   "outputs": [],
   "source": [
    "flagPat = '''\n",
    "(?:\n",
    "        (?:\n",
    "            !\\([^)]*\\)\n",
    "        )\n",
    "    |\n",
    "        [!#?]\n",
    ")\n",
    "'''\n",
    "\n",
    "flagModVarPat = '''\n",
    "(?:\n",
    "        (?:\n",
    "            !\\([^)]*\\)\n",
    "        )\n",
    "    |\n",
    "        [!#?]\n",
    "    |\n",
    "        (?:\n",
    "            @[A-WYZa-wyz]+\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            ~[A-WYZa-wyz0-9]+\n",
    "        )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:23.617385Z",
     "start_time": "2018-02-23T12:17:23.580202Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfFlags():\n",
    "    flags = []\n",
    "    for n in F.otype.s('sign'):\n",
    "        values = [Fs(ft).v(n) for ft in flagFeatures]\n",
    "        if all(value is None for value in values):\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        sign = f\"{COMP.strFromSign(n, flags=True)}\"\n",
    "        if sign == '?':\n",
    "            print(f'TF: grapheme-less flag skipped in \"{line}\"')\n",
    "            continue\n",
    "        flags.append((F.period.v(t), tablet, F.srcLnNum.v(case), f\"{COMP.strFromSign(n, flags=True)}\"))\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:23.655928Z",
     "start_time": "2018-02-23T12:17:23.619981Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepFlags(gen):\n",
    "    flags = []\n",
    "    flagsPat = re.compile(f'{lineNumPat}(.*[!?#].*)')\n",
    "    graphemePat = re.compile(\n",
    "        f'''\n",
    "            (?:\n",
    "                [0-9N]+\\([^)]+\\)\n",
    "                {flagPat}+\n",
    "            )\n",
    "        |\n",
    "            (?:\n",
    "                [A-Z0-9~@a-wyz\\'-]+\n",
    "                {flagPat}+\n",
    "            )\n",
    "        ''', re.X)\n",
    "\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        line = tweakBeforeGrep(line.strip())\n",
    "\n",
    "        match = flagsPat.match(line)\n",
    "        if match:\n",
    "            material = match.group(1)\n",
    "            graphemes = graphemePat.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                grapheme = graphemeTweaks(grapheme)\n",
    "                flags.append((period, tablet, ln, grapheme))\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:26.016287Z",
     "start_time": "2018-02-23T12:17:23.658271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: grapheme-less flag skipped in \"C\"\n",
      "GREP: \"@inversum\" => \"@v\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: tweak \"SA|L\" => \"SAL|\"\n",
      "GREP: tweak \"1N(02)\" => \"1(N02)\"\n",
      "GREP: tweak \"{\" => \"(\"\n",
      "GREP: tweak \"}\" => \")\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: tweak \"KI@\" => \"KI!\"\n",
      "GREP: tweak \"(1N\" => \"1(N\"\n",
      "GREP: tweak \"~x(\" => \"~v (\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: double prime replaced by single one\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: tweak \"U2@~b\" => \"U2~b\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "IDENTICAL: all 21265 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ SANGA~a?\n",
      "=    : uruk-iii ◆ P448702 ◆ 58 ◆ KASZ~a?\n",
      "=    : uruk-iii ◆ P448702 ◆ 59 ◆ 6(N14)#?\n",
      "=    : uruk-iii ◆ P448702 ◆ 63 ◆ SUKUD@v?\n",
      "=    : uruk-iii ◆ P471695 ◆ 105 ◆ ISZ~a#?\n",
      "=    : uruk-iii ◆ P471695 ◆ 111 ◆ 6(N01)#\n",
      "=    : uruk-iii ◆ P482082 ◆ 120 ◆ 4(N14)#\n",
      "=    : uruk-iii ◆ P482082 ◆ 121 ◆ 2(N14)#\n",
      "=    : uruk-iii ◆ P482083 ◆ 133 ◆ 1(N14)#\n",
      "=    : uruk-iii ◆ P482083 ◆ 135 ◆ KASZ~b?\n",
      "=    : uruk-iii ◆ P504412 ◆ 176 ◆ MASZ2?\n",
      "=    : uruk-iii ◆ P504412 ◆ 177 ◆ X?\n",
      "=    : uruk-iii ◆ P504412 ◆ 179 ◆ X?\n",
      "=    : uruk-iii ◆ P504412 ◆ 182 ◆ GI4~a#\n",
      "=    : uruk-iii ◆ P504412 ◆ 183 ◆ SAL?\n",
      "=    : uruk-iii ◆ P006438 ◆ 213 ◆ RAD~a#\n",
      "=    : uruk-iii ◆ P006438 ◆ 217 ◆ LAL2~a#?\n",
      "=    : uruk-iii ◆ P006438 ◆ 217 ◆ NIM~b2#?\n",
      "=    : uruk-iii ◆ P000014 ◆ 229 ◆ SZUBUR#\n",
      "=    : uruk-iii ◆ P000014 ◆ 230 ◆ KAB#?\n",
      "=     and 21245 more\n",
      "Number of results: TF 21265; GREP 21265\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepFlags,\n",
    "    tfFlags,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All signs\n",
    "\n",
    "Now it is time to do a rigorous comparison of all signs in the transcriptions and in TF.\n",
    "\n",
    "Up till now we included only signs that had primes, variants, modifiers or flags attached to them.\n",
    "Now we extend the comparison to all of them.\n",
    "\n",
    "We still ignore the quad structures with operators and the bracketing of quads (clusters).\n",
    "But we do draw their component signs into the comparison.\n",
    "\n",
    "This comparison lists all signs in textual order, in TF and in GREP, and compares the two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:26.050707Z",
     "start_time": "2018-02-23T12:17:26.019035Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfSigns():\n",
    "    signs = []\n",
    "    for n in F.otype.s('sign'):\n",
    "        if F.grapheme.v(n) == '':\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        sign = f\"{COMP.strFromSign(n, flags=True)}\"\n",
    "        if sign == '?':\n",
    "            print(f'TF: grapheme-less flag skipped in \"{line}\"')\n",
    "            continue\n",
    "        signs.append((F.period.v(t), tablet, F.srcLnNum.v(case), sign))\n",
    "    return signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The regular expression that greps all graphemes from the transcription is quite daunting.\n",
    "Comapare this with the relative easy by which you get all this from the text-fabric representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:26.074847Z",
     "start_time": "2018-02-23T12:17:26.054202Z"
    }
   },
   "outputs": [],
   "source": [
    "smallPat = '[A-Zn]'\n",
    "\n",
    "graphemePat = re.compile(\n",
    "    f'''\n",
    "        (?:\n",
    "            \\.\\.\\.                        # three dots, mostly in [...]\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            [0-9N]+\\([^)]+\\)               # a repeat, e.g. 5(N024)\n",
    "            {flagModVarPat}*\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            [A-Z0-9a-wyzû\\'-]{{2,}}       # a plain grapheme, e.g. GA'AR\n",
    "            {flagModVarPat}*\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            {smallPat}                    # a single letter grapheme: X or n, mostly in [n]\n",
    "            {flagModVarPat}*\n",
    "        )\n",
    "    ''', re.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:26.113128Z",
     "start_time": "2018-02-23T12:17:26.077118Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepSigns(gen):\n",
    "    signs = []\n",
    "    signsPat = re.compile(f'{lineNumPat}(.*)')\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        if line.startswith('1.1('):\n",
    "            print(f'GREP: inserted space between number and material: \"1.1(\"')\n",
    "            line = line.replace('1.1(', '1.1 (', 1)\n",
    "        match = signsPat.match(line)\n",
    "        if match:\n",
    "            material = match.group(1).strip()\n",
    "            material = tweakBeforeGrep(material)\n",
    "            graphemes = graphemePat.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                grapheme = graphemeTweaks(grapheme)\n",
    "                signs.append((period, tablet, ln, grapheme))\n",
    "    return signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next one will take 5-10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.460483Z",
     "start_time": "2018-02-23T12:17:26.115811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"@inversum\" => \"@v\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: tweak \"SA|L\" => \"SAL|\"\n",
      "GREP: tweak \"1N(02)\" => \"1(N02)\"\n",
      "GREP: tweak \"{\" => \"(\"\n",
      "GREP: tweak \"}\" => \")\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: tweak \"KI@\" => \"KI!\"\n",
      "GREP: tweak \"(1N\" => \"1(N\"\n",
      "GREP: tweak \"~x(\" => \"~v (\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: inserted space between number and material: \"1.1(\"\n",
      "GREP: double prime replaced by single one\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: tweak \"U2@~b\" => \"U2~b\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "IDENTICAL: all 129827 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ ...\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ X\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ X\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ 3(N14)\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ X\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ SANGA~a?\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ ...\n",
      "=    : uruk-iii ◆ P006428 ◆ 16 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 16 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 17 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 17 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 19 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 19 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 20 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 20 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 22 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 22 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 23 ◆ 3(N14)\n",
      "=    : uruk-iii ◆ P006428 ◆ 23 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 24 ◆ 1(N14)\n",
      "=     and 129807 more\n",
      "Number of results: TF 129827; GREP 129827\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepSigns,\n",
    "    tfSigns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quads\n",
    "\n",
    "Quads are the compositions of signs by operators. Operators can be applied several times,\n",
    "so quads themselves can be the building blocks for other quads.\n",
    "\n",
    "In transcription, the outermost quads are what you get if you split the transcription\n",
    "line (the part after the line number) of white space.\n",
    "\n",
    "Normally, if an outer quad is complex, it is written between `| |`.\n",
    "\n",
    "Quads and sub-quads may be augmented with variants, modifiers and flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer complex quads\n",
    "\n",
    "Let us first check whether we see the same outer quads by TF as by GREP.\n",
    "We are not interested in the simple quads.\n",
    "They are the signs, and we have already checked them.\n",
    "So we look for all outer complex quads, i.e. quads with an operator in them,\n",
    "such as `x` or `+` or `.`\n",
    "\n",
    "In the transcriptions, complex outer quads should be surrounded by `| |`.\n",
    "However, in this corpus there are a few cases where one or both of the surrounding\n",
    "`|` are missing.\n",
    "\n",
    "We make an explicit list of these cases, and will correct the GREP results for these.\n",
    "\n",
    "In TF, outer quads are characterized by not having an incoming `sub` edge.\n",
    "Remember that edges connect the complex quads with their component quads.\n",
    "\n",
    "In TF we recognize a complex quad as one having an outgoing `sub` edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants: inside or outside?\n",
    "\n",
    "It seems that in the transcriptions there are two ways to augment an outer quad with a variant:\n",
    "\n",
    "`|(QQxRR)~a|` versus `|QQxRR|~a`\n",
    "\n",
    "Both occur\n",
    "\n",
    "In P000783 we have\n",
    "```\n",
    "6. 2(N14) , |(SZAxHI@g~a)~b|\n",
    "```\n",
    "\n",
    "whereas in P252180 we have\n",
    "\n",
    "```\n",
    "4. UB URI3~a |BAD+DISZ|~a EN~a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants: extra level of brackets?\n",
    "\n",
    "What binds stronger: an operator, or a variant?\n",
    "Consider the following line of P006326:\n",
    "\n",
    "```\n",
    "1.b2. 2(N14)# 3(N01)# , |GA2~a1x(SUKUD&SUKUD)~b|#\n",
    "```\n",
    "\n",
    "If variants bind stronger than operators, we must read the big quad as\n",
    "\n",
    "```\n",
    "|GA2~a1x((SUKUD&SUKUD)~b)|#\n",
    "```\n",
    "\n",
    "If operators bind stronger, we need to read it as\n",
    "\n",
    "```\n",
    "|(GA2~a1x(SUKUD&SUKUD))~b|#\n",
    "```\n",
    "\n",
    "A variant is unary operator, whereas an operator is a binary operator,\n",
    "so it makes much more sense to opt for the first interpretation.\n",
    "\n",
    "However, in the corpus we see cases where there are unnecessary brackets\n",
    "for variants. See the following line in P002269:\n",
    "\n",
    "```\n",
    "1.a. 1(N01) , |NINDA2x((UDU~a+TAR)~b)| KU6~a\n",
    "```\n",
    "\n",
    "Here the brackets around `UDU~a+TAR)~b` are unneccesary. \n",
    "If variants bind stronger, then this should have the same meaning:\n",
    "\n",
    "```\n",
    "1.a. 1(N01) , |NINDA2x(UDU~a+TAR)~b| KU6~a\n",
    "```\n",
    "\n",
    "Since both bracketings occur, and since TF stores the abstract structure, and not\n",
    "the surface bracketing, there is no way for TF to remember the bracketing.\n",
    "\n",
    "We could add a feature to remember this, but as the meaning is not changed by extra\n",
    "brackets, it is silly to do so.\n",
    "\n",
    "Hence, after GREPPING, we will remove these kinds of brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More bracket issues\n",
    "\n",
    "In P005112 we find a line\n",
    "\n",
    "```\n",
    "1. [...] , |U4x2(N01).(2(N14).1(N08))| EN~a PA~a\n",
    "```\n",
    "\n",
    "The quad seems the composition of three subquads:\n",
    "`U4` and `2(N01)` and `2(N14).1(N08)`.\n",
    "\n",
    "But whereas it has been made explicit in which order the `.` operator should be applied,\n",
    "we do not know that for `x` versus `.`\n",
    "\n",
    "There are three possible meanings of `GxH.J`\n",
    "\n",
    "1. `Gx(H.J)`\n",
    "2. `(GxH).J`\n",
    "3. the order is immaterial, the previous meanings are equal\n",
    "\n",
    "Given the fact that there are no brackets, I opt for the third possibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most complex quads\n",
    "\n",
    "Here are a few really intricate quads:\n",
    "\n",
    "In P005573, column 2, line 2b2\n",
    "\n",
    "P005381 2 1\n",
    "\n",
    "Let's retrieve them using with a bit of Text-Fabric agility:\n",
    "\n",
    "```\n",
    "2.b2. , (|(HIx1(N57))&(HI+1(N57))| EN~a)a \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.486772Z",
     "start_time": "2018-02-23T12:17:32.464151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.b2. , (|(HIx1(N57))&(HI+1(N57))| EN~a)a \n",
      "1. 3(N04) , |GISZ.TE| GAR |SZU2.((HI+1(N57))+(HI+1(N57)))| GI4~a\n"
     ]
    }
   ],
   "source": [
    "for passage in (\n",
    "    ('P005573', 'obverse:2', '2', '2b2'),\n",
    "    ('P005381', 'obverse:2', '1'),\n",
    "):\n",
    "    line = T.nodeFromSection(passage[0:3])\n",
    "    cases = L.d(line, otype='case')\n",
    "    caseNr = passage[3] if len(passage) >= 4 else None\n",
    "    for case in cases:\n",
    "        if not caseNr or F.fullNumber.v(case) == caseNr:\n",
    "            print(F.srcLn.v(case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.512098Z",
     "start_time": "2018-02-23T12:17:32.492983Z"
    }
   },
   "outputs": [],
   "source": [
    "quadVarPat = re.compile('''\n",
    "    \\|\n",
    "        ([^|]+)\n",
    "    \\|\n",
    "    ~\n",
    "        ([a-wyz0-9A-WYZ]+)\n",
    "''', re.X)\n",
    "\n",
    "def quadVarReplace(match):\n",
    "    quad = match.group(1)\n",
    "    var = match.group(2)\n",
    "    print(f'GREP: pulling variant inside quad: \"|{quad}|~{var}\" => |({quad})~{var}|')\n",
    "    return f'|({quad})~{var}|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.540204Z",
     "start_time": "2018-02-23T12:17:32.514455Z"
    }
   },
   "outputs": [],
   "source": [
    "quadBracketPat = re.compile('''\n",
    "    \\(\n",
    "        \\(\n",
    "            ([^() ]+)\n",
    "        \\)\n",
    "        ~\n",
    "        ([a-wyz0-9A-WYZ]+)\n",
    "    \\)\n",
    "''', re.X)\n",
    "\n",
    "def quadBracketReplace(match):\n",
    "    quad = match.group(1)\n",
    "    var = match.group(2)\n",
    "    print(f'GREP: removing brackets around a variant: \"(({quad})~{var})\" => ({quad})~{var}')\n",
    "    return f'({quad})~{var}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.572014Z",
     "start_time": "2018-02-23T12:17:32.542850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272832 = 1. 1(N01) , |(BU~a&BU~a).NA2~a|\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "234105"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = T.nodeFromSection(('P004747', 'obverse:2', '1'))\n",
    "case = L.d(line, otype='case')[0]\n",
    "print(f'{case} = {F.srcLn.v(case)}')\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.596907Z",
     "start_time": "2018-02-23T12:17:32.574853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234105 line\n",
      " 18863 sign\n",
      "147452 quad\n",
      "147453 quad\n",
      " 18864 sign\n",
      " 18865 sign\n",
      " 18866 sign\n",
      "Using quad 147452\n"
     ]
    }
   ],
   "source": [
    "q = None\n",
    "for qs in L.d(case):\n",
    "    nodeType = F.otype.v(qs)\n",
    "    print(f'{qs:>6} {nodeType}')\n",
    "    if nodeType == 'quad' and q is None:\n",
    "        q = qs\n",
    "print(f'Using quad {q}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.618981Z",
     "start_time": "2018-02-23T12:17:32.599823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|(BU~a&BU~a).NA2~a|'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.strFromQuad(q, flags=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.650099Z",
     "start_time": "2018-02-23T12:17:32.623157Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfQuads():\n",
    "    quads = []\n",
    "    for n in F.otype.s('quad'):\n",
    "        if E.sub.t(n) or not E.sub.f(n):\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        quad = f\"{COMP.strFromQuad(n, flags=True)}\"\n",
    "        quads.append((F.period.v(t), tablet, F.srcLnNum.v(case), quad))\n",
    "    return quads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.670375Z",
     "start_time": "2018-02-23T12:17:32.655097Z"
    }
   },
   "outputs": [],
   "source": [
    "operatorPat = '[x%&.:+]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.695132Z",
     "start_time": "2018-02-23T12:17:32.673322Z"
    }
   },
   "outputs": [],
   "source": [
    "MISSING_PIPES = {\n",
    "       ('uruk-iii', 16730): '|SZE~a+NAM2|',\n",
    "       ('uruk-iii', 16896): '|EN~a+NUN~a| UTUL~a',\n",
    "       ('uruk-iii', 16962): 'GAL~a |EZEN~b+6N57|',\n",
    "       ('uruk-iii', 25956): '|GISZ+SZU2~a| |SZE~a+SZE~a|',\n",
    "       ('uruk-iii', 26281): '|GISZ.tenû| E2~b',\n",
    "       ('uruk-iii', 31523): '|MUD3.gunû|',\n",
    "       ('uruk-iii', 40186): '|SZUBUR+1(N57)|',\n",
    "       ('uruk-iii', 40188): '|SZUBUR+2(N57)|',\n",
    "       ('uruk-iii', 45102): '|ZATU737xDI| SANGA~a',\n",
    "       ('uruk-iii', 45533): '|SZE~a+NAM2| A',\n",
    "       ('uruk-iii', 52806): '1(N01) , UDUNITA~a |IDIN+1(N57)|',\n",
    "       ('uruk-iii', 55110): '|U4+1(N08)| |GI+A#|',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:32.752607Z",
     "start_time": "2018-02-23T12:17:32.699140Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepQuads(gen):\n",
    "    quads = []\n",
    "    quadsPat = re.compile(f'{lineNumPat}(.*\\S{operatorPat}\\S.*)')\n",
    "    quadPat = re.compile(f'\\|\\S+{operatorPat}\\S+\\|{flagModVarPat}*', re.X)\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        if line.startswith('1.1('):\n",
    "            print(f'GREP: inserted space between number and material: \"1.1(\"')\n",
    "            line = line.replace('1.1(', '1.1 (', 1)\n",
    "        material = MISSING_PIPES.get((period, ln), None)\n",
    "        if material == None:\n",
    "            match = quadsPat.match(line)\n",
    "            if match:\n",
    "                material = match.group(1).strip()\n",
    "                material = tweakBeforeGrep(material)\n",
    "        if material is not None:\n",
    "            for quad in quadPat.findall(material):\n",
    "                quad = graphemeTweaks(quad)\n",
    "                quad = quadVarPat.sub(quadVarReplace, quad)\n",
    "                quad = quadBracketPat.sub(quadBracketReplace, quad)\n",
    "                quads.append((period, tablet, ln, quad))\n",
    "    return quads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-23T12:17:33.353235Z",
     "start_time": "2018-02-23T12:17:32.755233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: tweak \"SA|L\" => \"SAL|\"\n",
      "GREP: tweak \"{\" => \"(\"\n",
      "GREP: tweak \"}\" => \")\"\n",
      "GREP: tweak \"~x(\" => \"~v (\"\n",
      "GREP: inserted space between number and material: \"1.1(\"\n",
      "GREP: removing brackets around a variant: \"((UDU~a+TAR)~b)\" => (UDU~a+TAR)~b\n",
      "GREP: removing brackets around a variant: \"((UDU~axTAR)~a)\" => (UDU~axTAR)~a\n",
      "GREP: pulling variant inside quad: \"|BAD+DISZ|~a\" => |(BAD+DISZ)~a|\n",
      "HEAD : period ◆ tablet ◆ ln ◆ quad\n",
      "IDENTICAL: all 3733 items\n",
      "=    : uruk-iii ◆ P006428 ◆ 26 ◆ |DUG~bx1(N57)|\n",
      "=    : uruk-iii ◆ P448702 ◆ 63 ◆ |U4x1(N01)|\n",
      "=    : uruk-iii ◆ P448703 ◆ 76 ◆ |U4.1(N08)|\n",
      "=    : uruk-iii ◆ P448703 ◆ 77 ◆ |U4.1(N08)|\n",
      "=    : uruk-iii ◆ P448703 ◆ 78 ◆ |U4.1(N08)|#\n",
      "=    : uruk-iii ◆ P448703 ◆ 78 ◆ |GI&GI|#\n",
      "=    : uruk-iii ◆ P448703 ◆ 79 ◆ |U4.1(N08)|#\n",
      "=    : uruk-iii ◆ P448703 ◆ 80 ◆ |U4.1(N08)|\n",
      "=    : uruk-iii ◆ P482083 ◆ 135 ◆ |U4x3(N01)|\n",
      "=    : uruk-iii ◆ P499393 ◆ 153 ◆ |LAGAB~bxX|\n",
      "=    : uruk-iii ◆ P499393 ◆ 155 ◆ |MUSZEN.X|\n",
      "=    : uruk-iii ◆ P504412 ◆ 177 ◆ |SILA3~dxNI~a|\n",
      "=    : uruk-iii ◆ P006438 ◆ 205 ◆ |AB~axSUKKAL|\n",
      "=    : uruk-iii ◆ P000014 ◆ 226 ◆ |1(N57).SZUBUR|\n",
      "=    : uruk-iii ◆ P000014 ◆ 228 ◆ |2(N57).SZUBUR|\n",
      "=    : uruk-iii ◆ P000014 ◆ 231 ◆ |SILA3~axGARA2~a|#?\n",
      "=    : uruk-iii ◆ P000014 ◆ 267 ◆ |BU~a+DU6~a|\n",
      "=    : uruk-iii ◆ P000014 ◆ 288 ◆ |3(N57).SZUBUR|\n",
      "=    : uruk-iii ◆ P000456 ◆ 307 ◆ |1(N57).SZUBUR|\n",
      "=    : uruk-iii ◆ P002718 ◆ 333 ◆ |SZE~a&SZE~a|#?\n",
      "=     and 3713 more\n",
      "Number of results: TF 3733; GREP 3733\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('quad',),\n",
    "    grepQuads,\n",
    "    tfQuads,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
