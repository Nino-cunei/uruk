{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Tablets\" data-toc-modified-id=\"Tablets-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Tablets</a></span></li><li><span><a href=\"#Faces\" data-toc-modified-id=\"Faces-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Faces</a></span></li><li><span><a href=\"#Columns\" data-toc-modified-id=\"Columns-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Columns</a></span></li><li><span><a href=\"#Lines\" data-toc-modified-id=\"Lines-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Lines</a></span><ul class=\"toc-item\"><li><span><a href=\"#Line-numbers\" data-toc-modified-id=\"Line-numbers-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Line numbers</a></span></li><li><span><a href=\"#Cross-references\" data-toc-modified-id=\"Cross-references-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Cross references</a></span></li></ul></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Comments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Object-descriptions\" data-toc-modified-id=\"Object-descriptions-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Object descriptions</a></span></li><li><span><a href=\"#Rulings\" data-toc-modified-id=\"Rulings-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Rulings</a></span></li><li><span><a href=\"#Metadata\" data-toc-modified-id=\"Metadata-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Metadata</a></span></li></ul></li><li><span><a href=\"#Graphemes\" data-toc-modified-id=\"Graphemes-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Graphemes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Primes\" data-toc-modified-id=\"Primes-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Primes</a></span></li><li><span><a href=\"#Variants-and-modifiers\" data-toc-modified-id=\"Variants-and-modifiers-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Variants and modifiers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Order\" data-toc-modified-id=\"Order-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;</span>Order</a></span></li><li><span><a href=\"#Uppercase\" data-toc-modified-id=\"Uppercase-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;</span>Uppercase</a></span></li><li><span><a href=\"#Stray-modifier\" data-toc-modified-id=\"Stray-modifier-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;</span>Stray modifier</a></span></li></ul></li><li><span><a href=\"#Tweaks\" data-toc-modified-id=\"Tweaks-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Tweaks</a></span></li><li><span><a href=\"#Flags\" data-toc-modified-id=\"Flags-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Flags</a></span><ul class=\"toc-item\"><li><span><a href=\"#A-bit-of-research\" data-toc-modified-id=\"A-bit-of-research-6.4.1\"><span class=\"toc-item-num\">6.4.1&nbsp;&nbsp;</span>A bit of research</a></span></li></ul></li><li><span><a href=\"#All-signs\" data-toc-modified-id=\"All-signs-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>All signs</a></span></li></ul></li><li><span><a href=\"#Quads\" data-toc-modified-id=\"Quads-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Quads</a></span><ul class=\"toc-item\"><li><span><a href=\"#Outer-complex-quads\" data-toc-modified-id=\"Outer-complex-quads-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Outer complex quads</a></span></li><li><span><a href=\"#Variants:-inside-or-outside?\" data-toc-modified-id=\"Variants:-inside-or-outside?-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Variants: inside or outside?</a></span></li><li><span><a href=\"#Variants:-extra-level-of-brackets?\" data-toc-modified-id=\"Variants:-extra-level-of-brackets?-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Variants: extra level of brackets?</a></span></li><li><span><a href=\"#More-bracket-issues\" data-toc-modified-id=\"More-bracket-issues-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>More bracket issues</a></span></li><li><span><a href=\"#The-most-complex-quads\" data-toc-modified-id=\"The-most-complex-quads-7.5\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>The most complex quads</a></span></li></ul></li><li><span><a href=\"#Clusters\" data-toc-modified-id=\"Clusters-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Clusters</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks\n",
    "Various checks on the correctness of the transformation from ascii transcriptions to a text-fabric data set.\n",
    "\n",
    "The\n",
    "[diagnostics](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/diagnostics.tsv)\n",
    "of the transformation contains valueable issues that may be used to correct mistakes in the sources.\n",
    "Or, equally likely, they correspond to misunderstandings on my (Dirk's) part of the model\n",
    "that underlies the transcriptions.\n",
    "\n",
    "We will perform *grep* commands on the source files, and we will traverse node in Text-Fabric and collect information.\n",
    "\n",
    "Then we compare these sets of information.\n",
    "\n",
    "# Docs\n",
    "\n",
    "[Feature docs](https://github.com/Dans-labs/Nino-cunei/blob/master/docs/transcription.md)\n",
    "\n",
    "[Cunei API](https://github.com/Dans-labs/Nino-cunei/blob/master/docs/cunei.md)\n",
    "\n",
    "[Utils API](https://github.com/Dans-labs/Nino-cunei/blob/master/docs/utils.md)\n",
    "\n",
    "[Text-Fabric API](https://github.com/Dans-labs/text-fabric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:13.441806Z",
     "start_time": "2018-03-01T13:06:13.418541Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:14.394898Z",
     "start_time": "2018-03-01T13:06:14.371646Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, collections, re\n",
    "from glob import glob\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:15.223563Z",
     "start_time": "2018-03-01T13:06:15.199751Z"
    }
   },
   "outputs": [],
   "source": [
    "REPO = '~/github/Dans-labs/Nino-cunei'\n",
    "SOURCE = 'uruk'\n",
    "VERSION = '0.1'\n",
    "CORPUS = f'{REPO}/tf/{SOURCE}/{VERSION}'\n",
    "SOURCE_DIR = os.path.expanduser(f'{REPO}/sources/cdli')\n",
    "PROGRAM_DIR = os.path.expanduser(f'{REPO}/programs')\n",
    "REPORT_DIR = os.path.expanduser(f'{REPO}/reports')\n",
    "TEMP_DIR = os.path.expanduser(f'{REPO}/_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:16.048325Z",
     "start_time": "2018-03-01T13:06:16.025200Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(PROGRAM_DIR)\n",
    "from cunei import Cunei\n",
    "from utils import Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:16.790345Z",
     "start_time": "2018-03-01T13:06:16.772994Z"
    }
   },
   "outputs": [],
   "source": [
    "for cdir in (TEMP_DIR, REPORT_DIR):\n",
    "    os.makedirs(cdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:21.020252Z",
     "start_time": "2018-03-01T13:06:20.996258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.2.2\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "32 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=[CORPUS], modules=[''], silent=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:23.874003Z",
     "start_time": "2018-03-01T13:06:22.785769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.00s B catalogId            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B fullNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B number               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.06s B grapheme             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.05s B srcLn                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B srcLnNum             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B prime                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B repeat               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B variant              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B variantOuter         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifier             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierInner        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierFirst        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B damage               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B uncertain            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B remarkable           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B written              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B period               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B name                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.03s B type                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B identifier           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B origNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B badNumbering         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B crossref             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B text                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B op                   from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.10s B sub                  from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B comments             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s Feature overview: 27 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  1.07s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    grapheme prime repeat\n",
    "    variant variantOuter\n",
    "    modifier modifierInner modifierFirst\n",
    "    damage uncertain remarkable written\n",
    "    period name type identifier catalogId\n",
    "    number fullNumber origNumber badNumbering\n",
    "    crossref text\n",
    "    srcLn srcLnNum\n",
    "    op sub comments\n",
    "''')\n",
    "api.makeAvailableIn(globals())\n",
    "CUNEI = Cunei(api)\n",
    "COMP = Compare(api, SOURCE_DIR, TEMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablets\n",
    "We check whether we have the same sequence of tablet numbers.\n",
    "In TF, the tablet number is stored in the feature `catalogId`.\n",
    "\n",
    "Note that we also check on the order of the tablets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:27.105068Z",
     "start_time": "2018-03-01T13:06:27.066660Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfTablets():\n",
    "    tablets = []\n",
    "    for t in F.otype.s('tablet'):\n",
    "        (tablet, column, line) = T.sectionFromNode(t)\n",
    "        tablets.append((F.period.v(t), tablet, F.srcLnNum.v(t), F.catalogId.v(t)))\n",
    "    return tablets\n",
    "\n",
    "def grepTablets(gen):\n",
    "    tablets = []\n",
    "    prevTablet = None\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            print(f'GREP: skipping duplicate tablet \"{tablet}\"')\n",
    "            continue\n",
    "        if tablet != prevTablet:\n",
    "            tablets.append((period, tablet, ln, tablet))\n",
    "        prevTablet = tablet\n",
    "    return tablets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:28.455309Z",
     "start_time": "2018-03-01T13:06:28.128747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: skipping duplicate tablet \"P002176\"\n",
      "GREP: skipping duplicate tablet \"P464118\"\n",
      "GREP: skipping duplicate tablet \"P471689\"\n",
      "GREP: skipping duplicate tablet \"P471682\"\n",
      "GREP: skipping duplicate tablet \"P471685\"\n",
      "GREP: skipping duplicate tablet \"P471683\"\n",
      "GREP: skipping duplicate tablet \"P471691\"\n",
      "GREP: skipping duplicate tablet \"P471694\"\n",
      "GREP: skipping duplicate tablet \"P471693\"\n",
      "GREP: skipping duplicate tablet \"P471688\"\n",
      "GREP: skipping duplicate tablet \"P471687\"\n",
      "GREP: skipping duplicate tablet \"P471692\"\n",
      "GREP: skipping duplicate tablet \"P471684\"\n",
      "GREP: skipping duplicate tablet \"P491489\"\n",
      "GREP: skipping duplicate tablet \"P471686\"\n",
      "GREP: skipping duplicate tablet \"P471690\"\n",
      "GREP: skipping duplicate tablet \"P455567\"\n",
      "GREP: skipping duplicate tablet \"P456183\"\n",
      "GREP: skipping duplicate tablet \"P455718\"\n",
      "GREP: skipping duplicate tablet \"P455726\"\n",
      "GREP: skipping duplicate tablet \"P456095\"\n",
      "GREP: skipping duplicate tablet \"P456780\"\n",
      "GREP: skipping duplicate tablet \"P456795\"\n",
      "GREP: skipping duplicate tablet \"P456817\"\n",
      "GREP: skipping duplicate tablet \"P457754\"\n",
      "GREP: skipping duplicate tablet \"P457755\"\n",
      "GREP: skipping duplicate tablet \"P458281\"\n",
      "GREP: skipping duplicate tablet \"P458349\"\n",
      "GREP: skipping duplicate tablet \"P458394\"\n",
      "GREP: skipping duplicate tablet \"P458395\"\n",
      "GREP: skipping duplicate tablet \"P458434\"\n",
      "GREP: skipping duplicate tablet \"P458717\"\n",
      "GREP: skipping duplicate tablet \"P458792\"\n",
      "GREP: skipping duplicate tablet \"P458869\"\n",
      "GREP: skipping duplicate tablet \"P252175\"\n",
      "GREP: skipping duplicate tablet \"P431151\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ tablet\n",
      "IDENTICAL: all 6362 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 1 ◆ P006427\n",
      "=    : uruk-iii ◆ P006428 ◆ 11 ◆ P006428\n",
      "=    : uruk-iii ◆ P448701 ◆ 36 ◆ P448701\n",
      "=    : uruk-iii ◆ P448702 ◆ 50 ◆ P448702\n",
      "=    : uruk-iii ◆ P448703 ◆ 71 ◆ P448703\n",
      "=    : uruk-iii ◆ P471695 ◆ 87 ◆ P471695\n",
      "=    : uruk-iii ◆ P482082 ◆ 114 ◆ P482082\n",
      "=    : uruk-iii ◆ P482083 ◆ 127 ◆ P482083\n",
      "=    : uruk-iii ◆ P499393 ◆ 147 ◆ P499393\n",
      "=    : uruk-iii ◆ P504412 ◆ 166 ◆ P504412\n",
      "=    : uruk-iii ◆ P504413 ◆ 189 ◆ P504413\n",
      "=    : uruk-iii ◆ P006438 ◆ 199 ◆ P006438\n",
      "=    : uruk-iii ◆ P000014 ◆ 220 ◆ P000014\n",
      "=    : uruk-iii ◆ P000456 ◆ 297 ◆ P000456\n",
      "=    : uruk-iii ◆ P002718 ◆ 326 ◆ P002718\n",
      "=    : uruk-iii ◆ P000021 ◆ 341 ◆ P000021\n",
      "=    : uruk-iii ◆ P000023 ◆ 374 ◆ P000023\n",
      "=    : uruk-iii ◆ P000025 ◆ 403 ◆ P000025\n",
      "=    : uruk-iii ◆ P000167 ◆ 500 ◆ P000167\n",
      "=    : uruk-iii ◆ P000453 ◆ 531 ◆ P000453\n",
      "=     and 6342 more\n",
      "Number of results: TF 6362; GREP 6362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('tablet',),\n",
    "    grepTablets,\n",
    "    tfTablets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faces\n",
    "\n",
    "We check whether we see the same faces with GREP and TF.\n",
    "\n",
    "Note that in TF we have inserted missing faces `@noface`.\n",
    "We leave them out again in the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:33.372827Z",
     "start_time": "2018-03-01T13:06:33.354190Z"
    }
   },
   "outputs": [],
   "source": [
    "FACES = set(\n",
    "    '''\n",
    "    obverse\n",
    "    reverse\n",
    "    top\n",
    "    bottom\n",
    "    left\n",
    "    seal\n",
    "    surface\n",
    "    edge\n",
    "'''.strip().split()\n",
    ")\n",
    "\n",
    "NOFACE = 'noface'\n",
    "\n",
    "faceDetect = '''\n",
    "(?:\n",
    "    ^@([a-z]+)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:34.515852Z",
     "start_time": "2018-03-01T13:06:34.486450Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfFaces():\n",
    "    faces = []\n",
    "    for tablet in F.otype.s('tablet'):\n",
    "        tabletName = F.catalogId.v(tablet)\n",
    "        period = F.period.v(tablet)\n",
    "        for face in L.d(tablet, otype='face'):\n",
    "            tp = F.type.v(face)\n",
    "            it = F.identifier.v(face) or None\n",
    "            ln = F.srcLnNum.v(face)\n",
    "            itStr = '' if it is None else f' {it}'\n",
    "            if tp != 'noface':\n",
    "                faces.append((period, tabletName, ln, f'@{tp}{itStr}'))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:35.564052Z",
     "start_time": "2018-03-01T13:06:35.536927Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepFaces(gen):\n",
    "    faces = []\n",
    "    faceRe = re.compile(faceDetect, re.X)\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        match = faceRe.match(line)\n",
    "        if match:\n",
    "            face = match.group(1)\n",
    "            if face in FACES:\n",
    "                faces.append((period, tablet, ln, line.strip()))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:37.414300Z",
     "start_time": "2018-03-01T13:06:37.041599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD : period ◆ tablet ◆ ln ◆ face\n",
      "IDENTICAL: all 9407 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 4 ◆ @obverse\n",
      "=    : uruk-iii ◆ P006428 ◆ 14 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448701 ◆ 39 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448701 ◆ 46 ◆ @reverse\n",
      "=    : uruk-iii ◆ P448702 ◆ 53 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448702 ◆ 67 ◆ @reverse\n",
      "=    : uruk-iii ◆ P448703 ◆ 74 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448703 ◆ 83 ◆ @reverse\n",
      "=    : uruk-iii ◆ P471695 ◆ 90 ◆ @obverse\n",
      "=    : uruk-iii ◆ P471695 ◆ 109 ◆ @reverse\n",
      "=    : uruk-iii ◆ P482082 ◆ 117 ◆ @obverse\n",
      "=    : uruk-iii ◆ P482082 ◆ 123 ◆ @reverse\n",
      "=    : uruk-iii ◆ P482083 ◆ 130 ◆ @obverse\n",
      "=    : uruk-iii ◆ P482083 ◆ 143 ◆ @reverse\n",
      "=    : uruk-iii ◆ P499393 ◆ 150 ◆ @obverse\n",
      "=    : uruk-iii ◆ P499393 ◆ 162 ◆ @reverse\n",
      "=    : uruk-iii ◆ P504412 ◆ 169 ◆ @obverse\n",
      "=    : uruk-iii ◆ P504412 ◆ 185 ◆ @reverse\n",
      "=    : uruk-iii ◆ P504413 ◆ 192 ◆ @obverse\n",
      "=    : uruk-iii ◆ P504413 ◆ 195 ◆ @reverse\n",
      "=     and 9387 more\n",
      "Number of results: TF 9407; GREP 9407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('face',),\n",
    "    grepFaces,\n",
    "    tfFaces,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns\n",
    "\n",
    "We check whether we see the same columns with GREP and TF.\n",
    "\n",
    "Note that in TF we have inserted missing columns as `@column 0`.\n",
    "We leave them out again in the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:39.717292Z",
     "start_time": "2018-03-01T13:06:39.684882Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfColumns():\n",
    "    columns = []\n",
    "    for tablet in F.otype.s('tablet'):\n",
    "        tabletName = F.catalogId.v(tablet)\n",
    "        period = F.period.v(tablet)\n",
    "        for face in L.d(tablet, otype='face'):\n",
    "            tp = F.type.v(face)\n",
    "            for column in L.d(face, otype='column'):\n",
    "                number = F.number.v(column)\n",
    "                prime = F.prime.v(column)\n",
    "                ln = F.srcLnNum.v(column)\n",
    "                primeStr = \"'\" if prime else ''\n",
    "                if number != '0':\n",
    "                    columns.append((period, tabletName, ln, tp, f'@column {number}{primeStr}'))\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:40.588717Z",
     "start_time": "2018-03-01T13:06:40.571440Z"
    }
   },
   "outputs": [],
   "source": [
    "columnDetect = '''\n",
    "(?:\n",
    "    ^@col\n",
    ")\n",
    "'''\n",
    "\n",
    "columnCorrectPat = '''\n",
    "(?:\n",
    "    ^@([a-z]+)\n",
    "    (\\s*)\n",
    "    (\\S*)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:41.723629Z",
     "start_time": "2018-03-01T13:06:41.640283Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepColumns(gen):\n",
    "    columnRe = re.compile(columnDetect, re.X)\n",
    "    correctRe = re.compile(columnCorrectPat, re.X)\n",
    "    faceRe = re.compile(faceDetect, re.X)\n",
    "\n",
    "    columns = []\n",
    "    curFace = NOFACE\n",
    "    prevTablet = None\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        if tablet != prevTablet:\n",
    "            curFace = NOFACE\n",
    "        prevTablet = tablet\n",
    "\n",
    "        match = faceRe.match(line)\n",
    "\n",
    "        if match:\n",
    "            face = match.group(1)\n",
    "            if face in FACES:\n",
    "                curFace = face\n",
    "\n",
    "        if columnRe.match(line):\n",
    "            if not line.startswith('@column '):\n",
    "                match = correctRe.match(line)\n",
    "                if match:\n",
    "                    colSpec = match.group(1)\n",
    "                    sep = match.group(2)\n",
    "                    colNum = match.group(3)\n",
    "                    line = f'@column {colNum}'\n",
    "                    print(f'GREP: corrected \"{colSpec}{sep}{colNum}\" => \"{line}\"')\n",
    "                else:\n",
    "                    print(f'GREP: found \"{line}\"')\n",
    "                \n",
    "            columns.append((period, tablet, ln, curFace, line.strip()))\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:43.798421Z",
     "start_time": "2018-03-01T13:06:43.239974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: corrected \"columm 4\" => \"@column 4\"\n",
      "GREP: corrected \"column3\" => \"@column 3\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ face ◆ column\n",
      "IDENTICAL: all 13123 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 5 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P006427 ◆ 7 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 15 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 18 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 21 ◆ obverse ◆ @column 3\n",
      "=    : uruk-iii ◆ P006428 ◆ 29 ◆ obverse ◆ @column 4\n",
      "=    : uruk-iii ◆ P006428 ◆ 32 ◆ obverse ◆ @column 5\n",
      "=    : uruk-iii ◆ P448701 ◆ 40 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 43 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P448702 ◆ 54 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P448702 ◆ 60 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P448702 ◆ 64 ◆ obverse ◆ @column 3\n",
      "=    : uruk-iii ◆ P448703 ◆ 75 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P448703 ◆ 81 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P471695 ◆ 91 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P471695 ◆ 104 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P482082 ◆ 118 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P482083 ◆ 131 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P482083 ◆ 138 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P499393 ◆ 151 ◆ obverse ◆ @column 1\n",
      "=     and 13103 more\n",
      "Number of results: TF 13123; GREP 13123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('face', 'column'),\n",
    "    grepColumns,\n",
    "    tfColumns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lines\n",
    "\n",
    "We check whether we see the same line numbers with GREP and TF.\n",
    "We also check the cross-references on lines.\n",
    "\n",
    "The text material on lines will be checked below, systematically.\n",
    "\n",
    "### Line numbers\n",
    "\n",
    "During the conversion to TF we have \n",
    "detected bad numberings in some columns\n",
    "and stored that fact in the `badNumbering` feature.\n",
    "\n",
    "One way to look at them is in the raw TF file\n",
    "[badNumbering.tf](https://github.com/Dans-labs/Nino-cunei/blob/master/tf/uruk/0.1/badNumbering.tf).\n",
    "\n",
    "There you see case nodes with values `1` (duplicate numbers) or `2` (wrong order).\n",
    "\n",
    "Here is an overview of the cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:46.866932Z",
     "start_time": "2018-03-01T13:06:46.849338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26 x 2\n",
      "  3 x 1\n"
     ]
    }
   ],
   "source": [
    "for (val, amount) in F.badNumbering.freqList():\n",
    "    print(f'{amount:>3} x {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For full detail, see the\n",
    "[diagnostics](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/diagnostics.tsv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the numbered lines in the transcriptions do not correspond to the TF node type `line`,\n",
    "but to `case`. \n",
    "Because these lines are filled with material of the smallest cases (those that do not have\n",
    "sub-cases).\n",
    "\n",
    "In TF these are the cases that have the feature `fullNumber`.\n",
    "\n",
    "In TF we have removed the dots from numbers, but kept them otherwise unchanged.\n",
    "In order to make the comparison, we also remove the dots after grepping numbers from the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:50.328762Z",
     "start_time": "2018-03-01T13:06:50.298924Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfLines():\n",
    "    cases = []\n",
    "    for tablet in F.otype.s('tablet'):\n",
    "        tabletName = F.catalogId.v(tablet)\n",
    "        period = F.period.v(tablet)\n",
    "        for case in L.d(tablet, otype='case'):\n",
    "            fullNumber = F.fullNumber.v(case)\n",
    "            if fullNumber is None:\n",
    "                continue\n",
    "            ln = F.srcLnNum.v(case)\n",
    "            origNumber = F.origNumber.v(case)\n",
    "            theNumber = fullNumber if origNumber is None else origNumber \n",
    "            cases.append((period, tabletName, ln, f'{theNumber}'))\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:51.193377Z",
     "start_time": "2018-03-01T13:06:51.176695Z"
    }
   },
   "outputs": [],
   "source": [
    "lineNumPat = '''\n",
    "(?:\n",
    "    ^\n",
    "    (\n",
    "            (?:[a-zA-Z0-9.\\'-]+)\n",
    "        |\n",
    "            (?=[|\\[])\n",
    "    )\n",
    ")\n",
    "'''\n",
    "lineNumDetect = '''\n",
    "(?:\n",
    "    ^\n",
    "    (?:\n",
    "            (?:[a-zA-Z0-9.\\'-]+\\s+)\n",
    "        |\n",
    "            (?=[|\\[])\n",
    "    )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:51.909529Z",
     "start_time": "2018-03-01T13:06:51.891460Z"
    }
   },
   "outputs": [],
   "source": [
    "def tweakLine(line):\n",
    "    if line.startswith('1.1('):\n",
    "        print(f'GREP: \"1.1(\" => \"1. 1(\"')\n",
    "        line = line.replace('1.1(', '1. 1(', 1)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:52.545662Z",
     "start_time": "2018-03-01T13:06:52.518392Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepLines(gen):\n",
    "    cases = []\n",
    "    lineNumRe = re.compile(lineNumPat, re.X)\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "\n",
    "        line = tweakLine(line)\n",
    "        match = lineNumRe.match(line)\n",
    "        if match:\n",
    "            caseNum = match.group(1)\n",
    "            caseNumClean = caseNum.replace('.', '').strip()\n",
    "            cases.append((period, tablet, ln, caseNumClean))\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:53.852477Z",
     "start_time": "2018-03-01T13:06:53.350068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"1.1(\" => \"1. 1(\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ lineNum\n",
      "IDENTICAL: all 41142 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ 1\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 16 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 17 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 19 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 20 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 22 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 23 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 24 ◆ 3\n",
      "=    : uruk-iii ◆ P006428 ◆ 25 ◆ 4\n",
      "=    : uruk-iii ◆ P006428 ◆ 26 ◆ 5\n",
      "=    : uruk-iii ◆ P006428 ◆ 27 ◆ 6\n",
      "=    : uruk-iii ◆ P006428 ◆ 28 ◆ 7\n",
      "=    : uruk-iii ◆ P006428 ◆ 30 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 31 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 33 ◆ 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 41 ◆ 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 42 ◆ 2\n",
      "=    : uruk-iii ◆ P448701 ◆ 44 ◆ 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 45 ◆ 2\n",
      "=     and 41122 more\n",
      "Number of results: TF 41142; GREP 41142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('lineNum',),\n",
    "    grepLines,\n",
    "    tfLines,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross references\n",
    "\n",
    "Cross references are the lines starting with `>>`.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    ">>P000014 oi2 \n",
    "```\n",
    "\n",
    "It means that the preceding line refers to tablet `P000014`, line `oi2`.\n",
    "We do not interpret these values, but we have stored it in the feature *crossref*\n",
    "as `P000014.oi2`.\n",
    "\n",
    "If there are multiple crossrefs, we haven combined them in a comma-separated list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:56.425576Z",
     "start_time": "2018-03-01T13:06:56.393033Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfCrossrefs():\n",
    "    crossrefs = []\n",
    "    for tablet in F.otype.s('tablet'):\n",
    "        tabletName = F.catalogId.v(tablet)\n",
    "        period = F.period.v(tablet)\n",
    "        for case in L.d(tablet, otype='case'):\n",
    "            crossrefStr = F.crossref.v(case)\n",
    "            if crossrefStr is None:\n",
    "                continue\n",
    "            theseCrossrefs = crossrefStr.split(',')\n",
    "            fullNumber = F.fullNumber.v(case)\n",
    "            ln = F.srcLnNum.v(case)\n",
    "            origNumber = F.origNumber.v(case)\n",
    "            theNumber = fullNumber if origNumber is None else origNumber\n",
    "            for (offset, crossref) in enumerate(theseCrossrefs):\n",
    "                crossrefs.append((period, tabletName, ln + 1 + offset, theNumber, crossref))\n",
    "    return crossrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:57.660508Z",
     "start_time": "2018-03-01T13:06:57.644793Z"
    }
   },
   "outputs": [],
   "source": [
    "crossrefPat = '''\n",
    "(?:\n",
    "    >>\n",
    "    \\s*\n",
    "    (\\S+)\n",
    "    (.*)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:06:58.762682Z",
     "start_time": "2018-03-01T13:06:58.702809Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepCrossrefs(gen):\n",
    "    lineNumRe = re.compile(lineNumPat, re.X)\n",
    "    crossrefRe = re.compile(crossrefPat, re.X)\n",
    "\n",
    "    crossrefs = []\n",
    "    curNum = None\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "\n",
    "        line = tweakLine(line)\n",
    "            \n",
    "        match = lineNumRe.match(line)\n",
    "        if match:\n",
    "            caseNum = match.group(1)\n",
    "            caseNumClean = caseNum.replace('.', '').strip()\n",
    "            curNum = caseNumClean\n",
    "            continue\n",
    "        match = crossrefRe.match(line)\n",
    "        if match:\n",
    "            cTablet = match.group(1)\n",
    "            rest = match.group(2).strip()\n",
    "            if rest:\n",
    "                rest = ':'.join(rest.split(maxsplit=1))\n",
    "            if rest:\n",
    "                rest = f'.{rest}'\n",
    "            crossrefs.append((period, tablet, ln, curNum, f'{cTablet}{rest}'))\n",
    "        \n",
    "    return crossrefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are comments intervening a line and its crossrefs,\n",
    "TF can no longer produce the exact line numbers for those crossrefs. They will be a bit of.\n",
    "We will allow the comparison a bit of leeway in this respect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:07:01.193206Z",
     "start_time": "2018-03-01T13:07:00.721452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"1.1(\" => \"1. 1(\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ lineNum ◆ crossref\n",
      "IDENTICAL: all 5927 items\n",
      "=    : uruk-iii ◆ P000456 ◆ 308 ◆ 1 ◆ P000014.oi2\n",
      "=    : uruk-iii ◆ P000456 ◆ 311 ◆ 3 ◆ P000014.oiii5\n",
      "=    : uruk-iii ◆ P000456 ◆ 317 ◆ 1 ◆ P000014.oii8\n",
      "=    : uruk-iii ◆ P000456 ◆ 320 ◆ 3 ◆ P000014.ri2\n",
      "=    : uruk-iii ◆ P002498 ◆ 6606 ◆ 1 ◆ Q000026.007\n",
      "=    : uruk-iii ◆ P002498 ◆ 6608 ◆ 2 ◆ Q000026.008\n",
      "=    : uruk-iii ◆ P002498 ◆ 6610 ◆ 3 ◆ Q000026.009\n",
      "=    : uruk-iii ◆ P002498 ◆ 6612 ◆ 4 ◆ Q000026.010\n",
      "=    : uruk-iii ◆ P002498 ◆ 6614 ◆ 5 ◆ Q000026.011\n",
      "=    : uruk-iii ◆ P002498 ◆ 6618 ◆ 1 ◆ Q000026.n\n",
      "=    : uruk-iii ◆ P002498 ◆ 6620 ◆ 2 ◆ Q000026.n\n",
      "=    : uruk-iii ◆ P002498 ◆ 6622 ◆ 3 ◆ Q000026.n\n",
      "=    : uruk-iii ◆ P002498 ◆ 6624 ◆ 4 ◆ Q000026.n\n",
      "=    : uruk-iii ◆ P002498 ◆ 6628 ◆ 1 ◆ Q000026.colophon\n",
      "=    : uruk-iii ◆ P000106 ◆ 16985 ◆ 1 ◆ Q000002.001\n",
      "=    : uruk-iii ◆ P000106 ◆ 16989 ◆ 1 ◆ Q000002.colophon\n",
      "=    : uruk-iii ◆ P000161 ◆ 16998 ◆ 1 ◆ Q000002.001\n",
      "=    : uruk-iii ◆ P000161 ◆ 17000 ◆ 2 ◆ Q000002.002\n",
      "=    : uruk-iii ◆ P000161 ◆ 17002 ◆ 3 ◆ Q000002.003\n",
      "=    : uruk-iii ◆ P000161 ◆ 17004 ◆ 4 ◆ Q000002.004\n",
      "=     and 5907 more\n",
      "Number of results: TF 5927; GREP 5927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('lineNum', 'crossref'),\n",
    "    grepCrossrefs,\n",
    "    tfCrossrefs,\n",
    "    leeway=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "There are several types of comments: rulings (`$`), metadata (`#`), and object descriptions\n",
    "(`@object`).\n",
    "\n",
    "Comments can be associated with many kinds of source lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:07:05.828292Z",
     "start_time": "2018-03-01T13:07:05.813205Z"
    }
   },
   "outputs": [],
   "source": [
    "cTypes = set('''\n",
    "    tablet\n",
    "    face\n",
    "    column\n",
    "    line\n",
    "    case\n",
    "'''.strip().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object descriptions\n",
    "\n",
    "The object descriptions are tied to tablets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:07:07.482803Z",
     "start_time": "2018-03-01T13:07:07.460017Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfObjects():\n",
    "    tobjects = []\n",
    "    for t in F.otype.s('tablet'):\n",
    "        (tablet, column, line) = T.sectionFromNode(t)\n",
    "        objects = (o for o in L.d(t, otype='comment') if F.type.v(o) == 'object')\n",
    "        for obj in objects:\n",
    "            tobjects.append((\n",
    "                F.period.v(t), tablet, F.srcLnNum.v(obj), \n",
    "                F.catalogId.v(t), F.text.v(obj)\n",
    "            ))\n",
    "    return tobjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:07:09.135534Z",
     "start_time": "2018-03-01T13:07:09.120047Z"
    }
   },
   "outputs": [],
   "source": [
    "objectDetect = '''\n",
    "(?:\n",
    "    ^@object\n",
    "    \\s+\n",
    "    (.*)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:07:41.205350Z",
     "start_time": "2018-03-01T13:07:41.179411Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepObjects(gen):\n",
    "    objectRe = re.compile(objectDetect, re.X)\n",
    "\n",
    "    tobjects = []\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            print(f'GREP: skipping duplicate or non physical tablet \"{tablet}\"')\n",
    "            continue\n",
    "        match = objectRe.match(line)\n",
    "        if match:\n",
    "            text = match.group(1).strip()\n",
    "            tobjects.append((period, tablet, ln, tablet, text))\n",
    "    return tobjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:07:42.573783Z",
     "start_time": "2018-03-01T13:07:42.091746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: skipping duplicate or non physical tablet \"P002176\"\n",
      "GREP: skipping duplicate or non physical tablet \"P464118\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471689\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471682\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471685\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471683\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471691\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471694\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471693\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471688\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471687\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471692\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471684\"\n",
      "GREP: skipping duplicate or non physical tablet \"P491489\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471686\"\n",
      "GREP: skipping duplicate or non physical tablet \"P471690\"\n",
      "GREP: skipping duplicate or non physical tablet \"P455567\"\n",
      "GREP: skipping duplicate or non physical tablet \"P456183\"\n",
      "GREP: skipping duplicate or non physical tablet \"P455718\"\n",
      "GREP: skipping duplicate or non physical tablet \"P455726\"\n",
      "GREP: skipping duplicate or non physical tablet \"P456095\"\n",
      "GREP: skipping duplicate or non physical tablet \"P456780\"\n",
      "GREP: skipping duplicate or non physical tablet \"P456795\"\n",
      "GREP: skipping duplicate or non physical tablet \"P456817\"\n",
      "GREP: skipping duplicate or non physical tablet \"P457754\"\n",
      "GREP: skipping duplicate or non physical tablet \"P457755\"\n",
      "GREP: skipping duplicate or non physical tablet \"P458281\"\n",
      "GREP: skipping duplicate or non physical tablet \"P458349\"\n",
      "GREP: skipping duplicate or non physical tablet \"P458394\"\n",
      "GREP: skipping duplicate or non physical tablet \"P458395\"\n",
      "GREP: skipping duplicate or non physical tablet \"P458434\"\n",
      "GREP: skipping duplicate or non physical tablet \"P458717\"\n",
      "GREP: skipping duplicate or non physical tablet \"P458792\"\n",
      "GREP: skipping duplicate or non physical tablet \"P458869\"\n",
      "GREP: skipping duplicate or non physical tablet \"P252175\"\n",
      "GREP: skipping duplicate or non physical tablet \"P431151\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ text\n",
      "IDENTICAL: all 403 items\n",
      "=    : uruk-iii ◆ P274834 ◆ 40308 ◆ P274834 ◆ seal\n",
      "=    : uruk-iii ◆ P368413 ◆ 40316 ◆ P368413 ◆ seal\n",
      "=    : uruk-iii ◆ P454537 ◆ 40323 ◆ P454537 ◆ seal\n",
      "=    : uruk-iii ◆ P456542 ◆ 40361 ◆ P456542 ◆ seal\n",
      "=    : uruk-iii ◆ P472780 ◆ 40368 ◆ P472780 ◆ seal\n",
      "=    : uruk-iii ◆ P472781 ◆ 40375 ◆ P472781 ◆ seal\n",
      "=    : uruk-iii ◆ P472782 ◆ 40382 ◆ P472782 ◆ seal\n",
      "=    : uruk-iii ◆ P472783 ◆ 40389 ◆ P472783 ◆ seal\n",
      "=    : uruk-iii ◆ P472784 ◆ 40396 ◆ P472784 ◆ seal\n",
      "=    : uruk-iii ◆ P472785 ◆ 40403 ◆ P472785 ◆ seal\n",
      "=    : uruk-iii ◆ P472786 ◆ 40410 ◆ P472786 ◆ seal\n",
      "=    : uruk-iii ◆ P472787 ◆ 40417 ◆ P472787 ◆ seal\n",
      "=    : uruk-iii ◆ P472788 ◆ 40424 ◆ P472788 ◆ seal\n",
      "=    : uruk-iii ◆ P472789 ◆ 40431 ◆ P472789 ◆ seal\n",
      "=    : uruk-iii ◆ P472790 ◆ 40438 ◆ P472790 ◆ seal\n",
      "=    : uruk-iii ◆ P472791 ◆ 40445 ◆ P472791 ◆ seal\n",
      "=    : uruk-iii ◆ P472792 ◆ 40452 ◆ P472792 ◆ seal\n",
      "=    : uruk-iii ◆ P472793 ◆ 40459 ◆ P472793 ◆ seal\n",
      "=    : uruk-iii ◆ P472794 ◆ 40466 ◆ P472794 ◆ seal\n",
      "=    : uruk-iii ◆ P472795 ◆ 40473 ◆ P472795 ◆ seal\n",
      "=     and 383 more\n",
      "Number of results: TF 403; GREP 403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('text',),\n",
    "    grepObjects,\n",
    "    tfObjects,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rulings\n",
    "\n",
    "These are not really comments, but markings on the tablets.\n",
    "\n",
    "In order to find rulings that are associated to a node, we \n",
    "traverse from that node via `comments` edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:07:47.285290Z",
     "start_time": "2018-03-01T13:07:47.255094Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfRulings():\n",
    "    rulings = []\n",
    "    for n in N():\n",
    "        if F.otype.v(n) not in cTypes:\n",
    "            continue\n",
    "        cNodes = [c for c in E.comments.f(n) if F.type.v(c) == 'ruling']\n",
    "        if not cNodes:\n",
    "            continue\n",
    "        t = L.u(n, otype='tablet')[0] if F.otype.v(n) != 'tablet' else n\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        for cNode in cNodes:\n",
    "            rulings.append((\n",
    "                F.period.v(t), tablet, F.srcLnNum.v(cNode), \n",
    "                F.text.v(cNode)\n",
    "            ))\n",
    "    return rulings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:07:48.379874Z",
     "start_time": "2018-03-01T13:07:48.363622Z"
    }
   },
   "outputs": [],
   "source": [
    "rulingDetect = '''\n",
    "(?:\n",
    "    ^\\$\n",
    "    \\s*\n",
    "    (.*)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:16.381337Z",
     "start_time": "2018-03-01T13:08:16.350194Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepRulings(gen):\n",
    "    rulingRe = re.compile(rulingDetect, re.X)\n",
    "\n",
    "    rulings = []\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            print(f'GREP: skipping duplicate or non-physical tablet \"{tablet}\"')\n",
    "            continue\n",
    "        match = rulingRe.match(line)\n",
    "        if match:\n",
    "            text = match.group(1).strip()\n",
    "            rulings.append((period, tablet, ln, text))\n",
    "    return rulings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:18.470532Z",
     "start_time": "2018-03-01T13:08:17.776001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: skipping duplicate or non-physical tablet \"P002176\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P464118\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471689\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471682\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471685\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471683\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471691\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471694\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471693\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471688\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471687\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471692\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471684\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P491489\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471686\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471690\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P455567\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P456183\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P455718\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P455726\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P456095\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P456780\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P456795\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P456817\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P457754\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P457755\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458281\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458349\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458394\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458395\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458434\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458717\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458792\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458869\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P252175\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P431151\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ text\n",
      "IDENTICAL: all 4006 items\n",
      "=    : uruk-iii ◆ P448701 ◆ 47 ◆ (not imaged)\n",
      "=    : uruk-iii ◆ P448702 ◆ 55 ◆ beginning broken\n",
      "=    : uruk-iii ◆ P448702 ◆ 61 ◆ beginning broken\n",
      "=    : uruk-iii ◆ P448702 ◆ 62 ◆ blank space\n",
      "=    : uruk-iii ◆ P448702 ◆ 65 ◆ beginning broken\n",
      "=    : uruk-iii ◆ P448702 ◆ 66 ◆ blank space\n",
      "=    : uruk-iii ◆ P448702 ◆ 68 ◆ (not imaged)\n",
      "=    : uruk-iii ◆ P448703 ◆ 82 ◆ blank space\n",
      "=    : uruk-iii ◆ P448703 ◆ 84 ◆ (not imaged)\n",
      "=    : uruk-iii ◆ P471695 ◆ 99 ◆ n lines broken\n",
      "=    : uruk-iii ◆ P471695 ◆ 102 ◆ rest broken\n",
      "=    : uruk-iii ◆ P471695 ◆ 103 ◆ (for a total of 12 sub-cases with PNN)\n",
      "=    : uruk-iii ◆ P471695 ◆ 107 ◆ blank space\n",
      "=    : uruk-iii ◆ P471695 ◆ 108 ◆ rest broken\n",
      "=    : uruk-iii ◆ P471695 ◆ 110 ◆ beginning broken\n",
      "=    : uruk-iii ◆ P482082 ◆ 119 ◆ beginning broken\n",
      "=    : uruk-iii ◆ P482082 ◆ 124 ◆ (not given)\n",
      "=    : uruk-iii ◆ P482083 ◆ 132 ◆ beginning broken\n",
      "=    : uruk-iii ◆ P482083 ◆ 139 ◆ beginning broken\n",
      "=    : uruk-iii ◆ P482083 ◆ 144 ◆ (not given)\n",
      "=     and 3986 more\n",
      "Number of results: TF 4006; GREP 4006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('text',),\n",
    "    grepRulings,\n",
    "    tfRulings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "\n",
    "These are reall comments, in the sense that they do not correspond to \n",
    "information on the tablets, but remarks supplied by the transcribers.\n",
    "\n",
    "As with rulings, in order to find metadat that is associated to a node, we \n",
    "traverse from that node via `comments` edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:22.283998Z",
     "start_time": "2018-03-01T13:08:22.255339Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfMetas():\n",
    "    metas = []\n",
    "    for n in N():\n",
    "        if F.otype.v(n) not in cTypes:\n",
    "            continue\n",
    "        cNodes = [c for c in E.comments.f(n) if F.type.v(c) == 'meta']\n",
    "        if not cNodes:\n",
    "            continue\n",
    "        t = L.u(n, otype='tablet')[0] if F.otype.v(n) != 'tablet' else n\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        for cNode in cNodes:\n",
    "            metas.append((\n",
    "                F.period.v(t), tablet, F.srcLnNum.v(cNode), \n",
    "                F.text.v(cNode)\n",
    "            ))\n",
    "    return metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:23.393286Z",
     "start_time": "2018-03-01T13:08:23.377820Z"
    }
   },
   "outputs": [],
   "source": [
    "metaDetect = '''\n",
    "(?:\n",
    "    ^[#]\n",
    "    \\s*\n",
    "    (.*)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:34.236555Z",
     "start_time": "2018-03-01T13:08:34.206554Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepMetas(gen):\n",
    "    metaRe = re.compile(metaDetect, re.X)\n",
    "\n",
    "    metas = []\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            print(f'GREP: skipping duplicate or non-physical tablet \"{tablet}\"')\n",
    "            continue\n",
    "        match = metaRe.match(line)\n",
    "        if match:\n",
    "            text = match.group(1).strip()\n",
    "            metas.append((period, tablet, ln, text))\n",
    "    return metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:36.222922Z",
     "start_time": "2018-03-01T13:08:35.477419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: skipping duplicate or non-physical tablet \"P002176\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P464118\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471689\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471682\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471685\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471683\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471691\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471694\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471693\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471688\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471687\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471692\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471684\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P491489\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471686\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P471690\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P455567\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P456183\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P455718\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P455726\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P456095\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P456780\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P456795\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P456817\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P457754\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P457755\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458281\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458349\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458394\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458395\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458434\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458717\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458792\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P458869\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P252175\"\n",
      "GREP: skipping duplicate or non-physical tablet \"P431151\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ text\n",
      "IDENTICAL: all 11272 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 2 ◆ version: 0.1\n",
      "=    : uruk-iii ◆ P006427 ◆ 3 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P006428 ◆ 12 ◆ version: 0.1\n",
      "=    : uruk-iii ◆ P006428 ◆ 13 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P448701 ◆ 37 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P448702 ◆ 51 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P448703 ◆ 72 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P471695 ◆ 88 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P482082 ◆ 115 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P482083 ◆ 128 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P482083 ◆ 137 ◆ calculation: 3(N01) ÷ 10 = 1(N39) 1(N24)\n",
      "=    : uruk-iii ◆ P499393 ◆ 148 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P504412 ◆ 167 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P504413 ◆ 190 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P006438 ◆ 200 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P000014 ◆ 221 ◆ atf: lang qpc\n",
      "=    : uruk-iii ◆ P000014 ◆ 227 ◆ = P000456 obv. ii 1\n",
      "=    : uruk-iii ◆ P000014 ◆ 245 ◆ = P000456 obv. iii 1\n",
      "=    : uruk-iii ◆ P000014 ◆ 254 ◆ = P000456 obv. ii 3\n",
      "=    : uruk-iii ◆ P000014 ◆ 264 ◆ = P000456 obv. iii 3\n",
      "=     and 11252 more\n",
      "Number of results: TF 11272; GREP 11272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('text',),\n",
    "    grepMetas,\n",
    "    tfMetas,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have loaded functions to produce atf representations\n",
    "for signs, quads and clusters from the Cunei submodule of TF.\n",
    "These functions take care of repeats, primes, variants modifiers, and flags.\n",
    "See [additions](https://github.com/Dans-labs/text-fabric/wiki/Additions).\n",
    "\n",
    "A complication is that there are missing line numbers in a few cases, \n",
    "so the usual grep pattern does not pick them up.\n",
    "\n",
    "There a lines that start with `[` and with `|`, so we have to take care we get them.\n",
    "\n",
    "There are also line numbers with a hyphen in it, such as `6-7`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primes\n",
    "\n",
    "First an overview of the occurrence of primes.\n",
    "\n",
    "**N.B.:** This gathers primes on *signs*, *column* numbers and *case* numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:45.357607Z",
     "start_time": "2018-03-01T13:08:45.334298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5164 x 1\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.prime.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want so see the node types of primed entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:46.716824Z",
     "start_time": "2018-03-01T13:08:46.685832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4632 x case\n",
      "  523 x column\n",
      "    9 x sign\n"
     ]
    }
   ],
   "source": [
    "primed = collections.Counter()\n",
    "for n in F.prime.s(1):\n",
    "    primed[F.otype.v(n)] += 1\n",
    "for x in sorted(primed.items()):\n",
    "    print(f'{x[1]:>5} x {x[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us check the primes with grep, directly in the source files.\n",
    "We look into lines starting with a (hierarchical number), followed by space,\n",
    "and then later a single of double prime, but not one within a grapheme, such as `GA'AR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:47.746729Z",
     "start_time": "2018-03-01T13:08:47.719672Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfPrimes():\n",
    "    primes = []\n",
    "    for n in F.prime.s(1):\n",
    "        if F.otype.v(n) != 'sign':\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        primes.append((F.period.v(t), tablet, F.srcLnNum.v(case), f\"{CUNEI.atfFromSign(n)}\"))\n",
    "    return primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:48.761785Z",
     "start_time": "2018-03-01T13:08:48.744580Z"
    }
   },
   "outputs": [],
   "source": [
    "primeDetect = f'''\n",
    "(?:\n",
    "    {lineNumDetect}\n",
    "    (\n",
    "        .*\n",
    "        [\\'\"]\n",
    "        [^A]\n",
    "        .*\n",
    "    )\n",
    ")\n",
    "'''\n",
    "\n",
    "graphemePrimePat = '''\n",
    "(?:\n",
    "        (?:\n",
    "            [0-9N]+\n",
    "            \\(\n",
    "                [^)]+[\\'\"]\n",
    "            \\)\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            [A-Z0-9~@a-wyz\\'-]+\\'\n",
    "        )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:49.943558Z",
     "start_time": "2018-03-01T13:08:49.906004Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepPrimes(gen):\n",
    "    primes = []\n",
    "    primeRe = re.compile(primeDetect, re.X)\n",
    "    graphemeRe = re.compile(graphemePrimePat, re.X)\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        line = tweakLine(line)\n",
    "        match = primeRe.match(line)\n",
    "        if match:\n",
    "            material = match.group(1)\n",
    "            if '\"' in material:\n",
    "                print(f'GREP: in \"{material}\": replacing \" by \\'')\n",
    "                material = material.replace('\"', \"'\")\n",
    "            graphemes = graphemeRe.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                primes.append((period, tablet, ln, grapheme))\n",
    "    return primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:51.079791Z",
     "start_time": "2018-03-01T13:08:50.843222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"1.1(\" => \"1. 1(\"\n",
      "GREP: in \"3(N41) 1(N24\")# , [TAR~a] \": replacing \" by '\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "IDENTICAL: all 9 items\n",
      "=    : uruk-iii ◆ P411604 ◆ 48967 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49069 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49071 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49073 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49075 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411539 ◆ 49391 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P006437 ◆ 54446 ◆ 1(N30c')\n",
      "=    : uruk-iii ◆ P464140 ◆ 55938 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P464140 ◆ 55939 ◆ 1(N24')\n",
      "=     no more items\n",
      "Number of results: TF 9; GREP 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepPrimes,\n",
    "    tfPrimes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants and modifiers\n",
    "\n",
    "Overview of variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:54.300369Z",
     "start_time": "2018-03-01T13:08:54.255682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23156 x a\n",
      " 3994 x b\n",
      " 1505 x c\n",
      " 1308 x a1\n",
      "  689 x b1\n",
      "  188 x a2\n",
      "  183 x d\n",
      "  125 x b2\n",
      "   85 x f\n",
      "   72 x a3\n",
      "   40 x e\n",
      "   29 x c2\n",
      "   22 x c1\n",
      "   22 x c3\n",
      "   14 x c5\n",
      "   12 x a0\n",
      "   12 x b3\n",
      "   12 x d1\n",
      "   12 x v\n",
      "   11 x c4\n",
      "    6 x a4\n",
      "    6 x g\n",
      "    5 x d2\n",
      "    4 x d4\n",
      "    4 x h\n",
      "    2 x 3a\n",
      "    2 x d3\n",
      "    1 x h2\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.variant.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of modifiers outside a repeat expression, like `1(N57)@t`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:57.288540Z",
     "start_time": "2018-03-01T13:08:57.270644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  634 x g\n",
      "  247 x t\n",
      "   35 x n\n",
      "    6 x r\n",
      "    4 x s\n",
      "    1 x c\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifier.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of modifiers within a repeat expression, like `7(N34@f)#`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:08:58.709015Z",
     "start_time": "2018-03-01T13:08:58.691013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 x f\n",
      "   15 x t\n",
      "    1 x r\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifierInner.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are many variants and considerably fewer modifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look for variants and modifiers in the TF resource and by GREPping them from the sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:01.232311Z",
     "start_time": "2018-03-01T13:09:01.187707Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfVarMod():\n",
    "    varmods = []\n",
    "    for n in F.otype.s('sign'):\n",
    "        variant = F.variant.v(n)\n",
    "        modifier = F.modifier.v(n)\n",
    "        modifierInner = F.modifierInner.v(n)\n",
    "        if variant is None and modifier is None and modifierInner is None:\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        position = (F.period.v(t), tablet, F.srcLnNum.v(case))\n",
    "        varmods.append((*position, f\"{CUNEI.atfFromSign(n)}\"))\n",
    "\n",
    "        written = F.written.v(n)\n",
    "        if written is not None:\n",
    "            if '~' in written:\n",
    "                varmods.append((*position, written))\n",
    "\n",
    "    return varmods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order\n",
    "Modifiers and variants may come in any order.\n",
    "The conversion has set *modifierFirst* on those items where the modifier precedes the variant.\n",
    "\n",
    "Hence, when we fetch data from TF, we can and do put modifiers and variants in the right order.\n",
    "\n",
    "Examples:\n",
    "\n",
    "```\n",
    "3. 1(N14) 8(N01) , RAD~a@g ERIM~a SZU2 A?\n",
    "```\n",
    "\n",
    "and cases with modifier and then variant:\n",
    "\n",
    "```\n",
    "4. 2(N01) , URUDU@g~b SZU2#\n",
    "```\n",
    "\n",
    "both from the same tablet P003407.\n",
    "\n",
    "#### Uppercase\n",
    "We encounter modifiers or variants in uppercase.\n",
    "The conversion has brought them to lower case.\n",
    "When we fetch data by grep, we perform this lowercasing before making the comparison.\n",
    "\n",
    "#### Stray modifier\n",
    "Somewhere in the source is `SUKUD@inversum`.\n",
    "The conversion translates the `@inversum` to `@v`.\n",
    "We have to mimick that when we do grep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaks\n",
    "During conversion, we found some problems in the sources and tweaked them.\n",
    "When we grep, we must repeat those tweaks, in order to get comparable results.\n",
    "\n",
    "See the [diagnostics](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/diagnostics.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:59.958288Z",
     "start_time": "2018-03-01T13:09:59.890072Z"
    }
   },
   "outputs": [],
   "source": [
    "TWEAK_MATERIAL = (\n",
    "#    ('4\"', \"4'\"),\n",
    "#    ('[,', ''),\n",
    "    ('SA|L', 'SAL|'),\n",
    "    ('~x(|EN~c.NUN~a|)', '~v (|EN~c.NUN~a|)a'),\n",
    "    ('~x', '~v'),\n",
    "    ('U2@~b', 'U2~b'),\n",
    "#    (')|U', ') |U'),\n",
    "    ('1N(02)', '1(N02)'),\n",
    "    ('(1N', '1(N'),\n",
    "#    ('~A', '~a'),\n",
    "    ('{', '('),\n",
    "    ('}', ')'),\n",
    "#    ('sag-apin', 'sag-apin'),\n",
    "#    ('@inversum', '@v'),\n",
    "     (('KI@', -1), 'KI#'),\n",
    ")\n",
    "\n",
    "def tweakBeforeGrep(material):\n",
    "    for (pat, rep) in TWEAK_MATERIAL:\n",
    "        if type(pat) is tuple:\n",
    "            (pat, pos) = pat\n",
    "            if pos == 0:\n",
    "                condition = material.startswith(pat)\n",
    "                mark = ' (at start)'\n",
    "            elif pos == -1:\n",
    "                condition = material.endswith(pat)\n",
    "                mark = ' (at end)'\n",
    "        else:\n",
    "            pos = None\n",
    "            condition = pat in material\n",
    "            mark = ''\n",
    "\n",
    "        if condition:\n",
    "            print(f'GREP: tweak \"{pat}\" => \"{rep}\"')\n",
    "            if pos is None:\n",
    "                material = material.replace(pat, rep)\n",
    "            elif pos == 0:\n",
    "                material = material.replace(pat, rep, 1)\n",
    "            else:\n",
    "                material = material[0:-len(pat)] + rep\n",
    "    return material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:05.779589Z",
     "start_time": "2018-03-01T13:09:05.763746Z"
    }
   },
   "outputs": [],
   "source": [
    "upperPat = '''\n",
    "(?:\n",
    "    [~]([A-Z])\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:06.694313Z",
     "start_time": "2018-03-01T13:09:06.655591Z"
    }
   },
   "outputs": [],
   "source": [
    "upperRe = re.compile(upperPat, re.X)\n",
    "\n",
    "def lower(match):\n",
    "    return f'~{match.group(1).lower()}'\n",
    "\n",
    "def graphemeTweaks(grapheme):\n",
    "    if '@inversum' in grapheme:\n",
    "        print(f'GREP: \"@inversum\" => \"@v\"')\n",
    "        grapheme = grapheme.replace('@inversum', '@v')\n",
    "    if '~a~a' in grapheme:\n",
    "        print(f'GREP: \"~a~a\" => \"~a\"')\n",
    "        grapheme = grapheme.replace('~a~a', '~a')\n",
    "    if upperRe.search(grapheme):\n",
    "        print(f'GREP: uppercase variant/modifier in grapheme changed to lowercase')\n",
    "        grapheme = upperRe.sub(lower, grapheme)\n",
    "    if '\"' in grapheme:\n",
    "        print(f'GREP: double prime replaced by single one')\n",
    "        grapheme = grapheme.replace('\"', \"'\")\n",
    "    if '?#' in grapheme:\n",
    "        print(f'GREP: flags order \"?#\" changed into \"#?\"')\n",
    "        grapheme = grapheme.replace('?#', '#?')\n",
    "    return grapheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:07.611530Z",
     "start_time": "2018-03-01T13:09:07.593214Z"
    }
   },
   "outputs": [],
   "source": [
    "varmodDetect = f'''\n",
    "(?:\n",
    "    {lineNumDetect}\n",
    "    (\n",
    "        .*\n",
    "        [@~]\n",
    "        .*\n",
    "    )\n",
    ")\n",
    "'''\n",
    "\n",
    "graphemeVarmodPat = '''\n",
    "(?:\n",
    "        (?:\n",
    "            [0-9N]+\n",
    "            \\(\n",
    "                [^)]+\n",
    "                [@~]\n",
    "                [^)]+\n",
    "            \\)\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            [0-9N]+\n",
    "            \\(\n",
    "                [^)]+\n",
    "            \\)\n",
    "            @[a-z]\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            [A-Z0-9a-wyz\\'-]+\n",
    "            [@~]\n",
    "            [0-9~@a-wyzA-WYZ]+\n",
    "        )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:08.484220Z",
     "start_time": "2018-03-01T13:09:08.446317Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepVarMod(gen):\n",
    "    varmodRe = re.compile(varmodDetect, re.X)\n",
    "    graphemeRe = re.compile(graphemeVarmodPat, re.X)\n",
    "\n",
    "    varmods = []\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        line = tweakLine(line)\n",
    "        line = tweakBeforeGrep(line.strip())\n",
    "        match = varmodRe.match(line)\n",
    "        if match:\n",
    "            material = match.group(1)\n",
    "            graphemes = graphemeRe.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                grapheme = graphemeTweaks(grapheme)\n",
    "                varmods.append((period, tablet, ln, grapheme))\n",
    "    return varmods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:12.008158Z",
     "start_time": "2018-03-01T13:09:09.894681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"@inversum\" => \"@v\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: tweak \"KI@\" => \"KI!\"\n",
      "GREP: tweak \"(1N\" => \"1(N\"\n",
      "GREP: \"1.1(\" => \"1. 1(\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: tweak \"U2@~b\" => \"U2~b\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "IDENTICAL: all 31867 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ SANGA~a\n",
      "=    : uruk-iii ◆ P006428 ◆ 26 ◆ DUG~b\n",
      "=    : uruk-iii ◆ P448701 ◆ 42 ◆ AB~a\n",
      "=    : uruk-iii ◆ P448701 ◆ 42 ◆ APIN~a\n",
      "=    : uruk-iii ◆ P448701 ◆ 42 ◆ NUN~a\n",
      "=    : uruk-iii ◆ P448701 ◆ 45 ◆ SZE~a\n",
      "=    : uruk-iii ◆ P448701 ◆ 45 ◆ NUN~a\n",
      "=    : uruk-iii ◆ P448702 ◆ 56 ◆ KA~a\n",
      "=    : uruk-iii ◆ P448702 ◆ 57 ◆ KASZ~b\n",
      "=    : uruk-iii ◆ P448702 ◆ 57 ◆ NUN~a\n",
      "=    : uruk-iii ◆ P448702 ◆ 58 ◆ KASZ~a\n",
      "=    : uruk-iii ◆ P448702 ◆ 59 ◆ 2(N39~a)\n",
      "=    : uruk-iii ◆ P448702 ◆ 63 ◆ SUKUD@v\n",
      "=    : uruk-iii ◆ P471695 ◆ 92 ◆ APIN~a\n",
      "=    : uruk-iii ◆ P471695 ◆ 92 ◆ UR4~a\n",
      "=    : uruk-iii ◆ P471695 ◆ 93 ◆ EN~a\n",
      "=    : uruk-iii ◆ P471695 ◆ 94 ◆ BAN~b\n",
      "=    : uruk-iii ◆ P471695 ◆ 94 ◆ KASZ~c\n",
      "=    : uruk-iii ◆ P471695 ◆ 95 ◆ KI@n\n",
      "=    : uruk-iii ◆ P471695 ◆ 97 ◆ PAP~a\n",
      "=     and 31847 more\n",
      "Number of results: TF 31867; GREP 31867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepVarMod,\n",
    "    tfVarMod,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flags\n",
    "\n",
    "We have several features for flags: \n",
    "\n",
    "mark | feature | comments\n",
    "----|---\n",
    "`*`|*collation* | not encountered in uruk iii-iv\n",
    "`#`|*damage*\n",
    "`?`|*uncertain*\n",
    "`!`|*remarkable*\n",
    "`!(`ggg`)`|*written*\n",
    "\n",
    "#### A bit of research\n",
    "We start by surveying the possible values, including on which node types they occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:15.714365Z",
     "start_time": "2018-03-01T13:09:15.696703Z"
    }
   },
   "outputs": [],
   "source": [
    "flagFeatures = '''\n",
    "    damage\n",
    "    remarkable\n",
    "    written\n",
    "    uncertain\n",
    "'''.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:18.606745Z",
     "start_time": "2018-03-01T13:09:17.254026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19946 x sign-damage-1\n",
      "  3707 x sign-uncertain-1\n",
      "  1045 x quad-damage-1\n",
      "   319 x quad-uncertain-1\n",
      "    10 x sign-remarkable-1\n",
      "     2 x sign-written-KASKAL\n",
      "     1 x sign-written-GURUSZ~a\n",
      "     1 x sign-written-IB~a\n"
     ]
    }
   ],
   "source": [
    "flagNodeOverview = collections.Counter()\n",
    "flagNodeTypes = set()\n",
    "\n",
    "for n in N():\n",
    "    for ft in flagFeatures:\n",
    "        value = Fs(ft).v(n)\n",
    "        if not value: continue\n",
    "        nType = F.otype.v(n)\n",
    "        flagNodeTypes.add(nType)\n",
    "        flagNodeOverview[f'{nType}-{ft}-{value}'] += 1\n",
    "for (combi, amount) in sorted(flagNodeOverview.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f'{amount:>6} x {combi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see whether there are any cooccurrences of flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:22.425348Z",
     "start_time": "2018-03-01T13:09:21.084479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125995 x     *     -    *     -    *     -    *     \n",
      " 18386 x   damage  -    *     -    *     -    *     \n",
      "  2605 x   damage  -    *     -    *     -uncertain \n",
      "  1420 x     *     -    *     -    *     -uncertain \n",
      "    10 x     *     -remarkable-    *     -    *     \n",
      "     3 x     *     -    *     - written  -    *     \n",
      "     1 x     *     -    *     - written  -uncertain \n"
     ]
    }
   ],
   "source": [
    "flagCombis = collections.Counter()\n",
    "\n",
    "for n in N():\n",
    "    if F.otype.v(n) not in flagNodeTypes:\n",
    "        continue\n",
    "    values = []\n",
    "    for ft in flagFeatures:\n",
    "        rawValue = Fs(ft).v(n)\n",
    "        value = f'{\"*\":^10}' if rawValue is None else f'{ft:^10}' if rawValue else f'{\"\":^10}'\n",
    "        values.append(value)\n",
    "\n",
    "    combi = '-'.join(values)\n",
    "    flagCombis[combi] += 1\n",
    "\n",
    "for (combi, amount) in sorted(flagCombis.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f'{amount:>6} x {combi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to address the question about order of flags.\n",
    "\n",
    "A quick inspection in the corpus yields:\n",
    "\n",
    "* damage-uncertain (`#?`) and uncertain-damage (`?#`), but the latter is very rare and all cases\n",
    "  occur in the diagnostics;\n",
    "* uncertain-remarkable (`?!`) does not occur, and remarkable-written-uncertain (`!(`ggg`)?` does occur.\n",
    "\n",
    "Based on this observation, and assuming that the order between *damage* and *uncertain* is not relevant,\n",
    "we produce flags always in the order:\n",
    "\n",
    "* *damage* *remarkable* *written* *uncertain*\n",
    "\n",
    "When grepping, we have to normalize `?#` to `#?`.\n",
    "\n",
    "There is one weird case, diagnosed by the conversion, in tablet P471687:\n",
    "\n",
    "```\n",
    "C1. |DUGb+?|\n",
    "```\n",
    "\n",
    "Here we see an operator `+` of which the second operand `?` consists of a flag without a grapheme.\n",
    "This occurs only once, so I think it is a mistake.\n",
    "\n",
    "Yet we'll find it when we search with TF, so we exclude it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:24.318460Z",
     "start_time": "2018-03-01T13:09:24.281408Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfFlags():\n",
    "    flags = []\n",
    "    for n in F.otype.s('sign'):\n",
    "        values = [Fs(ft).v(n) for ft in flagFeatures]\n",
    "        if all(value is None for value in values):\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        sign = f\"{CUNEI.atfFromSign(n, flags=True)}\"\n",
    "        if sign == '?':\n",
    "            print(f'TF: grapheme-less flag skipped in \"{line}\"')\n",
    "            continue\n",
    "        flags.append((F.period.v(t), tablet, F.srcLnNum.v(case), f\"{CUNEI.atfFromSign(n, flags=True)}\"))\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:25.296349Z",
     "start_time": "2018-03-01T13:09:25.277718Z"
    }
   },
   "outputs": [],
   "source": [
    "flagDetect = f'''\n",
    "(?:\n",
    "    {lineNumDetect}\n",
    "    (\n",
    "        .*\n",
    "        [!?#]\n",
    "        .*\n",
    "    )\n",
    ")\n",
    "'''\n",
    "\n",
    "flagsPat = '''\n",
    "(?:\n",
    "        (?:\n",
    "            !\\([^)]*\\)\n",
    "        )\n",
    "    |\n",
    "        [!#?]\n",
    ")\n",
    "'''\n",
    "\n",
    "graphemeFlagPat = f'''\n",
    "(?:\n",
    "        (?:\n",
    "            [0-9N]+\n",
    "            \\(\n",
    "                [^)]+\n",
    "            \\)\n",
    "            {flagsPat}+\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            [A-Z0-9~@a-wyz\\'-]+\n",
    "            {flagsPat}+\n",
    "        )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:09:26.160846Z",
     "start_time": "2018-03-01T13:09:26.123871Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepFlags(gen):\n",
    "    flagsRe = re.compile(flagDetect, re.X)\n",
    "    graphemePat = re.compile(graphemeFlagPat, re.X)\n",
    "\n",
    "    flags = []\n",
    "\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        line = tweakLine(line)\n",
    "        line = tweakBeforeGrep(line.strip())\n",
    "\n",
    "        match = flagsRe.match(line)\n",
    "        if match:\n",
    "            material = match.group(1)\n",
    "            graphemes = graphemePat.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                grapheme = graphemeTweaks(grapheme)\n",
    "                flags.append((period, tablet, ln, grapheme))\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:11.722095Z",
     "start_time": "2018-03-01T13:10:09.284263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"@inversum\" => \"@v\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: tweak \"KI@\" => \"KI#\"\n",
      "GREP: tweak \"(1N\" => \"1(N\"\n",
      "GREP: \"1.1(\" => \"1. 1(\"\n",
      "GREP: double prime replaced by single one\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: tweak \"U2@~b\" => \"U2~b\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "IDENTICAL: all 21246 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ SANGA~a?\n",
      "=    : uruk-iii ◆ P448702 ◆ 58 ◆ KASZ~a?\n",
      "=    : uruk-iii ◆ P448702 ◆ 59 ◆ 6(N14)#?\n",
      "=    : uruk-iii ◆ P448702 ◆ 63 ◆ SUKUD@v?\n",
      "=    : uruk-iii ◆ P471695 ◆ 105 ◆ ISZ~a#?\n",
      "=    : uruk-iii ◆ P471695 ◆ 111 ◆ 6(N01)#\n",
      "=    : uruk-iii ◆ P482082 ◆ 120 ◆ 4(N14)#\n",
      "=    : uruk-iii ◆ P482082 ◆ 121 ◆ 2(N14)#\n",
      "=    : uruk-iii ◆ P482083 ◆ 133 ◆ 1(N14)#\n",
      "=    : uruk-iii ◆ P482083 ◆ 135 ◆ KASZ~b?\n",
      "=    : uruk-iii ◆ P504412 ◆ 176 ◆ MASZ2?\n",
      "=    : uruk-iii ◆ P504412 ◆ 177 ◆ X?\n",
      "=    : uruk-iii ◆ P504412 ◆ 179 ◆ X?\n",
      "=    : uruk-iii ◆ P504412 ◆ 182 ◆ GI4~a#\n",
      "=    : uruk-iii ◆ P504412 ◆ 183 ◆ SAL?\n",
      "=    : uruk-iii ◆ P006438 ◆ 213 ◆ RAD~a#\n",
      "=    : uruk-iii ◆ P006438 ◆ 217 ◆ LAL2~a#?\n",
      "=    : uruk-iii ◆ P006438 ◆ 217 ◆ NIM~b2#?\n",
      "=    : uruk-iii ◆ P000014 ◆ 229 ◆ SZUBUR#\n",
      "=    : uruk-iii ◆ P000014 ◆ 230 ◆ KAB#?\n",
      "=     and 21226 more\n",
      "Number of results: TF 21246; GREP 21246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepFlags,\n",
    "    tfFlags,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All signs\n",
    "\n",
    "Now it is time to do a rigorous comparison of all signs in the transcriptions and in TF.\n",
    "\n",
    "Up till now we included only signs that had primes, variants, modifiers or flags attached to them.\n",
    "Now we extend the comparison to all of them.\n",
    "\n",
    "We still ignore the quad structures with operators and the bracketing of quads (clusters).\n",
    "But we do draw their component signs into the comparison.\n",
    "\n",
    "This comparison lists all signs in textual order, in TF and in GREP, and compares the two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:23.335121Z",
     "start_time": "2018-03-01T13:10:23.306293Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfSigns():\n",
    "    signs = []\n",
    "    for n in F.otype.s('sign'):\n",
    "        if F.grapheme.v(n) == '':\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        sign = f\"{CUNEI.atfFromSign(n, flags=True)}\"\n",
    "        if sign == '?':\n",
    "            print(f'TF: grapheme-less flag skipped in \"{line}\"')\n",
    "            continue\n",
    "        signs.append((F.period.v(t), tablet, F.srcLnNum.v(case), sign))\n",
    "    return signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The regular expression that greps all graphemes from the transcription is quite daunting.\n",
    "Comapare this with the relative easy by which you get all this from the text-fabric representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:25.516885Z",
     "start_time": "2018-03-01T13:10:25.495007Z"
    }
   },
   "outputs": [],
   "source": [
    "smallPat = '''\n",
    "(?:\n",
    "    [A-Zn]\n",
    ")\n",
    "'''\n",
    "\n",
    "signDetect = f'''\n",
    "(?:\n",
    "    {lineNumDetect}\n",
    "    (.*)\n",
    ")\n",
    "'''\n",
    "\n",
    "flagsModVarPat = '''\n",
    "(?:\n",
    "        (?:\n",
    "            !\\([^)]*\\)\n",
    "        )\n",
    "    |\n",
    "        [!#?]\n",
    "    |\n",
    "        (?:\n",
    "            @[A-WYZa-wyz]+\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            ~[A-WYZa-wyz0-9]+\n",
    "        )\n",
    ")\n",
    "'''\n",
    "\n",
    "graphemePat = f'''\n",
    "(?:\n",
    "        (?:\n",
    "            \\.\\.\\.                        # three dots, mostly in [...]\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            [0-9N]+\\([^)]+\\)               # a repeat, e.g. 5(N024)\n",
    "            {flagsModVarPat}*\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            [A-Z0-9a-wyzû\\'-]{{2,}}       # a plain grapheme, e.g. GA'AR\n",
    "            {flagsModVarPat}*\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            {smallPat}                    # a single letter grapheme: X or n, mostly in [n]\n",
    "            {flagsModVarPat}*\n",
    "        )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:26.726294Z",
     "start_time": "2018-03-01T13:10:26.691200Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepSigns(gen):\n",
    "    signRe = re.compile(signDetect, re.X)\n",
    "    graphemeRe = re.compile(graphemePat, re.X)\n",
    "\n",
    "    signs = []\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        line = tweakLine(line)\n",
    "        match = signRe.match(line)\n",
    "        if match:\n",
    "            material = match.group(1).strip()\n",
    "            material = tweakBeforeGrep(material)\n",
    "            graphemes = graphemeRe.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                grapheme = graphemeTweaks(grapheme)\n",
    "                signs.append((period, tablet, ln, grapheme))\n",
    "    return signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next one will take 5-10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:40.299755Z",
     "start_time": "2018-03-01T13:10:33.913056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"@inversum\" => \"@v\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: tweak \"KI@\" => \"KI#\"\n",
      "GREP: tweak \"(1N\" => \"1(N\"\n",
      "GREP: \"1.1(\" => \"1. 1(\"\n",
      "GREP: double prime replaced by single one\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: tweak \"U2@~b\" => \"U2~b\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "IDENTICAL: all 127643 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ ...\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ X\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ X\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ 3(N14)\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ X\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ SANGA~a?\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ ...\n",
      "=    : uruk-iii ◆ P006428 ◆ 16 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 16 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 17 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 17 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 19 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 19 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 20 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 20 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 22 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 22 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 23 ◆ 3(N14)\n",
      "=    : uruk-iii ◆ P006428 ◆ 23 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 24 ◆ 1(N14)\n",
      "=     and 127623 more\n",
      "Number of results: TF 127643; GREP 127643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepSigns,\n",
    "    tfSigns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quads\n",
    "\n",
    "Quads are the compositions of signs by operators. Operators can be applied several times,\n",
    "so quads themselves can be the building blocks for other quads.\n",
    "\n",
    "In transcription, the outermost quads are what you get if you split the transcription\n",
    "line (the part after the line number) of white space.\n",
    "\n",
    "Normally, if an outer quad is complex, it is written between `| |`.\n",
    "\n",
    "Quads and sub-quads may be augmented with variants, modifiers and flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer complex quads\n",
    "\n",
    "Let us first check whether we see the same outer quads by TF as by GREP.\n",
    "We are not interested in the simple quads.\n",
    "They are the signs, and we have already checked them.\n",
    "So we look for all outer complex quads, i.e. quads with an operator in them,\n",
    "such as `x` or `+` or `.`\n",
    "\n",
    "In the transcriptions, complex outer quads should be surrounded by `| |`.\n",
    "However, in this corpus there are a few cases where one or both of the surrounding\n",
    "`|` are missing.\n",
    "\n",
    "We make an explicit list of these cases, and will correct the GREP results for these.\n",
    "\n",
    "In TF, outer quads are characterized by not having an incoming `sub` edge from an other quad.\n",
    "Remember that edges connect the complex quads with their component quads.\n",
    "\n",
    "**N.B.:** There are also `sub` edges between clusters and the quads that they contain,\n",
    "so when we check for incoming `sub` edges, we must only count the ones coming from a quad.\n",
    "\n",
    "In TF we recognize a complex quad as one having an outgoing `sub` edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:46.345229Z",
     "start_time": "2018-03-01T13:10:46.313363Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfQuads():\n",
    "    quads = []\n",
    "    for n in F.otype.s('quad'):\n",
    "        if any(\n",
    "            F.otype.v(parent) == 'quad' for parent in E.sub.t(n)\n",
    "        ) or not E.sub.f(n):\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        quad = f\"{CUNEI.atfFromQuad(n, flags=True)}\"\n",
    "        quads.append((F.period.v(t), tablet, F.srcLnNum.v(case), quad))\n",
    "    return quads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants: inside or outside?\n",
    "\n",
    "It seems that in the transcriptions there are two ways to augment an outer quad with a variant:\n",
    "\n",
    "`|(QQxRR)~a|` versus `|QQxRR|~a`\n",
    "\n",
    "Both occur\n",
    "\n",
    "In P000783 we have\n",
    "```\n",
    "6. 2(N14) , |(SZAxHI@g~a)~b|\n",
    "```\n",
    "\n",
    "whereas in P252180 we have\n",
    "\n",
    "```\n",
    "4. UB URI3~a |BAD+DISZ|~a EN~a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants: extra level of brackets?\n",
    "\n",
    "What binds stronger: an operator, or a variant?\n",
    "Consider the following line of P006326:\n",
    "\n",
    "```\n",
    "1.b2. 2(N14)# 3(N01)# , |GA2~a1x(SUKUD&SUKUD)~b|#\n",
    "```\n",
    "\n",
    "If variants bind stronger than operators, we must read the big quad as\n",
    "\n",
    "```\n",
    "|GA2~a1x((SUKUD&SUKUD)~b)|#\n",
    "```\n",
    "\n",
    "If operators bind stronger, we need to read it as\n",
    "\n",
    "```\n",
    "|(GA2~a1x(SUKUD&SUKUD))~b|#\n",
    "```\n",
    "\n",
    "A variant is unary operator, whereas an operator is a binary operator,\n",
    "so it makes much more sense to opt for the first interpretation.\n",
    "\n",
    "However, in the corpus we see cases where there are unnecessary brackets\n",
    "for variants. See the following line in P002269:\n",
    "\n",
    "```\n",
    "1.a. 1(N01) , |NINDA2x((UDU~a+TAR)~b)| KU6~a\n",
    "```\n",
    "\n",
    "Here the brackets around `UDU~a+TAR)~b` are unneccesary. \n",
    "If variants bind stronger, then this should have the same meaning:\n",
    "\n",
    "```\n",
    "1.a. 1(N01) , |NINDA2x(UDU~a+TAR)~b| KU6~a\n",
    "```\n",
    "\n",
    "Since both bracketings occur, and since TF stores the abstract structure, and not\n",
    "the surface bracketing, there is no way for TF to remember the bracketing.\n",
    "\n",
    "We could add a feature to remember this, but as the meaning is not changed by extra\n",
    "brackets, it is silly to do so.\n",
    "\n",
    "Hence, after GREPPING, we will remove these kinds of brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More bracket issues\n",
    "\n",
    "In P005112 we find a line\n",
    "\n",
    "```\n",
    "1. [...] , |U4x2(N01).(2(N14).1(N08))| EN~a PA~a\n",
    "```\n",
    "\n",
    "The quad seems the composition of three subquads:\n",
    "`U4` and `2(N01)` and `2(N14).1(N08)`.\n",
    "\n",
    "But whereas it has been made explicit in which order the `.` operator should be applied,\n",
    "we do not know that for `x` versus `.`\n",
    "\n",
    "There are three possible meanings of `GxH.J`\n",
    "\n",
    "1. `Gx(H.J)`\n",
    "2. `(GxH).J`\n",
    "3. the order is immaterial, the previous meanings are equal\n",
    "\n",
    "Given the fact that there are no brackets, I opt for the third possibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most complex quads\n",
    "\n",
    "Here are a few really intricate quads:\n",
    "\n",
    "In P005573, column 2, line 2b2\n",
    "\n",
    "P005381 2 1\n",
    "\n",
    "Let's retrieve them using with a bit of Text-Fabric agility:\n",
    "\n",
    "```\n",
    "2.b2. , (|(HIx1(N57))&(HI+1(N57))| EN~a)a \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:49.739481Z",
     "start_time": "2018-03-01T13:10:49.716841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.b2. , (|(HIx1(N57))&(HI+1(N57))| EN~a)a \n",
      "1. 3(N04) , |GISZ.TE| GAR |SZU2.((HI+1(N57))+(HI+1(N57)))| GI4~a\n"
     ]
    }
   ],
   "source": [
    "for passage in (\n",
    "    ('P005573', 'obverse:2', '2', '2b2'),\n",
    "    ('P005381', 'obverse:2', '1'),\n",
    "):\n",
    "    line = T.nodeFromSection(passage[0:3])\n",
    "    cases = L.d(line, otype='case')\n",
    "    caseNr = passage[3] if len(passage) >= 4 else None\n",
    "    for case in cases:\n",
    "        if not caseNr or F.fullNumber.v(case) == caseNr:\n",
    "            print(F.srcLn.v(case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:51.425926Z",
     "start_time": "2018-03-01T13:10:51.405465Z"
    }
   },
   "outputs": [],
   "source": [
    "quadVarPat = '''\n",
    "(?:\n",
    "    \\|\n",
    "        ([^|]+)\n",
    "    \\|\n",
    "    ~\n",
    "        ([a-wyz0-9A-WYZ]+)\n",
    ")\n",
    "'''\n",
    "\n",
    "quadVarRe = re.compile(quadVarPat, re.X)\n",
    "\n",
    "def quadVarReplace(match):\n",
    "    quad = match.group(1)\n",
    "    var = match.group(2)\n",
    "    print(f'GREP: pulling variant inside quad: \"|{quad}|~{var}\" => |({quad})~{var}|')\n",
    "    return f'|({quad})~{var}|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:52.559410Z",
     "start_time": "2018-03-01T13:10:52.533558Z"
    }
   },
   "outputs": [],
   "source": [
    "quadBracketPat = '''\n",
    "(?:\n",
    "    \\(\n",
    "        \\(\n",
    "            ([^() ]+)\n",
    "        \\)\n",
    "        ~\n",
    "        ([a-wyz0-9A-WYZ]+)\n",
    "    \\)\n",
    ")\n",
    "'''\n",
    "\n",
    "quadBracketRe = re.compile(quadBracketPat, re.X)\n",
    "\n",
    "def quadBracketReplace(match):\n",
    "    quad = match.group(1)\n",
    "    var = match.group(2)\n",
    "    print(f'GREP: removing brackets around a variant: \"(({quad})~{var})\" => ({quad})~{var}')\n",
    "    return f'({quad})~{var}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:53.643820Z",
     "start_time": "2018-03-01T13:10:53.629065Z"
    }
   },
   "outputs": [],
   "source": [
    "operatorPat = '''\n",
    "(?:\n",
    "    [x%&.:+]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:55.046385Z",
     "start_time": "2018-03-01T13:10:55.026270Z"
    }
   },
   "outputs": [],
   "source": [
    "MISSING_PIPES = {\n",
    "       ('uruk-iii', 16730): '|SZE~a+NAM2|',\n",
    "       ('uruk-iii', 16896): '|EN~a+NUN~a| UTUL~a',\n",
    "       ('uruk-iii', 16962): 'GAL~a |EZEN~b+6N57|',\n",
    "       ('uruk-iii', 25956): '|GISZ+SZU2~a| |SZE~a+SZE~a|',\n",
    "       ('uruk-iii', 26281): '|GISZ.tenû| E2~b',\n",
    "       ('uruk-iii', 31523): '|MUD3.gunû|',\n",
    "       ('uruk-iii', 40186): '|SZUBUR+1(N57)|',\n",
    "       ('uruk-iii', 40188): '|SZUBUR+2(N57)|',\n",
    "       ('uruk-iii', 45102): '|ZATU737xDI| SANGA~a',\n",
    "       ('uruk-iii', 45533): '|SZE~a+NAM2| A',\n",
    "       ('uruk-iii', 52806): '1(N01) , UDUNITA~a |IDIN+1(N57)|',\n",
    "       ('uruk-iii', 55110): '|U4+1(N08)| |GI+A#|',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:56.028103Z",
     "start_time": "2018-03-01T13:10:56.012148Z"
    }
   },
   "outputs": [],
   "source": [
    "complexQuadDetect = f'''\n",
    "(?:\n",
    "    {lineNumDetect}\n",
    "    (\n",
    "        .*\n",
    "        \\S\n",
    "        {operatorPat}\n",
    "        \\S\n",
    "        .*\n",
    "    )\n",
    ")\n",
    "'''\n",
    "\n",
    "complexQuadPat = f'''\n",
    "(?:\n",
    "    \\|\n",
    "        \\S+\n",
    "        {operatorPat}\n",
    "        \\S+\n",
    "    \\|\n",
    "    {flagsModVarPat}*\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:57.082892Z",
     "start_time": "2018-03-01T13:10:57.065052Z"
    }
   },
   "outputs": [],
   "source": [
    "quadRe = re.compile(complexQuadPat, re.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:57.966134Z",
     "start_time": "2018-03-01T13:10:57.925478Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepQuads(gen):\n",
    "    quadsRe = re.compile(complexQuadDetect, re.X)\n",
    "    quadRe = re.compile(complexQuadPat, re.X)\n",
    "\n",
    "    quads = []\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        line = tweakLine(line)\n",
    "        material = MISSING_PIPES.get((period, ln), None)\n",
    "        if material == None:\n",
    "            match = quadsRe.match(line)\n",
    "            if match:\n",
    "                material = match.group(1).strip()\n",
    "                material = tweakBeforeGrep(material)\n",
    "        if material is not None:\n",
    "            for quad in quadRe.findall(material):\n",
    "                quad = graphemeTweaks(quad)\n",
    "                quad = quadVarRe.sub(quadVarReplace, quad)\n",
    "                quad = quadBracketRe.sub(quadBracketReplace, quad)\n",
    "                quads.append((period, tablet, ln, quad))\n",
    "    return quads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:10:59.645595Z",
     "start_time": "2018-03-01T13:10:59.004746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"1.1(\" => \"1. 1(\"\n",
      "GREP: removing brackets around a variant: \"((UDU~a+TAR)~b)\" => (UDU~a+TAR)~b\n",
      "GREP: removing brackets around a variant: \"((UDU~axTAR)~a)\" => (UDU~axTAR)~a\n",
      "GREP: pulling variant inside quad: \"|BAD+DISZ|~a\" => |(BAD+DISZ)~a|\n",
      "HEAD : period ◆ tablet ◆ ln ◆ quad\n",
      "IDENTICAL: all 3623 items\n",
      "=    : uruk-iii ◆ P006428 ◆ 26 ◆ |DUG~bx1(N57)|\n",
      "=    : uruk-iii ◆ P448702 ◆ 63 ◆ |U4x1(N01)|\n",
      "=    : uruk-iii ◆ P448703 ◆ 76 ◆ |U4.1(N08)|\n",
      "=    : uruk-iii ◆ P448703 ◆ 77 ◆ |U4.1(N08)|\n",
      "=    : uruk-iii ◆ P448703 ◆ 78 ◆ |U4.1(N08)|#\n",
      "=    : uruk-iii ◆ P448703 ◆ 78 ◆ |GI&GI|#\n",
      "=    : uruk-iii ◆ P448703 ◆ 79 ◆ |U4.1(N08)|#\n",
      "=    : uruk-iii ◆ P448703 ◆ 80 ◆ |U4.1(N08)|\n",
      "=    : uruk-iii ◆ P482083 ◆ 135 ◆ |U4x3(N01)|\n",
      "=    : uruk-iii ◆ P499393 ◆ 153 ◆ |LAGAB~bxX|\n",
      "=    : uruk-iii ◆ P499393 ◆ 155 ◆ |MUSZEN.X|\n",
      "=    : uruk-iii ◆ P504412 ◆ 177 ◆ |SILA3~dxNI~a|\n",
      "=    : uruk-iii ◆ P006438 ◆ 205 ◆ |AB~axSUKKAL|\n",
      "=    : uruk-iii ◆ P000014 ◆ 226 ◆ |1(N57).SZUBUR|\n",
      "=    : uruk-iii ◆ P000014 ◆ 228 ◆ |2(N57).SZUBUR|\n",
      "=    : uruk-iii ◆ P000014 ◆ 231 ◆ |SILA3~axGARA2~a|#?\n",
      "=    : uruk-iii ◆ P000014 ◆ 267 ◆ |BU~a+DU6~a|\n",
      "=    : uruk-iii ◆ P000014 ◆ 288 ◆ |3(N57).SZUBUR|\n",
      "=    : uruk-iii ◆ P000456 ◆ 307 ◆ |1(N57).SZUBUR|\n",
      "=    : uruk-iii ◆ P002718 ◆ 333 ◆ |SZE~a&SZE~a|#?\n",
      "=     and 3603 more\n",
      "Number of results: TF 3623; GREP 3623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('quad',),\n",
    "    grepQuads,\n",
    "    tfQuads,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters\n",
    "\n",
    "Clusters are groupings of outermost quads.\n",
    "The transcription uses a variety of brackets for several kinds of clustering.\n",
    "\n",
    "In our corpus we encounter:\n",
    "\n",
    "* `[ ]` uncertain\n",
    "* `( )` proper names\n",
    "* `< >` supplied material\n",
    "\n",
    "Clusters may be nested.\n",
    "\n",
    "Most clusters are trivial: `[...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:11:02.115078Z",
     "start_time": "2018-03-01T13:11:02.089198Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfClusters():\n",
    "    clusters = []\n",
    "    for n in F.otype.s('cluster'):\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        cluster = f\"{CUNEI.atfFromCluster(n)}\"\n",
    "        clusters.append((F.period.v(t), tablet, F.srcLnNum.v(case), cluster))\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:11:03.006188Z",
     "start_time": "2018-03-01T13:11:02.982276Z"
    }
   },
   "outputs": [],
   "source": [
    "clusterOpen = '[(\\[<]'\n",
    "clusterClose = '[)\\]>]'\n",
    "openCluster = set('[(<')\n",
    "\n",
    "clusterDetect = f'''\n",
    "(?:\n",
    "    {lineNumDetect}\n",
    "    (\n",
    "        (?:\n",
    "                {clusterOpen}\n",
    "            |\n",
    "                (?:\n",
    "                    .*\\s\n",
    "                    {clusterOpen}\n",
    "                )\n",
    "        )\n",
    "        .*\n",
    "    )\n",
    ")\n",
    "'''\n",
    "\n",
    "nextMaterialPat = f'''\n",
    "(?:\n",
    "    \\s{clusterOpen}\n",
    ")\n",
    "'''\n",
    "\n",
    "clusterPat = f'''\n",
    "(?:\n",
    "    {clusterOpen}\n",
    "    (?:\n",
    "        (?:\n",
    "                {complexQuadPat}\n",
    "            |\n",
    "                {graphemePat}\n",
    "        )\n",
    "    )\n",
    "    (?:\n",
    "        \\s\n",
    "        (?:\n",
    "                {complexQuadPat}\n",
    "            |\n",
    "                {graphemePat}\n",
    "        )\n",
    "    )*\n",
    "    {clusterClose}\n",
    "    a?\n",
    ")\n",
    "'''\n",
    "\n",
    "cluster2Pat = f'''\n",
    "(?:\n",
    "    {clusterOpen}\n",
    "    (?:\n",
    "        (?:\n",
    "                {clusterPat}\n",
    "            |\n",
    "                {complexQuadPat}\n",
    "            |\n",
    "                {graphemePat}\n",
    "        )\n",
    "    )\n",
    "    (?:\n",
    "        \\s\n",
    "        (?:\n",
    "                {clusterPat}\n",
    "            |\n",
    "                {complexQuadPat}\n",
    "            |\n",
    "                {graphemePat}\n",
    "        )\n",
    "    )*\n",
    "    {clusterClose}\n",
    "    a?\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:11:04.071298Z",
     "start_time": "2018-03-01T13:11:03.936694Z"
    }
   },
   "outputs": [],
   "source": [
    "clustersRe = re.compile(clusterDetect, re.X)\n",
    "clusterRe = re.compile(cluster2Pat, re.X)\n",
    "nextRe = re.compile(nextMaterialPat, re.X)\n",
    "\n",
    "def getOuterClusters(material):\n",
    "    clusters = []\n",
    "    rest = 0\n",
    "    while rest < len(material):        \n",
    "        if material[rest] in openCluster:\n",
    "            clusterMatch = clusterRe.match(material[rest:])\n",
    "            if clusterMatch:\n",
    "                clusterRaw = clusterMatch.group(0)\n",
    "                clusters.append(clusterRaw)\n",
    "                clusters.extend(getOuterClusters(clusterRaw[1:-1]))\n",
    "                rest += len(clusterRaw)\n",
    "            else:\n",
    "                rest += 1\n",
    "        else:\n",
    "            nextMatch = nextRe.search(material[rest:])\n",
    "            if nextMatch:\n",
    "                rest += nextMatch.start() + 1\n",
    "            else:\n",
    "                break\n",
    "    return clusters\n",
    "\n",
    "def grepClusters(gen):\n",
    "    clusters = []\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        line = tweakLine(line)\n",
    "        line = tweakBeforeGrep(line)\n",
    "        line = line.replace(' , ', ' ').replace(',', '')\n",
    "\n",
    "        match = clustersRe.match(line)\n",
    "        if match:\n",
    "            material = match.group(1).strip()\n",
    "            clustersRaw = getOuterClusters(material)\n",
    "            for clusterRaw in clustersRaw:\n",
    "                cluster = graphemeTweaks(clusterRaw)\n",
    "                clusters.append((period, tablet, ln, cluster))\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T13:11:07.738981Z",
     "start_time": "2018-03-01T13:11:05.122289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: tweak \"(1N\" => \"1(N\"\n",
      "GREP: \"1.1(\" => \"1. 1(\"\n",
      "GREP: tweak \"U2@~b\" => \"U2~b\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ cluster\n",
      "IDENTICAL: all 32752 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ [...]\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ [...]\n",
      "=    : uruk-iii ◆ P006428 ◆ 33 ◆ [...]\n",
      "=    : uruk-iii ◆ P448702 ◆ 56 ◆ [n]\n",
      "=    : uruk-iii ◆ P448702 ◆ 56 ◆ [...]\n",
      "=    : uruk-iii ◆ P448702 ◆ 57 ◆ [n]\n",
      "=    : uruk-iii ◆ P448702 ◆ 59 ◆ [n]\n",
      "=    : uruk-iii ◆ P448702 ◆ 59 ◆ [...]\n",
      "=    : uruk-iii ◆ P471695 ◆ 93 ◆ (EN~a DU ZATU759)a\n",
      "=    : uruk-iii ◆ P471695 ◆ 94 ◆ (BAN~b KASZ~c)a\n",
      "=    : uruk-iii ◆ P471695 ◆ 95 ◆ (KI@n SAG)a\n",
      "=    : uruk-iii ◆ P471695 ◆ 96 ◆ [...]\n",
      "=    : uruk-iii ◆ P471695 ◆ 97 ◆ (3(N57) PAP~a)a\n",
      "=    : uruk-iii ◆ P471695 ◆ 98 ◆ (SZU KI X)a\n",
      "=    : uruk-iii ◆ P471695 ◆ 100 ◆ (EN~a AN EZINU~d)a\n",
      "=    : uruk-iii ◆ P471695 ◆ 101 ◆ (IDIGNA [...])a\n",
      "=    : uruk-iii ◆ P471695 ◆ 101 ◆ [...]\n",
      "=    : uruk-iii ◆ P471695 ◆ 106 ◆ (PAP~a GIR3~c)a\n",
      "=    : uruk-iii ◆ P471695 ◆ 111 ◆ [1(N14)]\n",
      "=    : uruk-iii ◆ P471695 ◆ 111 ◆ [...]\n",
      "=     and 32732 more\n",
      "Number of results: TF 32752; GREP 32752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('cluster',),\n",
    "    grepClusters,\n",
    "    tfClusters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Here ends the checking.\n",
    "\n",
    "This notebook has tested all patterns and quantities found in the transcriptions.\n",
    "\n",
    "By a somewhat convoluted GREP we have extracted patterns from the sources.\n",
    "\n",
    "By somewhat contrived TF alchemy we have produced the same patterns from the Text-Fabric\n",
    "representation of the sources.\n",
    "\n",
    "Then we have made a rigorous comparison: we have checked wether both methods found exactly\n",
    "the same sequence of values.\n",
    "\n",
    "And yes, it is so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
