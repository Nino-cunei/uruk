{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Tablets\" data-toc-modified-id=\"Tablets-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Tablets</a></span></li><li><span><a href=\"#Faces\" data-toc-modified-id=\"Faces-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Faces</a></span></li><li><span><a href=\"#Columns\" data-toc-modified-id=\"Columns-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Columns</a></span></li><li><span><a href=\"#Lines\" data-toc-modified-id=\"Lines-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Lines</a></span></li><li><span><a href=\"#Graphemes\" data-toc-modified-id=\"Graphemes-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Graphemes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Primes\" data-toc-modified-id=\"Primes-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Primes</a></span></li><li><span><a href=\"#Variants-and-modifiers\" data-toc-modified-id=\"Variants-and-modifiers-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Variants and modifiers</a></span></li><li><span><a href=\"#Tweaks\" data-toc-modified-id=\"Tweaks-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Tweaks</a></span></li><li><span><a href=\"#Flags\" data-toc-modified-id=\"Flags-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Flags</a></span></li><li><span><a href=\"#All-signs\" data-toc-modified-id=\"All-signs-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>All signs</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks\n",
    "Various checks on the correctness of the transformation from ascii transcriptions to a text-fabric data set.\n",
    "\n",
    "The\n",
    "[diagnostics](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/diagnostics.tsv)\n",
    "of the transformation contains valueable issues that may be used to correct mistakes in the sources.\n",
    "Or, equally likely, they correspond to misunderstandings on my (Dirk's) part of the model\n",
    "that underlies the transcriptions.\n",
    "\n",
    "We will perform *grep* commands on the source files, and we will traverse node in Text-Fabric and collect information.\n",
    "\n",
    "Then we compare these sets of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:16:57.220178Z",
     "start_time": "2018-02-21T21:16:57.198139Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:16:57.877624Z",
     "start_time": "2018-02-21T21:16:57.852295Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os, collections, re\n",
    "from glob import glob\n",
    "from tf.fabric import Fabric\n",
    "from utils import Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:16:58.467892Z",
     "start_time": "2018-02-21T21:16:58.450777Z"
    }
   },
   "outputs": [],
   "source": [
    "REPO = '~/github/Dans-labs/Nino-cunei'\n",
    "SOURCE = 'uruk'\n",
    "VERSION = '0.1'\n",
    "CORPUS = f'{REPO}/tf/{SOURCE}/{VERSION}'\n",
    "SOURCE_DIR = os.path.expanduser(f'{REPO}/sources/cdli')\n",
    "TEMP_DIR = os.path.expanduser(f'{REPO}/_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:16:59.460126Z",
     "start_time": "2018-02-21T21:16:59.437414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.2.0\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "31 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=[CORPUS], modules=[''], silent=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:02.410264Z",
     "start_time": "2018-02-21T21:17:01.250263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.00s B catalogId            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B number               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.06s B grapheme             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.05s B srcLn                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B srcLnNum             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B prime                from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B repeat               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B variant              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B variantOuter         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifier             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierInner        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B modifierFirst        from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B damage               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B uncertain            from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B remarkable           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B written              from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B period               from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B name                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.02s B type                 from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B identifier           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B fullNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B origNumber           from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B badNumbering         from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s B op                   from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.05s B sub                  from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.01s B comments             from /Users/dirk/github/Dans-labs/Nino-cunei/tf/uruk/0.1\n",
      "   |     0.00s Feature overview: 26 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  1.14s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    grapheme prime repeat\n",
    "    variant variantOuter\n",
    "    modifier modifierInner modifierFirst\n",
    "    damage uncertain remarkable written\n",
    "    period name type identifier catalogId\n",
    "    number fullNumber origNumber badNumbering\n",
    "    srcLn srcLnNum\n",
    "    op sub comments\n",
    "''')\n",
    "api.makeAvailableIn(globals())\n",
    "COMP = Compare(api, SOURCE_DIR, TEMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tablets\n",
    "We check whether we have the same sequence of tablet numbers.\n",
    "In TF, the tablet number is stored in the feature `catalogId`.\n",
    "\n",
    "Note that we also check on the order of the tablets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:04.433466Z",
     "start_time": "2018-02-21T21:17:04.394650Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfTablets():\n",
    "    tablets = []\n",
    "    for t in F.otype.s('tablet'):\n",
    "        (tablet, column, line) = T.sectionFromNode(t)\n",
    "        tablets.append((F.period.v(t), tablet, F.srcLnNum.v(t), F.catalogId.v(t)))\n",
    "    return tablets\n",
    "\n",
    "def grepTablets(gen):\n",
    "    tablets = []\n",
    "    prevTablet = None\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            print(f'GREP: skipping duplicate tablet \"{tablet}\"')\n",
    "            continue\n",
    "        if tablet != prevTablet:\n",
    "            tablets.append((period, tablet, ln, tablet))\n",
    "        prevTablet = tablet\n",
    "    return tablets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:05.441022Z",
     "start_time": "2018-02-21T21:17:05.129858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: skipping duplicate tablet \"P002176\"\n",
      "GREP: skipping duplicate tablet \"P252175\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ tablet\n",
      "IDENTICAL: all 6396 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 1 ◆ P006427\n",
      "=    : uruk-iii ◆ P006428 ◆ 11 ◆ P006428\n",
      "=    : uruk-iii ◆ P448701 ◆ 36 ◆ P448701\n",
      "=    : uruk-iii ◆ P448702 ◆ 50 ◆ P448702\n",
      "=    : uruk-iii ◆ P448703 ◆ 71 ◆ P448703\n",
      "=    : uruk-iii ◆ P471695 ◆ 87 ◆ P471695\n",
      "=    : uruk-iii ◆ P482082 ◆ 114 ◆ P482082\n",
      "=    : uruk-iii ◆ P482083 ◆ 127 ◆ P482083\n",
      "=    : uruk-iii ◆ P499393 ◆ 147 ◆ P499393\n",
      "=    : uruk-iii ◆ P504412 ◆ 166 ◆ P504412\n",
      "=    : uruk-iii ◆ P504413 ◆ 189 ◆ P504413\n",
      "=    : uruk-iii ◆ P006438 ◆ 199 ◆ P006438\n",
      "=    : uruk-iii ◆ P000014 ◆ 220 ◆ P000014\n",
      "=    : uruk-iii ◆ P000456 ◆ 297 ◆ P000456\n",
      "=    : uruk-iii ◆ P002718 ◆ 326 ◆ P002718\n",
      "=    : uruk-iii ◆ P000021 ◆ 341 ◆ P000021\n",
      "=    : uruk-iii ◆ P000023 ◆ 374 ◆ P000023\n",
      "=    : uruk-iii ◆ P000025 ◆ 403 ◆ P000025\n",
      "=    : uruk-iii ◆ P000167 ◆ 500 ◆ P000167\n",
      "=    : uruk-iii ◆ P000453 ◆ 531 ◆ P000453\n",
      "=     and 6376 more\n",
      "Number of results: TF 6396; GREP 6396\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('tablet',),\n",
    "    grepTablets,\n",
    "    tfTablets,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faces\n",
    "\n",
    "We check whether we see the same faces with GREP and TF.\n",
    "\n",
    "Note that in TF we have inserted missing faces `@noface`.\n",
    "We leave them out again in the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:07.273131Z",
     "start_time": "2018-02-21T21:17:07.254896Z"
    }
   },
   "outputs": [],
   "source": [
    "FACES = set(\n",
    "    '''\n",
    "    obverse\n",
    "    reverse\n",
    "    top\n",
    "    bottom\n",
    "    left\n",
    "    seal\n",
    "    surface\n",
    "    edge\n",
    "'''.strip().split()\n",
    ")\n",
    "\n",
    "NOFACE = 'noface'\n",
    "\n",
    "facePat = re.compile('^@([a-z]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:08.777480Z",
     "start_time": "2018-02-21T21:17:08.749877Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfFaces():\n",
    "    faces = []\n",
    "    for tablet in F.otype.s('tablet'):\n",
    "        tabletName = F.catalogId.v(tablet)\n",
    "        period = F.period.v(tablet)\n",
    "        for face in L.d(tablet, otype='face'):\n",
    "            tp = F.type.v(face)\n",
    "            it = F.identifier.v(face) or None\n",
    "            ln = F.srcLnNum.v(face)\n",
    "            itStr = '' if it is None else f' {it}'\n",
    "            if tp != 'noface':\n",
    "                faces.append((period, tabletName, ln, f'@{tp}{itStr}'))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:09.860806Z",
     "start_time": "2018-02-21T21:17:09.839613Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepFaces(gen):\n",
    "    faces = []\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        match = facePat.match(line)\n",
    "        if match:\n",
    "            face = match.group(1)\n",
    "            if face in FACES:\n",
    "                faces.append((period, tablet, ln, line.strip()))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:11.347493Z",
     "start_time": "2018-02-21T21:17:10.894998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD : period ◆ tablet ◆ ln ◆ face\n",
      "IDENTICAL: all 9441 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 4 ◆ @obverse\n",
      "=    : uruk-iii ◆ P006428 ◆ 14 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448701 ◆ 39 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448701 ◆ 46 ◆ @reverse\n",
      "=    : uruk-iii ◆ P448702 ◆ 53 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448702 ◆ 67 ◆ @reverse\n",
      "=    : uruk-iii ◆ P448703 ◆ 74 ◆ @obverse\n",
      "=    : uruk-iii ◆ P448703 ◆ 83 ◆ @reverse\n",
      "=    : uruk-iii ◆ P471695 ◆ 90 ◆ @obverse\n",
      "=    : uruk-iii ◆ P471695 ◆ 109 ◆ @reverse\n",
      "=    : uruk-iii ◆ P482082 ◆ 117 ◆ @obverse\n",
      "=    : uruk-iii ◆ P482082 ◆ 123 ◆ @reverse\n",
      "=    : uruk-iii ◆ P482083 ◆ 130 ◆ @obverse\n",
      "=    : uruk-iii ◆ P482083 ◆ 143 ◆ @reverse\n",
      "=    : uruk-iii ◆ P499393 ◆ 150 ◆ @obverse\n",
      "=    : uruk-iii ◆ P499393 ◆ 162 ◆ @reverse\n",
      "=    : uruk-iii ◆ P504412 ◆ 169 ◆ @obverse\n",
      "=    : uruk-iii ◆ P504412 ◆ 185 ◆ @reverse\n",
      "=    : uruk-iii ◆ P504413 ◆ 192 ◆ @obverse\n",
      "=    : uruk-iii ◆ P504413 ◆ 195 ◆ @reverse\n",
      "=     and 9421 more\n",
      "Number of results: TF 9441; GREP 9441\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('face',),\n",
    "    grepFaces,\n",
    "    tfFaces,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns\n",
    "\n",
    "We check whether we see the same columns with GREP and TF.\n",
    "\n",
    "Note that in TF we have inserted missing columns as `@column 0`.\n",
    "We leave them out again in the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:13.760924Z",
     "start_time": "2018-02-21T21:17:13.728608Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfColumns():\n",
    "    columns = []\n",
    "    for tablet in F.otype.s('tablet'):\n",
    "        tabletName = F.catalogId.v(tablet)\n",
    "        period = F.period.v(tablet)\n",
    "        for face in L.d(tablet, otype='face'):\n",
    "            tp = F.type.v(face)\n",
    "            for column in L.d(face, otype='column'):\n",
    "                number = F.number.v(column)\n",
    "                prime = F.prime.v(column)\n",
    "                ln = F.srcLnNum.v(column)\n",
    "                primeStr = \"'\" if prime else ''\n",
    "                if number != '0':\n",
    "                    columns.append((period, tabletName, ln, tp, f'@column {number}{primeStr}'))\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:14.602607Z",
     "start_time": "2018-02-21T21:17:14.475408Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepColumns(gen):\n",
    "    columns = []\n",
    "    columnPat = re.compile('^@col')\n",
    "    correctPat = re.compile('^@([a-z]+)(\\s*)(\\S*)')\n",
    "    curFace = NOFACE\n",
    "    prevTablet = None\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        if tablet != prevTablet:\n",
    "            curFace = NOFACE\n",
    "        prevTablet = tablet\n",
    "\n",
    "        match = facePat.match(line)\n",
    "        if match:\n",
    "            face = match.group(1)\n",
    "            if face in FACES:\n",
    "                curFace = face\n",
    "\n",
    "        if columnPat.match(line):\n",
    "            if not line.startswith('@column '):\n",
    "                match = correctPat.match(line)\n",
    "                if match:\n",
    "                    colSpec = match.group(1)\n",
    "                    sep = match.group(2)\n",
    "                    colNum = match.group(3)\n",
    "                    line = f'@column {colNum}'\n",
    "                    print(f'GREP: corrected \"{colSpec}{sep}{colNum}\" => \"{line}\"')\n",
    "                else:\n",
    "                    print(f'GREP: found \"{line}\"')\n",
    "                \n",
    "            columns.append((period, tablet, ln, curFace, line.strip()))\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:15.835649Z",
     "start_time": "2018-02-21T21:17:15.093605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: corrected \"columm 4\" => \"@column 4\"\n",
      "GREP: corrected \"column3\" => \"@column 3\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ face ◆ column\n",
      "IDENTICAL: all 13123 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 5 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P006427 ◆ 7 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 15 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 18 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 21 ◆ obverse ◆ @column 3\n",
      "=    : uruk-iii ◆ P006428 ◆ 29 ◆ obverse ◆ @column 4\n",
      "=    : uruk-iii ◆ P006428 ◆ 32 ◆ obverse ◆ @column 5\n",
      "=    : uruk-iii ◆ P448701 ◆ 40 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 43 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P448702 ◆ 54 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P448702 ◆ 60 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P448702 ◆ 64 ◆ obverse ◆ @column 3\n",
      "=    : uruk-iii ◆ P448703 ◆ 75 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P448703 ◆ 81 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P471695 ◆ 91 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P471695 ◆ 104 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P482082 ◆ 118 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P482083 ◆ 131 ◆ obverse ◆ @column 1\n",
      "=    : uruk-iii ◆ P482083 ◆ 138 ◆ obverse ◆ @column 2\n",
      "=    : uruk-iii ◆ P499393 ◆ 151 ◆ obverse ◆ @column 1\n",
      "=     and 13103 more\n",
      "Number of results: TF 13123; GREP 13123\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('face', 'column'),\n",
    "    grepColumns,\n",
    "    tfColumns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lines\n",
    "\n",
    "We check whether we see the same line numbers with GREP and TF.\n",
    "\n",
    "During the conversion to TF we have \n",
    "detected bad numberings in some columns\n",
    "and stored that fact in the `badNumbering` feature.\n",
    "\n",
    "One way to look at them is in the raw TF file\n",
    "[badNumbering.tf](https://github.com/Dans-labs/Nino-cunei/blob/master/tf/uruk/0.1/badNumbering.tf).\n",
    "\n",
    "There you see case nodes with values `1` (duplicate numbers) or `2` (wrong order).\n",
    "\n",
    "Here is an overview of the cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:17.277271Z",
     "start_time": "2018-02-21T21:17:17.260337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26 x 2\n",
      "  3 x 1\n"
     ]
    }
   ],
   "source": [
    "for (val, amount) in F.badNumbering.freqList():\n",
    "    print(f'{amount:>3} x {val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For full detail, see the\n",
    "[diagnostics](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/diagnostics.tsv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the numbered lines in the transcriptions do not correspond to the TF node type `line`,\n",
    "but to `case`. \n",
    "Because these lines are filled with material of the smallest cases (those that do not have\n",
    "sub-cases).\n",
    "\n",
    "In TF these are the cases that have the feature `fullNumber`.\n",
    "\n",
    "In TF we have removed the dots from numbers, but kept them otherwise unchanged.\n",
    "In order to make the comparison, we also remove the dots after grepping numbers from the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:19.366307Z",
     "start_time": "2018-02-21T21:17:19.338122Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfLines():\n",
    "    cases = []\n",
    "    for tablet in F.otype.s('tablet'):\n",
    "        tabletName = F.catalogId.v(tablet)\n",
    "        period = F.period.v(tablet)\n",
    "        for case in L.d(tablet, otype='case'):\n",
    "            fullNumber = F.fullNumber.v(case)\n",
    "            if fullNumber is None:\n",
    "                continue\n",
    "            ln = F.srcLnNum.v(case)\n",
    "            origNumber = F.origNumber.v(case)\n",
    "            theNumber = fullNumber if origNumber is None else origNumber \n",
    "            cases.append((period, tabletName, ln, f'{theNumber}'))\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:20.759816Z",
     "start_time": "2018-02-21T21:17:20.732884Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepLines(gen):\n",
    "    cases = []\n",
    "    lineNumScan = re.compile('^((?:[a-zA-Z0-9.\\'-]+)|(?=[|\\[]))')\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "\n",
    "        match = lineNumScan.match(line)\n",
    "        if match:\n",
    "            caseNum = match.group(1)\n",
    "            caseNumClean = caseNum.replace('.', '').strip()\n",
    "            cases.append((period, tablet, ln, caseNumClean))\n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:22.135349Z",
     "start_time": "2018-02-21T21:17:21.574111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD : period ◆ tablet ◆ ln ◆ lineNum\n",
      "IDENTICAL: all 42170 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ 1\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 16 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 17 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 19 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 20 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 22 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 23 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 24 ◆ 3\n",
      "=    : uruk-iii ◆ P006428 ◆ 25 ◆ 4\n",
      "=    : uruk-iii ◆ P006428 ◆ 26 ◆ 5\n",
      "=    : uruk-iii ◆ P006428 ◆ 27 ◆ 6\n",
      "=    : uruk-iii ◆ P006428 ◆ 28 ◆ 7\n",
      "=    : uruk-iii ◆ P006428 ◆ 30 ◆ 1\n",
      "=    : uruk-iii ◆ P006428 ◆ 31 ◆ 2\n",
      "=    : uruk-iii ◆ P006428 ◆ 33 ◆ 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 41 ◆ 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 42 ◆ 2\n",
      "=    : uruk-iii ◆ P448701 ◆ 44 ◆ 1\n",
      "=    : uruk-iii ◆ P448701 ◆ 45 ◆ 2\n",
      "=     and 42150 more\n",
      "Number of results: TF 42170; GREP 42170\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('lineNum',),\n",
    "    grepLines,\n",
    "    tfLines,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have defined a function to produce a string value for a full grapheme, including \n",
    "repeats, primes, variants and modifiers.\n",
    "See [utils](utils.py).\n",
    "\n",
    "A complication is that there are missing line numbers in a few cases, \n",
    "so the usual grep pattern does not pick them up.\n",
    "\n",
    "There a lines that start with `[` and with `|`, so we have to take care we get them.\n",
    "\n",
    "There are also line numbers with a hyphen in it, such as `6-7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:24.404511Z",
     "start_time": "2018-02-21T21:17:24.367185Z"
    }
   },
   "outputs": [],
   "source": [
    "lineNumPat = '^(?:(?:[a-zA-Z0-9.\\'-]+\\s+)|(?=[|\\[]))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primes\n",
    "\n",
    "First an overview of the occurrence of primes.\n",
    "\n",
    "**N.B.:** This gathers primes on *signs*, *column* numbers and *case* numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:26.082674Z",
     "start_time": "2018-02-21T21:17:26.048095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5184 x 1\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.prime.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want so see the node types of primed entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:27.782748Z",
     "start_time": "2018-02-21T21:17:27.737515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4652 x case\n",
      "  523 x column\n",
      "    9 x sign\n"
     ]
    }
   ],
   "source": [
    "primed = collections.Counter()\n",
    "for n in F.prime.s(1):\n",
    "    primed[F.otype.v(n)] += 1\n",
    "for x in sorted(primed.items()):\n",
    "    print(f'{x[1]:>5} x {x[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us check the primes with grep, directly in the source files.\n",
    "We look into lines starting with a (hierarchical number), followed by space,\n",
    "and then later a single of double prime, but not one within a grapheme, such as `GA'AR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:29.255452Z",
     "start_time": "2018-02-21T21:17:29.233830Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfPrimes():\n",
    "    primes = []\n",
    "    for n in F.prime.s(1):\n",
    "        if F.otype.v(n) != 'sign':\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        primes.append((F.period.v(t), tablet, F.srcLnNum.v(case), f\"{COMP.strFromSign(n)}\"))\n",
    "    return primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:30.117657Z",
     "start_time": "2018-02-21T21:17:30.094455Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepPrimes(gen):\n",
    "    primes = []\n",
    "    primePat = re.compile(f'{lineNumPat}(.*[\\'\"][^A].*)')\n",
    "    graphemePat = re.compile('(?:[0-9]+\\([^)]+[\\'\"]\\))|(?:[A-Z0-9~@a-wyz\\'-]+\\')')\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        match = primePat.match(line)\n",
    "        if match:\n",
    "            material = match.group(1)\n",
    "            graphemes = graphemePat.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                primes.append((period, tablet, ln, grapheme))\n",
    "    return primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:31.067973Z",
     "start_time": "2018-02-21T21:17:30.897914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "DIFFERENT: first different item is at position 1 in the list\n",
      "TF   : uruk-iii ◆ P411604 ◆ 48967 ◆ 1(N24')\n",
      "GREP : uruk-iii ◆ P411604 ◆ 48967 ◆ 1(N24\")\n",
      "remaining items (TF: 8); GREP: 8\n",
      "=    : uruk-iii ◆ P411610 ◆ 49069 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49071 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49073 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411610 ◆ 49075 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P411539 ◆ 49391 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P006437 ◆ 54446 ◆ 1(N30c')\n",
      "=    : uruk-iii ◆ P464140 ◆ 55938 ◆ 1(N24')\n",
      "=    : uruk-iii ◆ P464140 ◆ 55939 ◆ 1(N24')\n",
      "      no more items\n",
      "Number of results: TF 9; GREP 9\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepPrimes,\n",
    "    tfPrimes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes it clear: in the transcription there is a strange double prime on the `N(24\")`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants and modifiers\n",
    "\n",
    "Overview of variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:33.387340Z",
     "start_time": "2018-02-21T21:17:33.349911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23804 x a\n",
      " 4172 x b\n",
      " 1532 x c\n",
      " 1356 x a1\n",
      "  703 x b1\n",
      "  194 x a2\n",
      "  187 x d\n",
      "  127 x b2\n",
      "   85 x f\n",
      "   73 x a3\n",
      "   40 x e\n",
      "   29 x c2\n",
      "   22 x c1\n",
      "   22 x c3\n",
      "   17 x v\n",
      "   14 x c5\n",
      "   13 x b3\n",
      "   12 x a0\n",
      "   12 x d1\n",
      "   11 x c4\n",
      "    6 x a4\n",
      "    6 x g\n",
      "    5 x d2\n",
      "    4 x d4\n",
      "    4 x h\n",
      "    2 x 3a\n",
      "    2 x d3\n",
      "    1 x h2\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.variant.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of modifiers outside a repeat expression, like `1(N57)@t`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:34.810787Z",
     "start_time": "2018-02-21T21:17:34.794011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  648 x g\n",
      "  251 x t\n",
      "   39 x n\n",
      "    6 x r\n",
      "    4 x s\n",
      "    1 x c\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifier.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of modifiers within a repeat expression, like `7(N34@f)#`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:36.281476Z",
     "start_time": "2018-02-21T21:17:36.265772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25 x f\n",
      "   15 x t\n",
      "    1 x r\n",
      "    1 x v\n"
     ]
    }
   ],
   "source": [
    "for (value, frequency) in F.modifierInner.freqList():\n",
    "    print(f'{frequency:>5} x {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are many variants and considerably fewer modifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look for variants and modifiers in the TF resource and by GREPping them from the sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:38.466723Z",
     "start_time": "2018-02-21T21:17:38.421619Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfVarMod():\n",
    "    varmods = []\n",
    "    for n in F.otype.s('sign'):\n",
    "        variant = F.variant.v(n)\n",
    "        modifier = F.modifier.v(n)\n",
    "        modifierInner = F.modifierInner.v(n)\n",
    "        if variant is None and modifier is None and modifierInner is None:\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        position = (F.period.v(t), tablet, F.srcLnNum.v(case))\n",
    "        varmods.append((*position, f\"{COMP.strFromSign(n)}\"))\n",
    "\n",
    "        written = F.written.v(n)\n",
    "        if written is not None:\n",
    "            if '~' in written:\n",
    "                varmods.append((*position, written))\n",
    "\n",
    "    return varmods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order\n",
    "Modifiers and variants may come in any order.\n",
    "The conversion has set *modifierFirst* on those items where the modifier precedes the variant.\n",
    "\n",
    "Hence, when we fetch data from TF, we can and do put modifiers and variants in the right order.\n",
    "\n",
    "Examples:\n",
    "\n",
    "```\n",
    "3. 1(N14) 8(N01) , RAD~a@g ERIM~a SZU2 A?\n",
    "```\n",
    "\n",
    "and cases with modifier and then variant:\n",
    "\n",
    "```\n",
    "4. 2(N01) , URUDU@g~b SZU2#\n",
    "```\n",
    "\n",
    "both from the same tablet P003407.\n",
    "\n",
    "#### Uppercase\n",
    "We encounter modifiers or variants in uppercase.\n",
    "The conversion has brought them to lower case.\n",
    "When we fetch data by grep, we perform this lowercasing before making the comparison.\n",
    "\n",
    "#### Stray modifier\n",
    "Somewhere in the source is `SUKUD@inversum`.\n",
    "The conversion translates the `@inversum` to `@v`.\n",
    "We have to mimick that when we do grep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:40.029482Z",
     "start_time": "2018-02-21T21:17:39.998117Z"
    }
   },
   "outputs": [],
   "source": [
    "upperPat = re.compile('[~]([A-Z])')\n",
    "\n",
    "def lower(match):\n",
    "    return f'~{match.group(1).lower()}'\n",
    "\n",
    "def graphemeTweaks(grapheme):\n",
    "    if '@inversum' in grapheme:\n",
    "        print(f'GREP: \"@inversum\" => \"@v\"')\n",
    "        grapheme = grapheme.replace('@inversum', '@v')\n",
    "    if '~a~a' in grapheme:\n",
    "        print(f'GREP: \"~a~a\" => \"~a\"')\n",
    "        grapheme = grapheme.replace('~a~a', '~a')\n",
    "    if upperPat.search(grapheme):\n",
    "        print(f'GREP: uppercase variant/modifier in grapheme changed to lowercase')\n",
    "        grapheme = upperPat.sub(lower, grapheme)\n",
    "    if '\"' in grapheme:\n",
    "        print(f'GREP: double prime replaced by single one')\n",
    "        grapheme = grapheme.replace('\"', \"'\")\n",
    "    if '?#' in grapheme:\n",
    "        print(f'GREP: flags order \"?#\" changed into \"#?\"')\n",
    "        grapheme = grapheme.replace('?#', '#?')\n",
    "    return grapheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:40.862352Z",
     "start_time": "2018-02-21T21:17:40.837280Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepVarMod(gen):\n",
    "    varmods = []\n",
    "    varmodPat = re.compile(f'{lineNumPat}(.*[@~].*)')\n",
    "    graphemePat = re.compile(\n",
    "    '''\n",
    "    (?:\n",
    "        [0-9]+\\([^)]+[@~][^)]+\\)\n",
    "    )|(?:\n",
    "        [0-9]+\\([^)]+\\)@[a-z]\n",
    "    )|(?:\n",
    "        [A-Z0-9a-wyz\\'-]+[@~][0-9~@a-wyzA-WYZ]+\n",
    "    )\n",
    "    ''', re.X)\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        match = varmodPat.match(line)\n",
    "        if match:\n",
    "            material = match.group(1)\n",
    "            graphemes = graphemePat.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                grapheme = graphemeTweaks(grapheme)\n",
    "                varmods.append((period, tablet, ln, grapheme))\n",
    "    return varmods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:17:43.850929Z",
     "start_time": "2018-02-21T21:17:42.005755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"@inversum\" => \"@v\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "DIFFERENT: first different item is at position 8864 in the list\n",
      "=     start with 8843 items\n",
      "=    : uruk-iii ◆ P000608 ◆ 33914 ◆ SU~a\n",
      "=    : uruk-iii ◆ P000608 ◆ 33914 ◆ SZAH2~a\n",
      "=    : uruk-iii ◆ P000608 ◆ 33916 ◆ SU~a\n",
      "=    : uruk-iii ◆ P000608 ◆ 33916 ◆ ANSZE~b\n",
      "=    : uruk-iii ◆ P000608 ◆ 33918 ◆ SU~a\n",
      "=    : uruk-iii ◆ P000608 ◆ 33920 ◆ SILA3~a\n",
      "=    : uruk-iii ◆ P000608 ◆ 33922 ◆ SILA3~a\n",
      "=    : uruk-iii ◆ P000608 ◆ 33924 ◆ SILA3~a\n",
      "=    : uruk-iii ◆ P000608 ◆ 33926 ◆ SZA3~a1\n",
      "=    : uruk-iii ◆ P000608 ◆ 33928 ◆ BU~a\n",
      "=    : uruk-iii ◆ P471692 ◆ 33941 ◆ AD~a\n",
      "=    : uruk-iii ◆ P471692 ◆ 33943 ◆ AD~a\n",
      "=    : uruk-iii ◆ P471692 ◆ 33951 ◆ UZ~a\n",
      "=    : uruk-iii ◆ P471692 ◆ 33953 ◆ SI4~a\n",
      "=    : uruk-iii ◆ P471692 ◆ 33955 ◆ TU~b\n",
      "=    : uruk-iii ◆ P471692 ◆ 33957 ◆ GUKKAL~c\n",
      "=    : uruk-iii ◆ P471692 ◆ 33959 ◆ KAL~a\n",
      "=    : uruk-iii ◆ P471692 ◆ 33961 ◆ GA~b\n",
      "=    : uruk-iii ◆ P471692 ◆ 33965 ◆ KAR2~a\n",
      "=    : uruk-iii ◆ P471692 ◆ 33967 ◆ KAD4~b\n",
      "TF   : uruk-iii ◆ P471692 ◆ 33969 ◆ ZA~v\n",
      "GREP : uruk-iii ◆ P471692 ◆ 33971 ◆ GIR2~a\n",
      "remaining items (TF: 23943); GREP: 23938\n",
      "TF   : uruk-iii ◆ P471692 ◆ 33971 ◆ GIR2~a\n",
      "GREP : uruk-iii ◆ P471692 ◆ 33973 ◆ DA~a\n",
      "TF   : uruk-iii ◆ P471692 ◆ 33973 ◆ DA~a\n",
      "GREP : uruk-iii ◆ P471692 ◆ 33975 ◆ GA~b\n",
      "TF   : uruk-iii ◆ P471692 ◆ 33975 ◆ GA~b\n",
      "GREP : uruk-iii ◆ P471692 ◆ 33977 ◆ GARA2~a\n",
      "TF   : uruk-iii ◆ P471692 ◆ 33977 ◆ GARA2~a\n",
      "GREP : uruk-iii ◆ P471692 ◆ 33985 ◆ UTUA~b\n",
      "TF   : uruk-iii ◆ P471692 ◆ 33985 ◆ UTUA~b\n",
      "GREP : uruk-iii ◆ P471692 ◆ 33987 ◆ UD5~a\n",
      "TF   : uruk-iii ◆ P471692 ◆ 33987 ◆ UD5~a\n",
      "GREP : uruk-iii ◆ P471692 ◆ 33993 ◆ ISZ~b\n",
      "TF   : uruk-iii ◆ P471692 ◆ 33993 ◆ ISZ~b\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34007 ◆ UZ~a\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34007 ◆ UZ~a\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34009 ◆ SI4~a\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34009 ◆ SI4~a\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34011 ◆ TU~b\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34011 ◆ TU~b\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34013 ◆ GUKKAL~c\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34013 ◆ GUKKAL~c\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34015 ◆ KAL~a\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34015 ◆ KAL~a\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34017 ◆ GA~b\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34017 ◆ GA~b\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34021 ◆ KAR2~b\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34021 ◆ KAR2~b\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34023 ◆ KAD4~a\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34023 ◆ KAD4~a\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34027 ◆ GIR2~a\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34025 ◆ ZA~v\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34029 ◆ DA~a\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34027 ◆ GIR2~a\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34031 ◆ GA~b\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34029 ◆ DA~a\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34033 ◆ GARA2~a\n",
      "TF   : uruk-iii ◆ P471692 ◆ 34031 ◆ GA~b\n",
      "GREP : uruk-iii ◆ P471692 ◆ 34041 ◆ UTUA~b\n",
      "TF    and 23925 more\n",
      "GREP  and 23920 more\n",
      "Number of results: TF 32807; GREP 32802\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepVarMod,\n",
    "    tfVarMod,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweaks\n",
    "During conversion, we found some problems in the sources and tweaked them.\n",
    "When we grep, we must repeat those tweaks, in order to get comparable results.\n",
    "\n",
    "See the [diagnostics](https://github.com/Dans-labs/Nino-cunei/blob/master/reports/diagnostics.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:19:54.655032Z",
     "start_time": "2018-02-21T21:19:54.586656Z"
    }
   },
   "outputs": [],
   "source": [
    "TWEAK_MATERIAL = (\n",
    "#    ('4\"', \"4'\"),\n",
    "#    ('[,', ''),\n",
    "    ('SA|L', 'SAL|'),\n",
    "    ('~x(', '~v ('),\n",
    "    ('~x', '~v'),\n",
    "    ('U2@~b', 'U2~b'),\n",
    "#    (')|U', ') |U'),\n",
    "    ('1N(02)', '1(N02)'),\n",
    "    ('(1N', '1(N'),\n",
    "#    ('~A', '~a'),\n",
    "#    ('{', '('),\n",
    "#    ('}', ')'),\n",
    "#    ('sag-apin', 'sag-apin'),\n",
    "#    ('@inversum', '@v'),\n",
    "     (('KI@', -1), 'KI!'),\n",
    ")\n",
    "\n",
    "def tweakBeforeGrep(material):\n",
    "    for (pat, rep) in TWEAK_MATERIAL:\n",
    "        if type(pat) is tuple:\n",
    "            (pat, pos) = pat\n",
    "            if pos == 0:\n",
    "                condition = material.startswith(pat)\n",
    "                mark = ' (at start)'\n",
    "            elif pos == -1:\n",
    "                condition = material.endswith(pat)\n",
    "                mark = ' (at end)'\n",
    "        else:\n",
    "            pos = None\n",
    "            condition = pat in material\n",
    "            mark = ''\n",
    "\n",
    "        if condition:\n",
    "            print(f'GREP: tweak \"{pat}\" => \"{rep}\"')\n",
    "            if pos is None:\n",
    "                material = material.replace(pat, rep)\n",
    "            elif pos == 0:\n",
    "                material = material.replace(pat, rep, 1)\n",
    "            else:\n",
    "                material = material[0:-len(pat)] + rep\n",
    "    return material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flags\n",
    "\n",
    "We have several features for flags: \n",
    "\n",
    "mark | feature | comments\n",
    "----|---\n",
    "`*`|*collation* | not encountered in uruk iii-iv\n",
    "`#`|*damage*\n",
    "`?`|*uncertain*\n",
    "`!`|*remarkable*\n",
    "`!(`ggg`)`|*written*\n",
    "\n",
    "#### A bit of research\n",
    "We start by surveying the possible values, including on which node types they occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:20:00.744329Z",
     "start_time": "2018-02-21T21:19:58.865174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19945 x sign-damage-1\n",
      "  3727 x sign-uncertain-1\n",
      "  1045 x quad-damage-1\n",
      "   321 x quad-uncertain-1\n",
      "    11 x sign-remarkable-1\n",
      "     2 x sign-written-KASKAL\n",
      "     1 x sign-written-GURUSZ~a\n",
      "     1 x sign-written-IB~a\n"
     ]
    }
   ],
   "source": [
    "flagFeatures = '''\n",
    "    damage\n",
    "    remarkable\n",
    "    written\n",
    "    uncertain\n",
    "'''.strip().split()\n",
    "\n",
    "flagNodeOverview = collections.Counter()\n",
    "flagNodeTypes = set()\n",
    "\n",
    "for n in N():\n",
    "    for ft in flagFeatures:\n",
    "        value = Fs(ft).v(n)\n",
    "        if not value: continue\n",
    "        nType = F.otype.v(n)\n",
    "        flagNodeTypes.add(nType)\n",
    "        flagNodeOverview[f'{nType}-{ft}-{value}'] += 1\n",
    "for (combi, amount) in sorted(flagNodeOverview.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f'{amount:>6} x {combi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see whether there are any cooccurrences of flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:20:03.188604Z",
     "start_time": "2018-02-21T21:20:00.856663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258248 x     *     -    *     -    *     -    *     \n",
      " 18385 x   damage  -    *     -    *     -    *     \n",
      "  2605 x   damage  -    *     -    *     -uncertain \n",
      "  1442 x     *     -    *     -    *     -uncertain \n",
      "    11 x     *     -remarkable-    *     -    *     \n",
      "     3 x     *     -    *     - written  -    *     \n",
      "     1 x     *     -    *     - written  -uncertain \n"
     ]
    }
   ],
   "source": [
    "flagCombis = collections.Counter()\n",
    "\n",
    "for n in N():\n",
    "    if F.otype.v(n) not in flagNodeTypes:\n",
    "        continue\n",
    "    values = []\n",
    "    for ft in flagFeatures:\n",
    "        rawValue = Fs(ft).v(n)\n",
    "        value = f'{\"*\":^10}' if rawValue is None else f'{ft:^10}' if rawValue else f'{\"\":^10}'\n",
    "        values.append(value)\n",
    "\n",
    "    combi = '-'.join(values)\n",
    "    flagCombis[combi] += 1\n",
    "\n",
    "for (combi, amount) in sorted(flagCombis.items(), key=lambda x: (-x[1], x[0])):\n",
    "    print(f'{amount:>6} x {combi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to address the question about order of flags.\n",
    "\n",
    "A quick inspection in the corpus yields:\n",
    "\n",
    "* damage-uncertain (`#?`) and uncertain-damage (`?#`), but the latter is very rare and all cases\n",
    "  occur in the diagnostics;\n",
    "* uncertain-remarkable (`?!`) does not occur, and remarkable-written-uncertain (`!(`ggg`)?` does occur.\n",
    "\n",
    "Based on this observation, and assuming that the order between *damage* and *uncertain* is not relevant,\n",
    "we produce flags always in the order:\n",
    "\n",
    "* *damage* *remarkable* *written* *uncertain*\n",
    "\n",
    "When grepping, we have to normalize `?#` to `#?`.\n",
    "\n",
    "There is one weird case, diagnosed by the conversion, in tablet P471687:\n",
    "\n",
    "```\n",
    "C1. |DUGb+?|\n",
    "```\n",
    "\n",
    "Here we see an operator `+` of which the second operand `?` consists of a flag without a grapheme.\n",
    "This occurs only once, so I think it is a mistake.\n",
    "\n",
    "Yet we'll find it when we search with TF, so we exclude it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:20:05.212158Z",
     "start_time": "2018-02-21T21:20:05.197217Z"
    }
   },
   "outputs": [],
   "source": [
    "flagPat = '''\n",
    "(?:\n",
    "        (?:\n",
    "            !\\([^)]*\\)\n",
    "        )\n",
    "    |\n",
    "        [!#?]\n",
    ")\n",
    "'''\n",
    "\n",
    "flagModVarPat = '''\n",
    "(?:\n",
    "        (?:\n",
    "            !\\([^)]*\\)\n",
    "        )\n",
    "    |\n",
    "        [!#?]\n",
    "    |\n",
    "        (?:\n",
    "            @[A-WYZa-wyz]+\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            ~[A-WYZa-wyz0-9]+\n",
    "        )\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:20:09.874224Z",
     "start_time": "2018-02-21T21:20:09.844893Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfFlags():\n",
    "    flags = []\n",
    "    for n in F.otype.s('sign'):\n",
    "        values = [Fs(ft).v(n) for ft in flagFeatures]\n",
    "        if all(value is None for value in values):\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        sign = f\"{COMP.strFromSign(n, flags=True)}\"\n",
    "        if sign == '?':\n",
    "            print(f'TF: grapheme-less flag skipped in \"{line}\"')\n",
    "            continue\n",
    "        flags.append((F.period.v(t), tablet, F.srcLnNum.v(case), f\"{COMP.strFromSign(n, flags=True)}\"))\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:27:46.342262Z",
     "start_time": "2018-02-21T21:27:46.306130Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepFlags(gen):\n",
    "    flags = []\n",
    "    flagsPat = re.compile(f'{lineNumPat}(.*[!?#].*)')\n",
    "    graphemePat = re.compile(\n",
    "        f'''\n",
    "            (?:\n",
    "                [0-9]+\\([^)]+\\)\n",
    "                {flagPat}+\n",
    "            )\n",
    "        |\n",
    "            (?:\n",
    "                [A-Z0-9~@a-wyz\\'-]+\n",
    "                {flagPat}+\n",
    "            )\n",
    "        ''', re.X)\n",
    "\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        line = tweakBeforeGrep(line.strip())\n",
    "\n",
    "        match = flagsPat.match(line)\n",
    "        if match:\n",
    "            material = match.group(1)\n",
    "            graphemes = graphemePat.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                grapheme = graphemeTweaks(grapheme)\n",
    "                flags.append((period, tablet, ln, grapheme))\n",
    "    return flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:27:49.282004Z",
     "start_time": "2018-02-21T21:27:46.919684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: grapheme-less flag skipped in \"C\"\n",
      "GREP: \"@inversum\" => \"@v\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: tweak \"SA|L\" => \"SAL|\"\n",
      "GREP: tweak \"1N(02)\" => \"1(N02)\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: tweak \"KI@\" => \"KI!\"\n",
      "GREP: tweak \"(1N\" => \"1(N\"\n",
      "GREP: tweak \"~x(\" => \"~v (\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: double prime replaced by single one\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: tweak \"U2@~b\" => \"U2~b\"\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "IDENTICAL: all 21265 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ SANGA~a?\n",
      "=    : uruk-iii ◆ P448702 ◆ 58 ◆ KASZ~a?\n",
      "=    : uruk-iii ◆ P448702 ◆ 59 ◆ 6(N14)#?\n",
      "=    : uruk-iii ◆ P448702 ◆ 63 ◆ SUKUD@v?\n",
      "=    : uruk-iii ◆ P471695 ◆ 105 ◆ ISZ~a#?\n",
      "=    : uruk-iii ◆ P471695 ◆ 111 ◆ 6(N01)#\n",
      "=    : uruk-iii ◆ P482082 ◆ 120 ◆ 4(N14)#\n",
      "=    : uruk-iii ◆ P482082 ◆ 121 ◆ 2(N14)#\n",
      "=    : uruk-iii ◆ P482083 ◆ 133 ◆ 1(N14)#\n",
      "=    : uruk-iii ◆ P482083 ◆ 135 ◆ KASZ~b?\n",
      "=    : uruk-iii ◆ P504412 ◆ 176 ◆ MASZ2?\n",
      "=    : uruk-iii ◆ P504412 ◆ 177 ◆ X?\n",
      "=    : uruk-iii ◆ P504412 ◆ 179 ◆ X?\n",
      "=    : uruk-iii ◆ P504412 ◆ 182 ◆ GI4~a#\n",
      "=    : uruk-iii ◆ P504412 ◆ 183 ◆ SAL?\n",
      "=    : uruk-iii ◆ P006438 ◆ 213 ◆ RAD~a#\n",
      "=    : uruk-iii ◆ P006438 ◆ 217 ◆ LAL2~a#?\n",
      "=    : uruk-iii ◆ P006438 ◆ 217 ◆ NIM~b2#?\n",
      "=    : uruk-iii ◆ P000014 ◆ 229 ◆ SZUBUR#\n",
      "=    : uruk-iii ◆ P000014 ◆ 230 ◆ KAB#?\n",
      "=     and 21245 more\n",
      "Number of results: TF 21265; GREP 21265\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepFlags,\n",
    "    tfFlags,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All signs\n",
    "\n",
    "Now it is time to do a rigorous comparison of all signs in the transcriptions and in TF.\n",
    "\n",
    "Up till now we included only signs that had primes, variants, modifiers or flags attached to them.\n",
    "Now we extend the comparison to all of them.\n",
    "\n",
    "We still ignore the quad structures with operators and the bracketing of quads (clusters).\n",
    "But we do draw their component signs into the comparison.\n",
    "\n",
    "This comparison lists all signs in textual order, in TF and in GREP, and compares the two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:27:52.144322Z",
     "start_time": "2018-02-21T21:27:52.108685Z"
    }
   },
   "outputs": [],
   "source": [
    "def tfSigns():\n",
    "    signs = []\n",
    "    for n in F.otype.s('sign'):\n",
    "        if F.grapheme.v(n) == '':\n",
    "            continue\n",
    "        (tablet, column, line) = T.sectionFromNode(n)\n",
    "        t = L.u(n, otype='tablet')[0]\n",
    "        case = L.u(n, otype='case')[0]\n",
    "        \n",
    "        sign = f\"{COMP.strFromSign(n, flags=True)}\"\n",
    "        if sign == '?':\n",
    "            print(f'TF: grapheme-less flag skipped in \"{line}\"')\n",
    "            continue\n",
    "        signs.append((F.period.v(t), tablet, F.srcLnNum.v(case), f\"{COMP.strFromSign(n, flags=True)}\"))\n",
    "    return signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The regular expression that greps all graphemes from the transcription is quite daunting.\n",
    "Comapare this with the relative easy by which you get all this from the text-fabric representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:27:55.188185Z",
     "start_time": "2018-02-21T21:27:55.170140Z"
    }
   },
   "outputs": [],
   "source": [
    "smallPat = '[A-Zn]'\n",
    "\n",
    "graphemePat = re.compile(\n",
    "    f'''\n",
    "        (?:\n",
    "            \\.\\.\\.                        # three dots, mostly in [...]\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            [0-9]+\\([^)]+\\)               # a repeat, e.g. 5(N024)\n",
    "            {flagModVarPat}*\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            [A-Z0-9a-wyzû\\'-]{{2,}}       # a plain grapheme, e.g. GA'AR\n",
    "            {flagModVarPat}*\n",
    "        )\n",
    "    |\n",
    "        (?:\n",
    "            {smallPat}                    # a single letter grapheme: X or n, mostly in [n]\n",
    "            {flagModVarPat}*\n",
    "        )\n",
    "    ''', re.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:27:55.964548Z",
     "start_time": "2018-02-21T21:27:55.926357Z"
    }
   },
   "outputs": [],
   "source": [
    "def grepSigns(gen):\n",
    "    signs = []\n",
    "    signsPat = re.compile(f'{lineNumPat}(.*)')\n",
    "    for (period, tablet, ln, line, skip) in gen:\n",
    "        if skip:\n",
    "            continue\n",
    "        if line.startswith('1.1('):\n",
    "            print(f'GREP: inserted space between number and material: \"1.1(\"')\n",
    "            line = line.replace('1.1(', '1.1 (', 1)\n",
    "        match = signsPat.match(line)\n",
    "        if match:\n",
    "            material = match.group(1).strip()\n",
    "            material = tweakBeforeGrep(material)\n",
    "            graphemes = graphemePat.findall(material)\n",
    "            for grapheme in graphemes:\n",
    "                grapheme = graphemeTweaks(grapheme)\n",
    "                signs.append((period, tablet, ln, grapheme))\n",
    "    return signs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next one will take 5-10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-21T21:28:05.595247Z",
     "start_time": "2018-02-21T21:27:58.082319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREP: \"@inversum\" => \"@v\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: flags order \"?#\" changed into \"#?\"\n",
      "GREP: tweak \"SA|L\" => \"SAL|\"\n",
      "GREP: tweak \"1N(02)\" => \"1(N02)\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: tweak \"KI@\" => \"KI!\"\n",
      "GREP: tweak \"(1N\" => \"1(N\"\n",
      "GREP: tweak \"~x(\" => \"~v (\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: tweak \"~x\" => \"~v\"\n",
      "GREP: inserted space between number and material: \"1.1(\"\n",
      "GREP: double prime replaced by single one\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: \"~a~a\" => \"~a\"\n",
      "GREP: tweak \"U2@~b\" => \"U2~b\"\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "GREP: uppercase variant/modifier in grapheme changed to lowercase\n",
      "HEAD : period ◆ tablet ◆ ln ◆ grapheme\n",
      "IDENTICAL: all 129829 items\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ ...\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ X\n",
      "=    : uruk-iii ◆ P006427 ◆ 6 ◆ X\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ 3(N14)\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ X\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ SANGA~a?\n",
      "=    : uruk-iii ◆ P006427 ◆ 8 ◆ ...\n",
      "=    : uruk-iii ◆ P006428 ◆ 16 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 16 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 17 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 17 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 19 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 19 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 20 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 20 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 22 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 22 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 23 ◆ 3(N14)\n",
      "=    : uruk-iii ◆ P006428 ◆ 23 ◆ X\n",
      "=    : uruk-iii ◆ P006428 ◆ 24 ◆ 1(N14)\n",
      "=     and 129809 more\n",
      "Number of results: TF 129829; GREP 129829\n"
     ]
    }
   ],
   "source": [
    "COMP.checkSanity(\n",
    "    ('grapheme',),\n",
    "    grepSigns,\n",
    "    tfSigns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
